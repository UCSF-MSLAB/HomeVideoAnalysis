{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17dcd527-3bf6-4eb3-9c12-f7debb72c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from statannotations.Annotator import Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ccb540-2f7e-4d6e-b326-8ca9fabf42d4",
   "metadata": {},
   "source": [
    "# Gait Metric Analysis \n",
    "- For zeno videos: accuracy of video metrics vs mat metrics\n",
    "- For zeno and home videos: associations of video metrics with clinical outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5fbdf-17c4-4778-be5d-608fbf883466",
   "metadata": {},
   "source": [
    "# Define Analysis Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dfca59-601b-4fce-a880-ebfdb5f0a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ordinal value of EDSS severity \n",
    "# 0-2 (mild), 2.5-4 (moderate), 4.5+ (severe)\n",
    "\n",
    "# Function to categorize EDSS severity\n",
    "def categorize_edss(edss_value):\n",
    "    if 0 <= edss_value <= 2:\n",
    "        return 1, 'mild'\n",
    "    elif 2.5 <= edss_value <= 4:\n",
    "        return 2, 'moderate'\n",
    "    elif edss_value >= 4.5:\n",
    "        return 3, 'severe'\n",
    "    else:\n",
    "        return None, None  # Handle cases outside the defined ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5210fe62-0199-461c-81c9-a35b61d5c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ordinal value for T25FW \n",
    "def categorize_t25fw(t25fw_value):\n",
    "    if 0 <= t25fw_value < 6:\n",
    "        return 1, 'under_6'\n",
    "    elif 6 <= t25fw_value <= 7.99:\n",
    "        return 2, '6_to_8'\n",
    "    elif t25fw_value >= 8:\n",
    "        return 3, 'over_8'\n",
    "    else:\n",
    "        return None, None  # Handle cases outside the defined ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf7737a-517f-44de-9b24-86c8a492998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = gait_vertical_PWS_1 or gait_vertical_FW_1\n",
    "def merge_bw_zv(bw_df, zv_df, task, out_path):\n",
    "\n",
    "    # filter zv to only include one task (bw drop columns, zv drop rows) \n",
    "    zv_task_df = zv_df[zv_df['task_pose_zv'] == task]\n",
    "    print('confirm all one task')\n",
    "    print(pd.unique(zv_task_df['task_pose_zv']))\n",
    "\n",
    "    print('total zeno videos') \n",
    "    print(len(zv_task_df))\n",
    "\n",
    "    # drop bw columns to only include one task \n",
    "    if task == 'gait_vertical_PWS_1':\n",
    "        bw_df = bw_df.drop(['FW_stridetimesecmean', 'FW_stridetimeseccv','FW_cadencestepsminmean','FW_totaldsupportmean', \n",
    "                            'FW_singlesupportmean','FW_totaldsupportratiolr', 'FW_singlesupportratiolr', \n",
    "                            'FW_stridewidthcmmean','FW_stridewidthcmsd'], axis = 1)\n",
    "    elif task == 'gait_vertical_FW_1':\n",
    "         bw_df = bw_df.drop(['PWS_stridetimesecmean', 'PWS_stridetimeseccv','PWS_cadencestepsminmean','PWS_totaldsupportmean', \n",
    "                             'PWS_singlesupportmean','PWS_totaldsupportratiolr', 'PWS_singlesupportratiolr', \n",
    "                             'PWS_stridewidthcmmean','PWS_stridewidthcmsd'], axis = 1)\n",
    "        \n",
    "\n",
    "    # filter bw ids dataset to only those included in video data set \n",
    "    zv_in_bw_df = bw_df[bw_df['bw_id'].isin(zv_task_df['id_video'])]\n",
    "    zv_in_bw_df.to_csv(os.path.join(out_path, 'zv_id_in_bw_df_' + task + '.csv')) # save excel \n",
    "\n",
    "    print('total bw rows with id in video dataset') \n",
    "    print(len(zv_in_bw_df))\n",
    "\n",
    "    # merge bw data set rows with zeno videos rows \n",
    "        # merge bw data set rows with zeno videos rows \n",
    "        # id and date needs to be the same \n",
    "        # should only use each brainwalk visit once - once PWS_1 video per person \n",
    "\n",
    "    merged_bw_zv = []\n",
    "\n",
    "    # Loop through each row in zv_task_df\n",
    "    for index, zv_row in zv_task_df.iterrows():\n",
    "   \n",
    "        current_id = zv_row['id_video']\n",
    "        current_date = zv_row['visit_date_video']\n",
    "        zv_row_df = pd.DataFrame([zv_row])\n",
    "\n",
    "        # Find rows in brainwalk data set with same id and same date as current zv data \n",
    "        zv_in_bw_current_id_rows = zv_in_bw_df[(zv_in_bw_df['bw_id'] == current_id) & (zv_in_bw_df['visit_date'] == current_date)]\n",
    "        #zv_in_bw_current_id_date_rows = zv_in_bw_current_id_rows[zv_in_bw_current_id_rows['visit_date'] == current_date]\n",
    "   \n",
    "        if len(zv_in_bw_current_id_rows) == 1: \n",
    "            bw_row_to_merge = zv_in_bw_current_id_rows\n",
    "            # merge bw and zv, store merged row\n",
    "            merged_row = zv_row_df.merge(bw_row_to_merge, left_on='id_video', right_on='bw_id')\n",
    "            merged_bw_zv.append(merged_row)\n",
    "        \n",
    "        # if more than one row for the id and date, pick one with least na values \n",
    "        elif len(zv_in_bw_current_id_rows) > 1:\n",
    "            bw_row_to_merge = zv_in_bw_current_id_rows.loc[[zv_in_bw_current_id_rows.isna().sum(axis=1).idxmin()]]\n",
    "            # merge bw and zv, store merged row\n",
    "            merged_row = zv_row_df.merge(bw_row_to_merge, left_on='id_video', right_on='bw_id')\n",
    "            merged_bw_zv.append(merged_row)\n",
    "\n",
    "        else: \n",
    "            print('No matching id and daterow from video vs mat')\n",
    "            print(current_id)\n",
    "            print(current_date)\n",
    "\n",
    "\n",
    "    # merge all bw and zv data together \n",
    "    merged_bw_zv_df = pd.concat(merged_bw_zv)\n",
    "    merged_bw_zv_df = merged_bw_zv_df.reset_index(drop=True) # reset index \n",
    "\n",
    "    # check same ID for each row \n",
    "    print('mismatched zeno video vs brainwalk id')\n",
    "    print(sum(merged_bw_zv_df['id_video'] != merged_bw_zv_df['bw_id']))\n",
    "\n",
    "    print('mismatched zeno video vs brainwalk date')\n",
    "    print(sum(merged_bw_zv_df['visit_date_video'] != merged_bw_zv_df['visit_date']))\n",
    "\n",
    "    # saved merged df for future reference \n",
    "    merged_bw_zv_df.to_csv(os.path.join(out_path,  'zv_bw_merged_' + task + '.csv'))\n",
    "\n",
    "    return merged_bw_zv_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ef8a0e-b80e-45cf-813b-4beeaa2213b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge home video data with preferred walking speed mat data \n",
    "# participants walk at preferred pace at home \n",
    "\n",
    "def merge_bw_hv(bw_df, hv_df, task, out_path):\n",
    "    # filter zv to only include one task (bw drop columns, zv drop rows) \n",
    "    hv_task_df = hv_df[hv_df['task_pose_hv'] == task]\n",
    "    print('confirm all one task')\n",
    "    print(pd.unique(hv_task_df['task_pose_hv']))\n",
    "\n",
    "    print('total home videos') \n",
    "    print(len(hv_task_df))\n",
    "\n",
    "    # drop FW data from bw dataset \n",
    "    bw_df = bw_df.drop(['FW_stridetimesecmean', 'FW_stridetimeseccv','FW_cadencestepsminmean','FW_totaldsupportmean',\n",
    "                        'FW_singlesupportmean','FW_totaldsupportratiolr', 'FW_singlesupportratiolr', \n",
    "                        'FW_stridewidthcmmean','FW_stridewidthcmsd'], axis = 1)\n",
    "\n",
    "    # filter bw ids dataset to only those included in video data set \n",
    "    hv_in_bw_df = bw_df[bw_df['bw_id'].isin(hv_task_df['id_video'])]\n",
    "    hv_in_bw_df.to_csv(os.path.join(out_path, 'hv_id_in_bw_df.csv')) # save excel \n",
    "\n",
    "    print('total bw rows with id in video dataset') \n",
    "    print(len(hv_in_bw_df))\n",
    "\n",
    "    # Track used rows from zv_in_bw_df\n",
    "    used_indices = set()\n",
    "\n",
    "    # Helper function to find the closest date\n",
    "    def find_closest_date_unique(row, in_bw_df):\n",
    "        # Filter rows with the same 'bw_id' and not already used\n",
    "        filtered_df = in_bw_df[(in_bw_df['bw_id'] == row['id_video'])] # & (~in_bw_df.index.isin(used_indices)) - add after video'] for unique only\n",
    "        if filtered_df.empty:\n",
    "            return None\n",
    "        \n",
    "        # Find the closest date\n",
    "        closest_idx = (filtered_df['visit_date'] - row['visit_date_video']).abs().idxmin()\n",
    "       # used_indices.add(closest_idx)  # Mark the row as used\n",
    "        return filtered_df.loc[closest_idx]\n",
    "\n",
    "    # Apply the helper function row-wise\n",
    "    closest_rows = hv_task_df.apply(\n",
    "        lambda row: find_closest_date_unique(row, hv_in_bw_df), axis=1\n",
    "    )\n",
    "    \n",
    "    # Convert the results into a DataFrame\n",
    "   # closest_rows_df = pd.DataFrame(closest_rows.tolist(), index=hv_task_df.index)\n",
    "\n",
    "    # Merge the original `zv_task_df` with `closest_rows_df`\n",
    "    merged_bw_hv_df = hv_task_df.merge(closest_rows, left_index=True, right_index=True, suffixes=('', '_closest'))\n",
    "\n",
    "    # add column for date diff \n",
    "    merged_bw_hv_df['bw_hv_abs_date_diff'] = abs(merged_bw_hv_df['visit_date'] - merged_bw_hv_df['visit_date_video'])\n",
    "    \n",
    "    # check same ID for each row \n",
    "    print('mismatched home video vs brainwalk id')\n",
    "    print(sum(merged_bw_hv_df['id_video'] != merged_bw_hv_df['bw_id']))\n",
    "    \n",
    "    return merged_bw_hv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52986d6-49e3-4e4f-969e-cbef4138d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df input should be merged df - both video and bw data \n",
    "\n",
    "def print_video_counts(df):\n",
    "    # number of zeno videos and participants included \n",
    "    print('total videos - df length: ' + \n",
    "          str(len(df))) \n",
    "\n",
    "    print('unique demographic_diagnosis in df: ' + \n",
    "         str(pd.unique(df['demographic_diagnosis'])))\n",
    "    \n",
    "    print('num videos with demographic_diagnosis == HC: ' + \n",
    "         str(len(df[df['demographic_diagnosis'] == 'HC']))) \n",
    "\n",
    "    print('num videos demographic_diagnosis == MS: ' + \n",
    "         str(len(df[df['demographic_diagnosis'] == 'MS']))) \n",
    "\n",
    "    print('------')\n",
    "\n",
    "    print('unique id_video (participants) in df: ' + \n",
    "          str(len(pd.unique(df['id_video'])))) \n",
    "\n",
    "    print('num participants with demographic_diagnosis == HC: ' + \n",
    "         str(len(pd.unique(df['id_video'][df['demographic_diagnosis'] == 'HC'])))) \n",
    "    \n",
    "    print('num participants demographic_diagnosis == MS: ' + \n",
    "         str(len(pd.unique(df['id_video'][df['demographic_diagnosis'] == 'MS']))))\n",
    "\n",
    "    print('------') \n",
    "    \n",
    "    print('number of participants with multiple videos in dataset: ' + \n",
    "         str(df['id_video'][df['id_video'].duplicated()].nunique()))\n",
    "\n",
    "    print('number of participants with one video: ' + \n",
    "          str((df['id_video'].value_counts() == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230ebae8-f41c-46c6-8731-d9f7a0139164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to check \n",
    "    # string, either - PWS, FW, t25fw, or edss \n",
    "\n",
    "def drop_cols_missing_data(df, cols_to_check):\n",
    "    # drop row if all PWS mat vars are nan\n",
    "    if cols_to_check == 'pws': \n",
    "        subset_columns = ['PWS_stridetimesecmean',\n",
    "                          'PWS_stridetimeseccv',\n",
    "                          'PWS_cadencestepsminmean',\n",
    "                          'PWS_totaldsupportmean',\n",
    "                          'PWS_singlesupportmean', \n",
    "                          'PWS_totaldsupportratiolr',\n",
    "                          'PWS_singlesupportratiolr',\n",
    "                          'PWS_stridewidthcmmean', \n",
    "                          'PWS_stridewidthcmsd']\n",
    "\n",
    "    # drop row if all FW mat vars are nan \n",
    "    elif cols_to_check == 'fw':\n",
    "        subset_columns = ['FW_stridetimesecmean',\n",
    "                          'FW_stridetimeseccv',\n",
    "                          'FW_cadencestepsminmean',\n",
    "                          'FW_totaldsupportmean',\n",
    "                          'FW_singlesupportmean', \n",
    "                          'FW_totaldsupportratiolr',\n",
    "                          'FW_singlesupportratiolr',\n",
    "                          'FW_stridewidthcmmean', \n",
    "                          'FW_stridewidthcmsd']\n",
    "        \n",
    "    # drop row if edss is nan\n",
    "    elif cols_to_check == 'edss':\n",
    "        subset_columns = ['bingoEHR_EDSS_measure_value']\n",
    "\n",
    "    # drop row is tw5fw is nan \n",
    "    elif cols_to_check == 't25fw':\n",
    "        subset_columns = ['msfcEHR_T25FW SPEED AVG']\n",
    "\n",
    "    df_missing_rows_dropped = df.dropna(axis = 0, \n",
    "                                        how = 'all',\n",
    "                                        subset = subset_columns)\n",
    "\n",
    "    return df_missing_rows_dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeada4be-d309-47a9-a0a3-69ad6eabb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normality: histograms and shapiro test \n",
    "def hist_and_shapiro(df, hist_out_path): \n",
    "    results = []\n",
    "    histogram_folder = os.path.join(hist_out_path, 'histograms')\n",
    "    if not os.path.exists(histogram_folder):\n",
    "        os.makedirs(histogram_folder)\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'float64':\n",
    "            # histogram \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(df[column], bins=30, color='skyblue', edgecolor='black')\n",
    "            plt.title(f'Histogram of {column}')\n",
    "            plt.xlabel(column)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(histogram_folder, f'{column}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # shapiro wilks test \n",
    "            # check for missing data \n",
    "            non_missing_data = df[column].dropna()\n",
    "            n = len(non_missing_data) \n",
    "\n",
    "            if n > 3: \n",
    "                # Perform Shapiro-Wilk test\n",
    "                stat, p_value = stats.shapiro(non_missing_data)  \n",
    "            else: \n",
    "                stat = np.nan\n",
    "                p_value = np.nan \n",
    "            \n",
    "            results.append({'Column': column, 'non_missing_observations': n, 'Statistic': stat, 'P-value': p_value})\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    shapiro_results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # if p value less than 0.05, data is not normally distributed \n",
    "    shapiro_results_df['normal'] = shapiro_results_df['P-value'].apply(lambda x: 'no' if x < .05 else 'yes')\n",
    "    shapiro_results_df['test'] = shapiro_results_df['P-value'].apply(lambda x: 'spearman' if x < .05 else 'pearson')\n",
    "    shapiro_results_df.round(3)\n",
    "    \n",
    "    return(shapiro_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db504ab-edfd-4d96-afb1-525f5f8dfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of same metrics in each \n",
    "\n",
    "def metric_correlation(df, video_columns, bw_columns, output_folder_path): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    # create empty list to store results \n",
    "    corr_results_all = [] \n",
    "    clean_df = pd.DataFrame() \n",
    "    \n",
    "    for metric_i, current_metric in enumerate(video_columns): \n",
    "        current_vid_col = video_columns[metric_i]\n",
    "        current_bw_col = bw_columns[metric_i]\n",
    "\n",
    "        # Drop rows with NaN values in either column - required to run spearman r \n",
    "        clean_df = df.dropna(subset=[current_vid_col, current_bw_col])\n",
    "        \n",
    "        # plot \n",
    "        sns.lmplot(x = current_bw_col, y = current_vid_col, data = clean_df, ci = None)\n",
    "        # Set the x and y axis limits to the same range\n",
    "        plt.axis('square')  \n",
    "        min_val = min(clean_df[current_vid_col].min(), clean_df[current_vid_col].min())  \n",
    "        max_val = max(clean_df[current_vid_col].max(), clean_df[current_vid_col].max())  \n",
    "        plt.xlim(min_val, max_val)\n",
    "        plt.ylim(min_val, max_val) \n",
    "        plt.savefig(os.path.join(output_folder_path, str(current_vid_col + '_vs_' + current_bw_col + '.png')))\n",
    "        plt.close()\n",
    "\n",
    "        # run spearman correlation and append   \n",
    "        statistic, p_value = stats.spearmanr(clean_df[current_bw_col], clean_df[current_vid_col])\n",
    "        corr_results_all.append({'bw_column': current_bw_col, \n",
    "                                 'video_column': current_vid_col, \n",
    "                                 'corr_method': 'spearman' , \n",
    "                                 'rs': statistic, \n",
    "                                 'p_value' : p_value,\n",
    "                                 'n observations': len(clean_df)})\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    corr_results_df = pd.DataFrame(corr_results_all)\n",
    "    corr_results_df = corr_results_df.round(3)\n",
    "\n",
    "    return corr_results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df230d94-7571-4f14-9679-ca67a840df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same columns as metric correlations \n",
    "\n",
    "def calculate_metric_mean_error(df, video_columns, bw_columns, units, output_folder_path):\n",
    "    # one dot = participant \n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path) \n",
    "        \n",
    "    mean_error_all = [] \n",
    "\n",
    "    for metric_i, current_metric in enumerate(video_columns): \n",
    "        current_vid_col = video_columns[metric_i]\n",
    "        current_bw_col = bw_columns[metric_i]\n",
    "        current_unit = units[metric_i]\n",
    "\n",
    "        # Drop rows with NaN values in either column \n",
    "        clean_df = df.dropna(subset=[current_vid_col, current_bw_col])\n",
    "\n",
    "        current_metric_diff = clean_df[current_bw_col] - clean_df[current_vid_col]\n",
    "        current_mean_diff = current_metric_diff.mean()\n",
    "        current_abs_mean_diff = abs(current_metric_diff).mean()\n",
    "\n",
    "        # calculate mean ground truth data \n",
    "        bw_mean = clean_df[current_bw_col].mean()\n",
    "        mean_err_per = (current_mean_diff / bw_mean) * 100 \n",
    "        mae_per = (current_abs_mean_diff / bw_mean) * 100 \n",
    "\n",
    "        # plot \n",
    "        fig, ax1 = plt.subplots()\n",
    "        sns.boxplot(y=current_metric_diff, ax=ax1)\n",
    "        ax1.set_title(current_bw_col + ' - ' + current_vid_col)\n",
    "        # center plot at zero\n",
    "        ymin, ymax = plt.ylim()\n",
    "        plt.ylim(min(ymin, -ymax), max(ymax, -ymin))\n",
    "        plt.ylabel(current_unit)\n",
    "        # add line at zero\n",
    "        plt.axhline(y=0, color='grey', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder_path, str(current_vid_col + '_vs_' + current_bw_col + '_diff_box.png')))\n",
    "        plt.close()\n",
    "\n",
    "        # mean difference \n",
    "        mean_error_all.append({'bw_column': current_bw_col, \n",
    "                               'video_column': current_vid_col,\n",
    "                               'n' : len(clean_df), \n",
    "                               'bw_metric_mean' : bw_mean,\n",
    "                               'mean_error': current_mean_diff, \n",
    "                               'mean_abs_error' : current_abs_mean_diff, \n",
    "                               'mean_error_%_of_mean' : mean_err_per,\n",
    "                               'mae_%_of_mean' : mae_per})\n",
    "\n",
    "    \n",
    "     # Create DataFrame with results\n",
    "    mean_error_df = pd.DataFrame(mean_error_all)\n",
    "    mean_error_df = mean_error_df.round(3)\n",
    "    \n",
    "    return mean_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0813fa-e903-4806-ab12-771b8746d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same columns as metric correlation \n",
    "\n",
    "def bland_altman_plot(df, video_columns, bw_columns, units, output_folder_path):\n",
    "     \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    for metric_i, current_metric in enumerate(video_columns): \n",
    "        current_bw_col = bw_columns[metric_i]\n",
    "        current_vid_col = video_columns[metric_i]\n",
    "        current_unit = current_unit = units[metric_i]\n",
    "\n",
    "        clean_df = df.dropna(subset=[current_vid_col, current_bw_col])\n",
    "\n",
    "    \n",
    "        # Compute the mean and the difference\n",
    "        mean_measurements = (clean_df[current_bw_col] + clean_df[current_vid_col]) / 2\n",
    "        diff_measurements = clean_df[current_bw_col] - clean_df[current_vid_col]  # Difference between measurements\n",
    "\n",
    "        # Mean difference and standard deviation of the difference\n",
    "        mean_diff = np.mean(diff_measurements)\n",
    "        std_diff = np.std(diff_measurements)\n",
    "\n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(mean_measurements, diff_measurements, alpha=0.5)\n",
    "    \n",
    "        # Add mean difference line and limits of agreement (±1.96*std)\n",
    "        plt.axhline(mean_diff, color='black', linestyle='--', label=f'Mean diff: {mean_diff:.2f}')\n",
    "        plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=f'+1.96 SD: {mean_diff + 1.96 * std_diff:.2f}')\n",
    "        plt.axhline(mean_diff - 1.96 * std_diff, color='blue', linestyle='--', label=f'-1.96 SD: {mean_diff - 1.96 * std_diff:.2f}')\n",
    "        plt.axhline(y=0, color='grey', linestyle='--')\n",
    "    \n",
    "        # Labels and title\n",
    "        plt.xlabel('Mean of Zeno Mat vs Video Pose Metric (' + current_unit + ')') \n",
    "        plt.ylabel('Zeno mat - Video Pose Metric (' + current_unit + ')')\n",
    "        plt.title(current_bw_col + ' vs ' + current_vid_col)\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_folder_path,  str(current_vid_col + '_vs_' + current_bw_col + '_blandalt.png')))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d6d762-9181-49a0-8cd4-a2f46fa74e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation with clinical outcomes \n",
    "def outcome_correlation(df, output_folder_path, video_task_str, outcome_str): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # drop date time columns \n",
    "    if 'bw_hv_abs_date_diff' in df.columns:\n",
    "        df = df.drop(columns=['bw_hv_abs_date_diff'])\n",
    "        \n",
    "    # drop nonnumeric columns \n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    ordinal_cols = df.select_dtypes(include=['category']).columns\n",
    "\n",
    "    # Keep only numeric and ordinal columns\n",
    "    df_num = df[numeric_cols.union(ordinal_cols)]\n",
    "\n",
    "    # Create an empty DataFrame to store the Spearman correlation coefficients\n",
    "    n_cols = df_num.shape[1]\n",
    "\n",
    "    corr_matrix = pd.DataFrame(np.zeros((n_cols, n_cols)), columns=df_num.columns, index=df_num.columns)\n",
    "    pvalue_matrix = pd.DataFrame(np.zeros((n_cols, n_cols)), columns=df_num.columns, index=df_num.columns)\n",
    "    n_videos_matrix = pd.DataFrame(np.zeros((n_cols, n_cols)), columns=df_num.columns, index=df_num.columns)\n",
    "    \n",
    "    # Compute Spearman correlation for each pair of columns\n",
    "    for col1 in df_num.columns:\n",
    "        for col2 in df_num.columns:\n",
    "            # drop rows if col1 and col2 are both nan\n",
    "            df_num_clean = df.dropna(subset=[col1, col2])\n",
    "\n",
    "            # spearman correlation \n",
    "            corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
    "\n",
    "\n",
    "            # save results in matrix \n",
    "            corr_matrix.loc[col1, col2] = corr\n",
    "            pvalue_matrix.loc[col1, col2] = p_value\n",
    "            n_videos_matrix.loc[col1, col2] = len(df_num_clean) # number of rows with data for both columns \n",
    "\n",
    "    #  Plot and save the heatmap \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Spearman Rank Correlation Heatmap\")\n",
    "    plt.savefig(os.path.join(output_folder_path,  video_task_str + '_' + outcome_str + '_heatmap.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # select specific columns from the three matrices and concatenate into single data frame \n",
    "    if outcome_str == 'edss': \n",
    "        corr_df = pd.concat([corr_matrix['bingoEHR_EDSS_measure_value'],\n",
    "                             pvalue_matrix['bingoEHR_EDSS_measure_value'],\n",
    "                             n_videos_matrix['bingoEHR_EDSS_measure_value'],\n",
    "                             corr_matrix['edss_severity_cat'],\n",
    "                             pvalue_matrix['edss_severity_cat'],\n",
    "                             n_videos_matrix['edss_severity_cat']],\n",
    "                            axis = 1)\n",
    "        \n",
    "        corr_df.columns = ['edss_score_statistic', 'edss_score_p_value', 'edss_score_n_videos',\n",
    "                           'edss_severity_cat_statistic', 'edss_severity_cat_p_value', 'edss_severity_n_videos']\n",
    "\n",
    "    elif outcome_str == 't25fw': \n",
    "        corr_df = pd.concat([corr_matrix['msfcEHR_T25FW SPEED AVG'],\n",
    "                             pvalue_matrix['msfcEHR_T25FW SPEED AVG'],\n",
    "                             n_videos_matrix['msfcEHR_T25FW SPEED AVG']], \n",
    "                     axis = 1)\n",
    "        \n",
    "        corr_df.columns = ['t25fw_correlation_statistic', 't25fw_correlation_p_value', 't25fw_correlation_n_videos']\n",
    "\n",
    "\n",
    "    corr_df = corr_df.round(3)\n",
    "\n",
    "    return corr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a60147-243e-44dc-91f4-8695c3249ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c9df0d-dcf5-4619-81c0-f74a6b640492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30facf65-f1fd-4b9c-876b-68424a297269",
   "metadata": {},
   "source": [
    "# Run analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f2f84-10a5-4061-b70b-49e3cd0342ce",
   "metadata": {},
   "source": [
    "## Manually update output folder, load data, and format columns \n",
    "\n",
    "To do: loading variables \n",
    "- Check output folders consistent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a80658de-3535-40fb-ba83-ba9946b4d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folders \n",
    "out_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis\\002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04277eab-b4c4-4f02-a0c5-b22fcad3b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load variables of interest \n",
    "\n",
    "# zeno video metrics \n",
    "zv_df = pd.read_csv(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_outputs_002\\gait_bw_zeno_outputs_002_pose_metrics_all.csv',\n",
    "                     index_col = 0)\n",
    "\n",
    "# home video metrics \n",
    "hv_df = pd.read_csv(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_home_outputs_002\\gait_bw_home_outputs_002_pose_metrics_all.csv',\n",
    "                     index_col = 0)\n",
    "\n",
    "\n",
    "# BW and zeno mat metrics \n",
    "# decrypted file - may need to decrypt again if says file doesn't exit \n",
    "# copied file saved in Megan Project folder in Brainwalk box. \n",
    "# if issues decrypting, try copying original file again and then decrypting \n",
    "bw_df = pd.read_excel(r'C:\\Users\\mmccu\\AppData\\Local\\Temp\\ccsecure\\2024_10_15_BrainWalk_AllData_Long_MM.xlsx', \n",
    "                     index_col = None, \n",
    "                     usecols = ['bw_id', 'record_id', 'visit_date', 'demoEHR_DiseaseDuration',\n",
    "                                'demoEHR_GENDER', 'demoEHR_Age', 'demographic_diagnosis', 'bingoEHR_DX_MS DX', 'demoEHR_REC_1',\t\n",
    "                                'demoEHR_REC_2', 'bingoEHR_EDSS_measure_value', 'msfcEHR_T25FW SPEED AVG',\n",
    "                                'falls_number', 'falls_since_lastsurvey', 'near_falls', 'near_falls_no', \n",
    "                                'strength_lt_leg', 'strength_max', 'strength_rt_leg', 'sum_total_scores',\n",
    "                                'PWS_stridetimesecmean', 'PWS_stridetimeseccv','PWS_cadencestepsminmean','PWS_totaldsupportmean', \n",
    "                                'PWS_singlesupportmean','PWS_totaldsupportratiolr', 'PWS_singlesupportratiolr', \n",
    "                                'PWS_stridewidthcmmean','PWS_stridewidthcmsd',\n",
    "                                'FW_stridetimesecmean', 'FW_stridetimeseccv','FW_cadencestepsminmean','FW_totaldsupportmean', \n",
    "                                'FW_singlesupportmean','FW_totaldsupportratiolr', 'FW_singlesupportratiolr', \n",
    "                                'FW_stridewidthcmmean','FW_stridewidthcmsd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d57ad9-f35e-4a54-91c8-9ae0aa1698fb",
   "metadata": {},
   "source": [
    "### To-do in updating col names \n",
    "- in later scripts: control find id_video vs id_video or id_hv, same for visit date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c9442af-6e45-4706-a7cf-0ef07dfb49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename zeno video variables \n",
    "# ad zv to all zeno volumn names \n",
    "zv_df = zv_df.add_suffix('_zv')\n",
    "\n",
    "# add bw id and video date to zv df \n",
    "zv_df['id_video'] = zv_df['id_date_pose_zv'].str.extract(r'(BW-\\d{4})')\n",
    "zv_df['visit_date_video'] = zv_df['id_date_pose_zv'].str[8:]\n",
    "zv_df['visit_date_video'] = pd.to_datetime(zv_df['visit_date_video'].str.replace('_', '-'), format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc5f4877-573c-4051-b1bc-e26cd7d723d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_11948\\3253129783.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  hv_df['visit_date_video'] = pd.to_datetime(hv_df['visit_date_video'], errors = 'coerce')\n"
     ]
    }
   ],
   "source": [
    "# add hv to all home column names \n",
    "hv_df = hv_df.add_suffix('_hv')\n",
    "\n",
    "# add bw id and video date to hv df \n",
    "hv_df['id_video'] = hv_df['id_date_pose_hv'].str.extract(r'(BW-\\d{4})')\n",
    "hv_df['visit_date_video'] = hv_df['id_date_pose_hv'].str[8:]\n",
    "hv_df['visit_date_video'] = pd.to_datetime(hv_df['visit_date_video'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e6a3716-a614-44d9-9f47-e6456a225ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bw_id</th>\n",
       "      <th>record_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>demoEHR_DiseaseDuration</th>\n",
       "      <th>demoEHR_GENDER</th>\n",
       "      <th>demoEHR_Age</th>\n",
       "      <th>bingoEHR_DX_MS DX</th>\n",
       "      <th>demoEHR_REC_1</th>\n",
       "      <th>demoEHR_REC_2</th>\n",
       "      <th>bingoEHR_EDSS_measure_value</th>\n",
       "      <th>...</th>\n",
       "      <th>near_falls</th>\n",
       "      <th>near_falls_no</th>\n",
       "      <th>strength_lt_leg</th>\n",
       "      <th>strength_max</th>\n",
       "      <th>strength_rt_leg</th>\n",
       "      <th>sum_total_scores</th>\n",
       "      <th>edss_severity_num</th>\n",
       "      <th>edss_severity_cat</th>\n",
       "      <th>t25fw_group_num</th>\n",
       "      <th>t25fw_group_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BW-0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BW-0006</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>64.0</td>\n",
       "      <td>PPMS (Primary-progressive Multiple Sclerosis)</td>\n",
       "      <td>WhiteAsian</td>\n",
       "      <td>WhiteNonHispanic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BW-0086</td>\n",
       "      <td>100</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BW-0087</td>\n",
       "      <td>101</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BW-0088</td>\n",
       "      <td>102</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>pending</td>\n",
       "      <td>Other/Decline/Unknown</td>\n",
       "      <td>Other/Decline/Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6_to_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bw_id  record_id visit_date  demoEHR_DiseaseDuration demoEHR_GENDER  \\\n",
       "0  BW-0001          1 2022-08-26                      NaN            NaN   \n",
       "1  BW-0006         10 2022-09-26                     17.0         Female   \n",
       "2  BW-0086        100 2023-08-08                      NaN            NaN   \n",
       "3  BW-0087        101 2023-01-18                      NaN            NaN   \n",
       "4  BW-0088        102 2023-01-23                      0.0         Female   \n",
       "\n",
       "   demoEHR_Age                              bingoEHR_DX_MS DX  \\\n",
       "0          NaN                                            NaN   \n",
       "1         64.0  PPMS (Primary-progressive Multiple Sclerosis)   \n",
       "2          NaN                                            NaN   \n",
       "3          NaN                                            NaN   \n",
       "4         33.0                                        pending   \n",
       "\n",
       "           demoEHR_REC_1          demoEHR_REC_2  bingoEHR_EDSS_measure_value  \\\n",
       "0                    NaN                    NaN                          NaN   \n",
       "1             WhiteAsian       WhiteNonHispanic                          3.0   \n",
       "2                    NaN                    NaN                          NaN   \n",
       "3                    NaN                    NaN                          NaN   \n",
       "4  Other/Decline/Unknown  Other/Decline/Unknown                          NaN   \n",
       "\n",
       "   ...  near_falls  near_falls_no  strength_lt_leg  strength_max  \\\n",
       "0  ...         NaN            NaN              NaN           NaN   \n",
       "1  ...          No            NaN              NaN           NaN   \n",
       "2  ...          No            NaN              NaN           NaN   \n",
       "3  ...         Yes            5.0              NaN           NaN   \n",
       "4  ...         Yes            NaN              NaN           NaN   \n",
       "\n",
       "   strength_rt_leg  sum_total_scores  edss_severity_num  edss_severity_cat  \\\n",
       "0              NaN              46.0                NaN                NaN   \n",
       "1              NaN              46.0                2.0           moderate   \n",
       "2              NaN              46.0                NaN                NaN   \n",
       "3              NaN              46.0                NaN                NaN   \n",
       "4              NaN              46.0                NaN                NaN   \n",
       "\n",
       "   t25fw_group_num  t25fw_group_cat  \n",
       "0              NaN              NaN  \n",
       "1              1.0          under_6  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              2.0           6_to_8  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add columns for ordinal EDSS severity and t25fw \n",
    "bw_df['edss_severity_num'], bw_df['edss_severity_cat'] = zip(*bw_df['bingoEHR_EDSS_measure_value'].apply(categorize_edss))\n",
    "bw_df['edss_severity_cat'] = pd.Categorical(bw_df['edss_severity_cat'], categories=[\"mild\", \"moderate\", \"severe\"], ordered=True)\n",
    "\n",
    "# Apply the function to create new columns\n",
    "bw_df['t25fw_group_num'], bw_df['t25fw_group_cat'] = zip(*bw_df['msfcEHR_T25FW SPEED AVG'].apply(categorize_t25fw))\n",
    "bw_df['t25fw_group_cat'] = pd.Categorical(bw_df['t25fw_group_cat'], categories=[\"under_6\", \"6_to_8\", \"over_8\"], ordered=True)\n",
    "bw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c51e9-2601-43e1-883b-b96ed7971ed5",
   "metadata": {},
   "source": [
    "### Merge video data with brainwalk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "945d66a2-d05a-4679-b902-895fe28063ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm all one task\n",
      "['gait_vertical_PWS_1']\n",
      "total zeno videos\n",
      "256\n",
      "total bw rows with id in video dataset\n",
      "288\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0010\n",
      "2022-10-05 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0022\n",
      "2023-04-18 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0031\n",
      "2023-04-21 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2024-04-08 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0063\n",
      "2024-07-15 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0067\n",
      "2024-01-09 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0092\n",
      "2024-08-19 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0110\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0121\n",
      "2022-07-20 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0162\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0166\n",
      "2024-06-17 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0277\n",
      "2024-08-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0322\n",
      "2024-06-10 00:00:00\n",
      "mismatched zeno video vs brainwalk id\n",
      "0\n",
      "mismatched zeno video vs brainwalk date\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# zeno videos - preferred walking speed \n",
    "bw_zv_pws_df = merge_bw_zv(bw_df, zv_df, 'gait_vertical_PWS_1', out_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b89bbf1-5ddb-447e-abbe-e1b8ca7ecdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- print bw_zv_pws_df video counts ----\n",
      "total videos - df length: 243\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 34\n",
      "num videos demographic_diagnosis == MS: 209\n",
      "------\n",
      "unique id_video (participants) in df: 179\n",
      "num participants with demographic_diagnosis == HC: 33\n",
      "num participants demographic_diagnosis == MS: 146\n",
      "------\n",
      "number of participants with multiple videos in dataset: 62\n",
      "number of participants with one video: 117\n"
     ]
    }
   ],
   "source": [
    "print('----- print bw_zv_pws_df video counts ----')\n",
    "print_video_counts(bw_zv_pws_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80492797-2579-463c-83e1-7b32ca6e7aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm all one task\n",
      "['gait_vertical_FW_1']\n",
      "total zeno videos\n",
      "246\n",
      "total bw rows with id in video dataset\n",
      "283\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0010\n",
      "2022-10-05 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0031\n",
      "2023-04-21 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0036\n",
      "2024-04-02 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2023-05-02 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2024-04-08 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0063\n",
      "2024-07-15 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0067\n",
      "2024-01-09 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0110\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0162\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0166\n",
      "2024-06-17 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0277\n",
      "2024-08-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0322\n",
      "2024-06-10 00:00:00\n",
      "mismatched zeno video vs brainwalk id\n",
      "0\n",
      "mismatched zeno video vs brainwalk date\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# zeno videos - fast walking speed \n",
    "bw_zv_fw_df = merge_bw_zv(bw_df, zv_df, 'gait_vertical_FW_1', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5697b901-6db0-4ba7-b5df-855211d1cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- print bw_zv_fw_df video counts ----\n",
      "total videos - df length: 234\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 37\n",
      "num videos demographic_diagnosis == MS: 197\n",
      "------\n",
      "unique id_video (participants) in df: 177\n",
      "num participants with demographic_diagnosis == HC: 35\n",
      "num participants demographic_diagnosis == MS: 142\n",
      "------\n",
      "number of participants with multiple videos in dataset: 56\n",
      "number of participants with one video: 121\n"
     ]
    }
   ],
   "source": [
    "print('---- print bw_zv_fw_df video counts ----')\n",
    "print_video_counts(bw_zv_fw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7a73db1-4a98-42d1-949a-b78f11228d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm all one task\n",
      "['gait_vertical_right']\n",
      "total home videos\n",
      "26\n",
      "total bw rows with id in video dataset\n",
      "43\n",
      "mismatched home video vs brainwalk id\n",
      "0\n",
      "confirm all one task\n",
      "['gait_vertical_left']\n",
      "total home videos\n",
      "25\n",
      "total bw rows with id in video dataset\n",
      "42\n",
      "mismatched home video vs brainwalk id\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# home videos - merge home videos and BW \n",
    "bw_hv_r_pws_df = merge_bw_hv(bw_df, hv_df, 'gait_vertical_right', out_path)\n",
    "bw_hv_l_pws_df = merge_bw_hv(bw_df, hv_df, 'gait_vertical_left', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57443032-f6b4-400d-855d-54e5e08a0751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- print bw_hv_pws_df video counts ----\n",
      "total videos - df length: 51\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 51\n",
      "------\n",
      "unique id_video (participants) in df: 23\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 23\n",
      "------\n",
      "number of participants with multiple videos in dataset: 22\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# concatenate right and left \n",
    "bw_hv_pws_df = pd.concat([bw_hv_r_pws_df, bw_hv_l_pws_df], axis = 0).sort_index()\n",
    "bw_hv_pws_df['edss_severity_cat'] = pd.Categorical(bw_hv_pws_df['edss_severity_cat'], categories=[\"mild\", \"moderate\", \"severe\"], ordered=True)\n",
    "print('---- print bw_hv_pws_df video counts ----')\n",
    "print_video_counts(bw_hv_pws_df)\n",
    "\n",
    "# save merged df  \n",
    "bw_hv_pws_df.to_csv(os.path.join(out_path,  'hv_bw_merged.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8692bd80-7ddd-44db-a878-9fa05717f99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_date_pose_hv</th>\n",
       "      <th>video_id_date_name_pose_hv</th>\n",
       "      <th>task_pose_hv</th>\n",
       "      <th>stride_time_mean_sec_pose_hv</th>\n",
       "      <th>stride_time_median_sec_pose_hv</th>\n",
       "      <th>stride_time_std_pose_hv</th>\n",
       "      <th>stride_time_cv_pose_hv</th>\n",
       "      <th>stride_time_max_pose_hv</th>\n",
       "      <th>stride_time_min_pose_hv</th>\n",
       "      <th>mean_cadence_step_per_min_pose_hv</th>\n",
       "      <th>...</th>\n",
       "      <th>near_falls_no</th>\n",
       "      <th>strength_lt_leg</th>\n",
       "      <th>strength_max</th>\n",
       "      <th>strength_rt_leg</th>\n",
       "      <th>sum_total_scores</th>\n",
       "      <th>edss_severity_num</th>\n",
       "      <th>edss_severity_cat</th>\n",
       "      <th>t25fw_group_num</th>\n",
       "      <th>t25fw_group_cat</th>\n",
       "      <th>bw_hv_abs_date_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BW-0018\\10-24-23</td>\n",
       "      <td>gait_vertical_left_BW-0018_10-24-23</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.171</td>\n",
       "      <td>16.937</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.767</td>\n",
       "      <td>113.684</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BW-0018\\10-24-23</td>\n",
       "      <td>gait_vertical_right_BW-0018_10-24-23</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BW-0023\\05-05-23</td>\n",
       "      <td>gait_vertical_left_BW-0023_05-05-23</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>1.027</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.066</td>\n",
       "      <td>6.461</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>99.315</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>171 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BW-0023\\05-05-23</td>\n",
       "      <td>gait_vertical_right_BW-0023_05-05-23</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>1.070</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.098</td>\n",
       "      <td>9.114</td>\n",
       "      <td>1.300</td>\n",
       "      <td>0.933</td>\n",
       "      <td>93.532</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>171 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BW-0023\\10-23-23</td>\n",
       "      <td>gait_vertical_left_BW-0023_10-23-23</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.087</td>\n",
       "      <td>8.739</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.867</td>\n",
       "      <td>96.769</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_date_pose_hv            video_id_date_name_pose_hv  \\\n",
       "0  BW-0018\\10-24-23   gait_vertical_left_BW-0018_10-24-23   \n",
       "1  BW-0018\\10-24-23  gait_vertical_right_BW-0018_10-24-23   \n",
       "2  BW-0023\\05-05-23   gait_vertical_left_BW-0023_05-05-23   \n",
       "3  BW-0023\\05-05-23  gait_vertical_right_BW-0023_05-05-23   \n",
       "4  BW-0023\\10-23-23   gait_vertical_left_BW-0023_10-23-23   \n",
       "\n",
       "          task_pose_hv  stride_time_mean_sec_pose_hv  \\\n",
       "0   gait_vertical_left                         1.008   \n",
       "1  gait_vertical_right                           NaN   \n",
       "2   gait_vertical_left                         1.027   \n",
       "3  gait_vertical_right                         1.070   \n",
       "4   gait_vertical_left                         0.998   \n",
       "\n",
       "   stride_time_median_sec_pose_hv  stride_time_std_pose_hv  \\\n",
       "0                           1.050                    0.171   \n",
       "1                             NaN                      NaN   \n",
       "2                           1.033                    0.066   \n",
       "3                           1.033                    0.098   \n",
       "4                           0.983                    0.087   \n",
       "\n",
       "   stride_time_cv_pose_hv  stride_time_max_pose_hv  stride_time_min_pose_hv  \\\n",
       "0                  16.937                    1.167                    0.767   \n",
       "1                     NaN                      NaN                      NaN   \n",
       "2                   6.461                    1.167                    0.833   \n",
       "3                   9.114                    1.300                    0.933   \n",
       "4                   8.739                    1.100                    0.867   \n",
       "\n",
       "   mean_cadence_step_per_min_pose_hv  ...  near_falls_no  \\\n",
       "0                            113.684  ...            NaN   \n",
       "1                             50.000  ...            NaN   \n",
       "2                             99.315  ...            2.0   \n",
       "3                             93.532  ...            2.0   \n",
       "4                             96.769  ...            2.0   \n",
       "\n",
       "                            strength_lt_leg  strength_max  \\\n",
       "0  I can easily raise it and keep it raised           0.0   \n",
       "1  I can easily raise it and keep it raised           0.0   \n",
       "2  I can easily raise it and keep it raised           0.0   \n",
       "3  I can easily raise it and keep it raised           0.0   \n",
       "4  I can easily raise it and keep it raised           0.0   \n",
       "\n",
       "                            strength_rt_leg  sum_total_scores  \\\n",
       "0  I can easily raise it and keep it raised               2.0   \n",
       "1  I can easily raise it and keep it raised               2.0   \n",
       "2  I can easily raise it and keep it raised              15.0   \n",
       "3  I can easily raise it and keep it raised              15.0   \n",
       "4  I can easily raise it and keep it raised              15.0   \n",
       "\n",
       "   edss_severity_num  edss_severity_cat  t25fw_group_num  t25fw_group_cat  \\\n",
       "0                2.0           moderate              1.0          under_6   \n",
       "1                2.0           moderate              1.0          under_6   \n",
       "2                2.0           moderate              1.0          under_6   \n",
       "3                2.0           moderate              1.0          under_6   \n",
       "4                2.0           moderate              1.0          under_6   \n",
       "\n",
       "   bw_hv_abs_date_diff  \n",
       "0               0 days  \n",
       "1               0 days  \n",
       "2             171 days  \n",
       "3             171 days  \n",
       "4               0 days  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_hv_pws_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078571e-6f63-40df-8231-e26521116935",
   "metadata": {},
   "source": [
    "### Drop rows with missing brainwalk mat data \n",
    "- use these data frames when comparing the video metrics to mat metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ecffbf2-0cf8-41f6-b572-1d24706d860f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 239\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 34\n",
      "num videos demographic_diagnosis == MS: 205\n",
      "------\n",
      "unique id_video (participants) in df: 177\n",
      "num participants with demographic_diagnosis == HC: 33\n",
      "num participants demographic_diagnosis == MS: 144\n",
      "------\n",
      "number of participants with multiple videos in dataset: 60\n",
      "number of participants with one video: 117\n"
     ]
    }
   ],
   "source": [
    "# zeno preferred walk - participants with pws videos and pws mat metrics\n",
    "bw_zv_pws_df_2 = drop_cols_missing_data(bw_zv_pws_df, cols_to_check = 'pws')\n",
    "print_video_counts(bw_zv_pws_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "590de1d6-a836-428b-a45b-e8f6459b2768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 231\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 37\n",
      "num videos demographic_diagnosis == MS: 194\n",
      "------\n",
      "unique id_video (participants) in df: 174\n",
      "num participants with demographic_diagnosis == HC: 35\n",
      "num participants demographic_diagnosis == MS: 139\n",
      "------\n",
      "number of participants with multiple videos in dataset: 56\n",
      "number of participants with one video: 118\n"
     ]
    }
   ],
   "source": [
    "# zeno fast walk - participants with FWS videos and fWS mat metrics\n",
    "bw_zv_fw_df_2 = drop_cols_missing_data(bw_zv_fw_df, cols_to_check = 'fw')\n",
    "print_video_counts(bw_zv_fw_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e748f27-660e-4a0a-b980-8cdf92ecdf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 45\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 45\n",
      "------\n",
      "unique id_video (participants) in df: 20\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 20\n",
      "------\n",
      "number of participants with multiple videos in dataset: 19\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and pws mat metrics \n",
    "bw_hv_pws_df_2 = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 'pws')\n",
    "print_video_counts(bw_hv_pws_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292152e6-9770-40cf-9963-777fc375253f",
   "metadata": {},
   "source": [
    "### Drop rows with missing brainwalk clinical outcomes measures \n",
    "- use these data frames when comparing video metrics to clinical outcomes (ie - exclude participants with missing edss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39702a4c-5609-4c36-a8c2-307e6b0e7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 148\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 148\n",
      "------\n",
      "unique id_video (participants) in df: 126\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 126\n",
      "------\n",
      "number of participants with multiple videos in dataset: 22\n",
      "number of participants with one video: 104\n"
     ]
    }
   ],
   "source": [
    "# zeno preferred walk - participants with pws videos and t25fw \n",
    "bw_zv_pws_t25fw_df = drop_cols_missing_data(bw_zv_pws_df, cols_to_check = 't25fw')\n",
    "print_video_counts(bw_zv_pws_t25fw_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f25ccac-ee2d-416b-b0f7-f9736d60e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 200\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 200\n",
      "------\n",
      "unique id_video (participants) in df: 139\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 139\n",
      "------\n",
      "number of participants with multiple videos in dataset: 59\n",
      "number of participants with one video: 80\n"
     ]
    }
   ],
   "source": [
    "# zeno preferred walk - participants with pws videos and edss \n",
    "bw_zv_pws_edss_df = drop_cols_missing_data(bw_zv_pws_df, cols_to_check = 'edss')\n",
    "print_video_counts(bw_zv_pws_edss_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1d436b6-bd47-494d-9f71-9049fd1117f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 146\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 146\n",
      "------\n",
      "unique id_video (participants) in df: 123\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 123\n",
      "------\n",
      "number of participants with multiple videos in dataset: 22\n",
      "number of participants with one video: 101\n"
     ]
    }
   ],
   "source": [
    "# zeno fast walk - participants with fw videos and t25fw \n",
    "bw_zv_fw_t25fw_df = drop_cols_missing_data(bw_zv_fw_df, cols_to_check = 't25fw')\n",
    "print_video_counts(bw_zv_fw_t25fw_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85152e92-513c-4d6c-989e-59bdfbe12740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 192\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 192\n",
      "------\n",
      "unique id_video (participants) in df: 138\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 138\n",
      "------\n",
      "number of participants with multiple videos in dataset: 53\n",
      "number of participants with one video: 85\n"
     ]
    }
   ],
   "source": [
    "# zeno fast walk - participants with fw videos and edss \n",
    "bw_zv_fw_edss_df = drop_cols_missing_data(bw_zv_fw_df, cols_to_check = 'edss')\n",
    "print_video_counts(bw_zv_fw_edss_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dbdbf45-15f0-4f6d-84c6-fa029c0e46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 47\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 47\n",
      "------\n",
      "unique id_video (participants) in df: 22\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 22\n",
      "------\n",
      "number of participants with multiple videos in dataset: 21\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and t25fw \n",
    "bw_hv_t25fw_df = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 't25fw')\n",
    "print_video_counts(bw_hv_t25fw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f26002b-15c2-4554-bf3e-1c8a6ddc238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 51\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 51\n",
      "------\n",
      "unique id_video (participants) in df: 23\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 23\n",
      "------\n",
      "number of participants with multiple videos in dataset: 22\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and edss \n",
    "bw_hv_edss_df = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 'edss')\n",
    "print_video_counts(bw_hv_edss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412d0bc-7044-4803-91d7-38b236e52d7c",
   "metadata": {},
   "source": [
    "## Correlation: Mat Metrics vs Video Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c052781-9a12-42b7-b5d0-f764d2ad38e4",
   "metadata": {},
   "source": [
    "### Check Normality and save histograms \n",
    "Checks normality and plots histogram for each column in dataframe where type == float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f0fe54-9164-4614-96ae-580d78826b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWS Zeno Videos - video of walk on mat \n",
    "hist_out_path_1 = (os.path.join(out_path, 'zv_vs_bw_pws_metric_correlation', 'check_normality'))\n",
    "if not os.path.exists(hist_out_path_1):\n",
    "    os.makedirs(hist_out_path_1)\n",
    "     \n",
    "bw_zv_pws_2_shapiro = hist_and_shapiro(bw_zv_pws_df_2, hist_out_path_1)\n",
    "\n",
    "# save in test normality folder\n",
    "bw_zv_pws_2_shapiro.to_csv(os.path.join(hist_out_path_1, 'zv_vs_bw_pws_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e064e87-a31a-4db8-93cc-7c3f1b711146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FWS Zeno Videos - video of walk on mat \n",
    "hist_out_path_2 = (os.path.join(out_path, 'zv_vs_bw_fw_metric_correlation', 'check_normality'))\n",
    "if not os.path.exists(hist_out_path_2):\n",
    "    os.makedirs(hist_out_path_2)\n",
    "\n",
    "bw_zv_fw_2_shapiro = hist_and_shapiro(bw_zv_fw_df_2, hist_out_path_2)\n",
    "\n",
    "# save in test normality folder\n",
    "bw_zv_fw_2_shapiro.to_csv(os.path.join(hist_out_path_2, 'zv_vs_bw_fw_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18a88d04-3515-4902-9df1-97ce4861d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos - video closest to walk on mat date \n",
    "hist_out_path_3 = (os.path.join(out_path, 'hv_vs_bw_pws_metric_correlation', 'check_normality'))\n",
    "if not os.path.exists(hist_out_path_3):\n",
    "    os.makedirs(hist_out_path_3)\n",
    "\n",
    "bw_hv_pws_2_shapiro = hist_and_shapiro(bw_hv_pws_df_2, hist_out_path_3)\n",
    "\n",
    "# save in test normality folder \n",
    "bw_hv_pws_2_shapiro.to_csv(os.path.join(hist_out_path_3, 'hv_vs_bw_pws_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcec32-0175-4042-b252-b0d7ea9a2bad",
   "metadata": {},
   "source": [
    "### Run correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc50aa82-284b-45f5-b60d-9e0d8fca048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cols to compare \n",
    "# column pairs to evaluate matching metrics \n",
    "# for each of the column pairs below (zv 1 vs bw1, zv 2 vs bw 3, etc), run and save correlation \n",
    "zv_colnames = ['stride_time_median_sec_pose_zv', \n",
    "               'stride_time_mean_sec_pose_zv',\n",
    "               'foot1_gait_cycle_time_mean_pose_zv',\n",
    "               'stride_time_cv_pose_zv', \n",
    "               'mean_cadence_step_per_min_pose_zv',\n",
    "               'foot1_double_support_per_mean_pose_zv',\n",
    "               'foot1_single_support_per_mean_pose_zv',\n",
    "               'stride_width_median_cm_pose_zv',\n",
    "               'stride_width_mean_cm_pose_zv',\n",
    "               'stride_width_std_pose_zv']\n",
    "\n",
    "hv_colnames = ['stride_time_median_sec_pose_hv', \n",
    "               'stride_time_mean_sec_pose_hv',\n",
    "               'foot1_gait_cycle_time_mean_pose_hv', \n",
    "               'stride_time_cv_pose_hv', \n",
    "               'mean_cadence_step_per_min_pose_hv',\n",
    "               'foot1_double_support_per_mean_pose_hv',\n",
    "               'foot1_single_support_per_mean_pose_hv',\n",
    "               'stride_width_median_cm_pose_hv',\n",
    "               'stride_width_mean_cm_pose_hv',\n",
    "               'stride_width_std_pose_hv']\n",
    "               \n",
    "bw_pws_colnames = ['PWS_stridetimesecmean', \n",
    "                   'PWS_stridetimesecmean',\n",
    "                   'PWS_stridetimesecmean',\n",
    "                   'PWS_stridetimeseccv',\n",
    "                   'PWS_cadencestepsminmean',\n",
    "                   'PWS_totaldsupportmean',\n",
    "                   'PWS_singlesupportmean', \n",
    "                   'PWS_stridewidthcmmean',\n",
    "                   'PWS_stridewidthcmmean',\n",
    "                   'PWS_stridewidthcmsd']\n",
    "\n",
    "bw_fw_colnames = ['FW_stridetimesecmean', \n",
    "                  'FW_stridetimesecmean', \n",
    "                  'FW_stridetimesecmean', \n",
    "                  'FW_stridetimeseccv',\n",
    "                   'FW_cadencestepsminmean',\n",
    "                   'FW_totaldsupportmean',\n",
    "                   'FW_singlesupportmean', \n",
    "                   'FW_stridewidthcmmean',\n",
    "                  'FW_stridewidthcmmean',\n",
    "                   'FW_stridewidthcmsd']\n",
    "\n",
    "units = ['seconds',\n",
    "         'seconds',\n",
    "         'seconds',\n",
    "         'CV%',\n",
    "         'steps/min',\n",
    "         '%',\n",
    "         '%', \n",
    "         'cm',\n",
    "         'cm',\n",
    "         'cm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3351cbd-96b4-4543-9369-a0fd5bb72c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWS Zeno Videos - video of walk on mat \n",
    "corr_out_path1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_correlation')\n",
    "\n",
    "bw_zv_pws_corr_results_df = metric_correlation(bw_zv_pws_df_2, zv_colnames, bw_pws_colnames, corr_out_path1)\n",
    "bw_zv_pws_corr_results_df.to_csv(os.path.join(corr_out_path1, 'bw_zv_pws_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb847f93-5a81-4387-b459-563919a853e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FW Zeno Videos - video of walk on mat \n",
    "corr_out_path2 = os.path.join(out_path, 'zv_vs_bw_fw_metric_correlation')\n",
    "\n",
    "bw_zv_fw_corr_results_df = metric_correlation(bw_zv_fw_df_2, zv_colnames, bw_fw_colnames, corr_out_path2)\n",
    "bw_zv_fw_corr_results_df.to_csv(os.path.join(corr_out_path2, 'bw_zv_fw_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd0ebe2f-64a9-4497-a07a-2b98c6218d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos - video closest to walk on mat date \n",
    "corr_out_path3 = os.path.join(out_path, 'hv_vs_bw_pws_metric_correlation')\n",
    "\n",
    "bw_hv_pws_corr_results_df = metric_correlation(bw_hv_pws_df_2, hv_colnames, bw_pws_colnames, corr_out_path3)\n",
    "bw_hv_pws_corr_results_df.to_csv(os.path.join(corr_out_path3, 'bw_hv_fw_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61ed39-3f24-4d35-b25f-dea20d595eef",
   "metadata": {},
   "source": [
    "## Mean Error: BW mat metrics vs Zeno video metrics \n",
    "- to-do:\n",
    "    - convert existing code into function\n",
    "    - mean error as percent of mean ground truth value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7915cc7a-ca32-4d45-8738-af625de6b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeno video vs brainwalk mat: preferred walking speed \n",
    "mae_out_path1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_mean_error')\n",
    "\n",
    "bw_zv_pws_mae_df = calculate_metric_mean_error(bw_zv_pws_df_2, zv_colnames, bw_pws_colnames, units, mae_out_path1)\n",
    "bw_zv_pws_mae_df.to_csv(os.path.join(mae_out_path1, 'bw_zv_pws_metric_mean_error_mae.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4465ea1a-ff75-44fe-bd32-a0c566a0dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeno video vs brainwalk mat: fast walking speed \n",
    "mae_out_path2 = os.path.join(out_path, 'zv_vs_bw_fw_metric_mean_error')\n",
    "\n",
    "bw_zv_fw_mae_df = calculate_metric_mean_error(bw_zv_fw_df_2, zv_colnames, bw_fw_colnames, units, mae_out_path2)\n",
    "bw_zv_fw_mae_df.to_csv(os.path.join(mae_out_path2, 'bw_zv_fw_metric_mean_error_mae.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b36558-0e88-4be2-967f-20c3f5088a44",
   "metadata": {},
   "source": [
    "## Bland Altman: BW mat metrics vs Zeno video metrics \n",
    "- function already written, just need to tweak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8c298a0-e096-4d6f-afda-b4954631ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferred walking speed \n",
    "bland_alt_path1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_BlandAlt')\n",
    "bland_altman_plot(bw_zv_pws_df_2, zv_colnames, bw_pws_colnames, units, bland_alt_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18c7fe21-8b41-4811-836b-0d93f9e5956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast walking speed \n",
    "# preferred walking speed \n",
    "bland_alt_path2 = os.path.join(out_path, 'zv_vs_bw_fw_metric_BlandAlt')\n",
    "bland_altman_plot(bw_zv_fw_df_2, zv_colnames, bw_fw_colnames, units, bland_alt_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37492011-116a-468c-9515-b118f9e12914",
   "metadata": {},
   "source": [
    "## Correlation of Gait Metrics vs Clinical Outcomes \n",
    "- includes both mat and video gait metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7687f55-b0af-4aec-8076-87f22e7e0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In person zeno videos + mat at PWS vs EDSS score and EDSS severity \n",
    "outcome_corr_path1 = os.path.join(out_path, 'zv_vs_bw_pws_outcome_corr')\n",
    "zv_pws_vs_edss_corr = outcome_correlation(bw_zv_pws_edss_df, outcome_corr_path1, 'zv_bw_pws', 'edss')\n",
    "zv_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path1, 'zv_bw_pws_edss_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e6eacb8-1e3c-4e59-8730-ef899596dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_11948\\1659443283.py:31: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_11948\\1659443283.py:31: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n"
     ]
    }
   ],
   "source": [
    "# In person zeno videos at PWS vs T25FW \n",
    "outcome_corr_path1 = os.path.join(out_path, 'zv_vs_bw_pws_outcome_corr')\n",
    "zv_pws_vs_t25fw_corr = outcome_correlation(bw_zv_pws_t25fw_df, outcome_corr_path1, 'zv_bw_pws', 't25fw')\n",
    "zv_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path1, 'zv_bw_pws_t25fw_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56615f74-bc23-4c17-97b4-68df48833126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In person zeno videos + mat at FW vs EDSS score and EDSS Severity \n",
    "outcome_corr_path2 = os.path.join(out_path, 'zv_vs_bw_fw_outcome_corr')\n",
    "zv_fw_vs_edss_corr = outcome_correlation(bw_zv_fw_edss_df, outcome_corr_path2, 'zv_bw_fw', 'edss')\n",
    "zv_fw_vs_edss_corr.to_csv(os.path.join(outcome_corr_path2, 'zv_bw_fw_edss_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f0e37-3a88-43a2-b070-eb43e974dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_11948\\1659443283.py:31: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_11948\\1659443283.py:31: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n"
     ]
    }
   ],
   "source": [
    "# in person zeno videos + mat at FW vs T25FW \n",
    "outcome_corr_path2 = os.path.join(out_path, 'zv_vs_bw_fw_outcome_corr')\n",
    "zv_fw_vs_t25fw_corr = outcome_correlation(bw_zv_fw_t25fw_df, outcome_corr_path2, 'zv_bw_fw', 't25fw')\n",
    "zv_fw_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path2, 'zv_bw_fw_t25fw_corr.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3aeba-ccf4-41dd-b30c-48a0e06bce50",
   "metadata": {},
   "source": [
    "### Not sure if enough videos for correlation\n",
    "Especially for only right or only left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa3af2-788f-4b66-b1a3-8dfb3755bc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bw home videos + in-person pws speed vs EDSS score and EDSS severity \n",
    "# all videos - can be two rows per particiant, one for gait vertical right and one for gait vertical left \n",
    "outcome_corr_path3 = os.path.join(out_path, 'hv_vs_bw_pws_outcome_corr')\n",
    "hv_pws_vs_edss_corr = outcome_correlation(bw_hv_edss_df, outcome_corr_path3, 'hv_all_bw_pws', 'edss')\n",
    "hv_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_all_bw_pws_edss_corr.csv'))\n",
    "\n",
    "\n",
    "# only \"gait_vertical_left\" \n",
    "bw_hv_edss_df_left = bw_hv_edss_df.loc[bw_hv_edss_df['task_pose_hv'] == 'gait_vertical_left']\n",
    "hv_left_pws_vs_edss_corr = outcome_correlation(bw_hv_edss_df_left, outcome_corr_path3, 'hv_left_bw_pws', 'edss')\n",
    "hv_left_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_left_bw_pws_edss_corr.csv'))\n",
    "\n",
    "# only \"gait_vertical_right\" \n",
    "bw_hv_edss_df_right = bw_hv_edss_df.loc[bw_hv_edss_df['task_pose_hv'] == 'gait_vertical_right']\n",
    "hv_right_pws_vs_edss_corr = outcome_correlation(bw_hv_edss_df_right, outcome_corr_path3, 'hv_right_bw_pws', 'edss')\n",
    "hv_right_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_right_bw_pws_edss_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b8eff-708d-49ed-afdf-e8f42d100123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bw_hv_t25fw_df\n",
    "# bw home videos + in-person pws speed vs T25FW \n",
    "outcome_corr_path3 = os.path.join(out_path, 'hv_vs_bw_pws_outcome_corr')\n",
    "hv_pws_vs_t25fw_corr = outcome_correlation(bw_hv_t25fw_df, outcome_corr_path3, 'hv_all_bw_pws', 't25fw')\n",
    "hv_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_all_bw_pws_t25fw_corr.csv'))\n",
    "\n",
    "# only \"gait_vertical_left\" \n",
    "bw_hv_t25fw_df_left = bw_hv_t25fw_df.loc[bw_hv_t25fw_df['task_pose_hv'] == 'gait_vertical_left']\n",
    "hv_left_pws_vs_t25fw_corr = outcome_correlation(bw_hv_t25fw_df_left, outcome_corr_path3, 'hv_left_bw_pws', 't25fw')\n",
    "hv_left_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_left_bw_pws_t25fw_corr.csv'))\n",
    "\n",
    "# only \"gait_vertical_right\" \n",
    "bw_hv_t25fw_df_right = bw_hv_t25fw_df.loc[bw_hv_t25fw_df['task_pose_hv'] == 'gait_vertical_right']\n",
    "hv_right_pws_vs_t25fw_corr = outcome_correlation(bw_hv_t25fw_df_right, outcome_corr_path3, 'hv_right_bw_pws', 't25fw')\n",
    "hv_right_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_right_bw_pws_t25fw_corr.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76327b-1705-4d7a-bf48-7a4dd836def1",
   "metadata": {},
   "source": [
    "## Analyze difference between categorical groups (diagnoses, edss severity, etc)\n",
    " - to do: anova/t-test scripts (mann whitney below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7d0a7-63b2-41f3-a4b7-9f06fc2aaf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ttest_anova_assumptions(df, group_col, metric_col_suffix, output_folder_path, video_task_str): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "\n",
    "    # count number of cateogries in group_col \n",
    "    x_cat_groups = df[group_col].unique()\n",
    "    print('groups')\n",
    "    print(x_cat_groups)\n",
    "\n",
    "    # create save folder for histograms \n",
    "    if not os.path.exists(os.path.join(output_folder_path, 'check_normality')):\n",
    "        os.makedirs(os.path.join(output_folder_path, 'check_normality'))\n",
    "    \n",
    "    # loop through each y column and plot vs group_col variable histogram \n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns): \n",
    "\n",
    "        # check normality of each y column, grouped by current x value \n",
    "        plt.figure(figsize = (10,6))\n",
    "\n",
    "        # Save for storing shapiro results and standard deviation \n",
    "        results_text_on_plot = []\n",
    "        \n",
    "        for current_group in x_cat_groups: \n",
    "            current_group_values = df[df[group_col] == current_group][current_metric_col]\n",
    "            sns.histplot(data = current_group_values, alpha = 0.5, label = f'Group {current_group}')\n",
    "\n",
    "            if current_group_values.count() > 3:\n",
    "                # perform shapiro walks test for normality \n",
    "                stat, p_value = stats.shapiro(current_group_values, nan_policy='omit')\n",
    "                # save standard deviation for each group \n",
    "                sd = current_group_values.std(skipna = True)\n",
    "                \n",
    "            else:  \n",
    "                stat = np.nan\n",
    "                p_value = np.nan\n",
    "                sd = np.nan\n",
    "\n",
    "            results_text_on_plot.append((current_group, np.round(stat, decimals=3), np.round(p_value, decimals = 3), np.round(sd, decimals = 3)))\n",
    "\n",
    "        # plot title and legend \n",
    "        plt.title('Metric Values by group') \n",
    "        plt.legend()\n",
    "        \n",
    "        # Annotate Shapiro-Wilk results on the plot\n",
    "        plt.text(0.05, 0.95, 'Hypothesis test assumptions', transform=plt.gca().transAxes)\n",
    "        text_y_position = 0.9  # Start near the top of the plot\n",
    "        for result in results_text_on_plot:\n",
    "            current_group, stat, p_value, sd = result\n",
    "            plt.text(\n",
    "                0.05, text_y_position, \n",
    "                f'Group {current_group}: Shapiro Stat ={stat}, Shapiro p={p_value}, SD = {sd}', \n",
    "                transform=plt.gca().transAxes\n",
    "            )\n",
    "            text_y_position -= 0.05  # Move down for the next annotation\n",
    "        \n",
    "        plt.savefig(os.path.join(output_folder_path, 'check_normality', current_metric_col + '_by_' + group_col + '_hist.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9a0f8-afd3-4031-8d8b-fe82cbcf1e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_cat(df, group_col, metric_col_suffix, output_folder_path, video_task_str): \n",
    "\n",
    "    # create save folder for histograms \n",
    "    if not os.path.exists(os.path.join(output_folder_path)):\n",
    "        os.makedirs(os.path.join(output_folder_path))\n",
    "    \n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "\n",
    "    # loop through each y column and plot vs group_col variable histogram \n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns): \n",
    "        \n",
    "        # BOXPLOT \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.boxplot(data=df, x=group_col, y=current_metric_col, width = 0.75, fill = False)\n",
    "        # Add in points to show each observation\n",
    "        sns.stripplot(data=df, x=group_col, y=current_metric_col, size=4, color=\".3\")\n",
    "        ax.set_title(f'{current_metric_col} vs {group_col}') \n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "        # Save the plot\n",
    "        fig_path = os.path.join(output_folder_path,  video_task_str + '_' + current_metric_col + '_vs_' + group_col + '.png')\n",
    "        fig.savefig(fig_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fea60-f12c-49a5-ae0d-ee59ee16870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann whitney U function - loop through all y vals \n",
    "def mannwhitneyu_all_metrics(df, group_col, group_1, group_2, metric_col_suffix, output_folder_path, video_task_str): \n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "\n",
    "    # loop through each y column and plot vs group_col variable histogram \n",
    "    stats_results = []\n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns): \n",
    "        group1_data = df[df[group_col] == group_1][current_metric_col]\n",
    "        group2_data = df[df[group_col] == group_2][current_metric_col] \n",
    "        U1, p = stats.mannwhitneyu(group1_data, group2_data, nan_policy='omit')\n",
    "        stats_results.append((group_col, current_metric_col, U1, p))\n",
    "\n",
    "    stats_results_df = pd.DataFrame(stats_results, columns = [group_col, 'metric', 'U1', 'p'])\n",
    "    stats_results_df.to_csv(os.path.join(output_folder_path, 'mannwhitney_' + video_task_str + '.csv'))\n",
    "    return(stats_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f61e3-c8af-45a3-a558-1554b90515c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal Wallace and Dunn's test function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59a7a4-a2ea-4b40-9625-8678c38e6ab8",
   "metadata": {},
   "source": [
    "### each video metric vs HC vs MS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305ebce-76f2-4109-b9f3-a538edb66129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person preferred walk \n",
    "outpath_1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_demographic_diagnosis')\n",
    "bw_zv_pws_df_2.loc[:, 'demographic_diagnosis'] = pd.Categorical(bw_zv_pws_df_2.loc[:,'demographic_diagnosis'], categories=['MS', 'HC'], ordered=True)\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_pws_df_2, \n",
    "                              group_col = 'demographic_diagnosis', \n",
    "                              metric_col_suffix = 'zv',\n",
    "                              output_folder_path = outpath_1, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat(bw_zv_pws_df_2, \n",
    "            group_col = 'demographic_diagnosis', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_1, \n",
    "            video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "# Mannwhitneyu test \n",
    "pws_demographic_diagnosis_results =  mannwhitneyu_all_metrics(bw_zv_pws_df_2,\n",
    "                                group_col = 'demographic_diagnosis',\n",
    "                                group_1 = 'HC', \n",
    "                                group_2 = 'MS', \n",
    "                                metric_col_suffix = 'zv', \n",
    "                                output_folder_path = outpath_1, \n",
    "                                video_task_str = 'zv_bw_pws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ff5b4-082b-4e77-9553-11f67186e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person fast walk\n",
    "outpath_1b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_demographic_diagnosis')\n",
    "bw_zv_fw_df_2.loc[:, 'demographic_diagnosis'] = pd.Categorical(bw_zv_fw_df_2.loc[:,'demographic_diagnosis'], categories=['MS', 'HC'], ordered=True)\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_fw_df_2, \n",
    "                              group_col = 'demographic_diagnosis', \n",
    "                              metric_col_suffix = 'zv',\n",
    "                              output_folder_path = outpath_1b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat(bw_zv_fw_df_2, \n",
    "            group_col = 'demographic_diagnosis', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_1b, \n",
    "            video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55fc9c-a14a-486e-8bf6-27074c16a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home video - not applicable - only MS participants "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe985869-f95c-4ae1-affc-5398a791e53b",
   "metadata": {},
   "source": [
    "### each video metric vs EDSS severity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89f934-3fd0-4c59-a717-1d94768d6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bw_zv_pws_edss_df['edss_severity_cat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2bab31-0a41-4f99-a4ac-05cee00e77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person preferred walk \n",
    "outpath_2 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_edss_severity')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_pws_edss_df, \n",
    "                              group_col = 'edss_severity_cat', \n",
    "                              metric_col_suffix = 'zv', \n",
    "                              output_folder_path = outpath_2, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat(bw_zv_pws_edss_df, \n",
    "            group_col = 'edss_severity_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_2, \n",
    "            video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "# kruskal ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68893b-dbe2-4df7-a1bd-1e01e3bc7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person fast walk \n",
    "outpath_2b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_edss_severity')\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_fw_edss_df, \n",
    "                              group_col = 'edss_severity_cat', \n",
    "                              metric_col_suffix = 'zv', \n",
    "                              output_folder_path = outpath_2b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat(bw_zv_fw_edss_df, \n",
    "            group_col = 'edss_severity_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_2b, \n",
    "            video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df83c1-6d71-40da-aed3-e953abe34136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos \n",
    "outpath_2c = os.path.join(out_path, 'hv_vs_bw_pws_metric_by_edss_severity')\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_hv_edss_df, \n",
    "                              group_col = 'edss_severity_cat', \n",
    "                              metric_col_suffix = 'hv', \n",
    "                              output_folder_path = outpath_2c, \n",
    "                              video_task_str = 'hv_bw_pws')\n",
    "\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat(bw_hv_edss_df, \n",
    "            group_col = 'edss_severity_cat', \n",
    "            metric_col_suffix = 'hv',\n",
    "            output_folder_path = outpath_2c, \n",
    "            video_task_str = 'hv_bw_pws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c9b7f-7dbe-4efb-90d4-300cb5147d5f",
   "metadata": {},
   "source": [
    "### each video metric vs edss score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ed0a7d-ae1f-48d6-ab14-3ad8655161cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person preferred walk \n",
    "outpath_3 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_edss_score')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_pws_edss_df, \n",
    "                              group_col = 'bingoEHR_EDSS_measure_value', \n",
    "                              metric_col_suffix = 'zv', \n",
    "                              output_folder_path = outpath_3, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat(bw_zv_pws_edss_df, \n",
    "            group_col = 'bingoEHR_EDSS_measure_value', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_3, \n",
    "            video_task_str = 'zv_bw_pws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54b021-b3db-4c69-af12-e84d3a868c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person fast walk \n",
    "outpath_3b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_edss_score')\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_fw_edss_df, \n",
    "                              group_col = 'bingoEHR_EDSS_measure_value', \n",
    "                              metric_col_suffix = 'zv', \n",
    "                              output_folder_path = outpath_3b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat(bw_zv_fw_edss_df, \n",
    "            group_col = 'bingoEHR_EDSS_measure_value', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_3b, \n",
    "            video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0026d-3785-47a1-a851-d195504ca44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos \n",
    "outpath_3c = os.path.join(out_path, 'hv_vs_bw_pws_metric_by_edss_score')\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_hv_edss_df, \n",
    "                              group_col = 'bingoEHR_EDSS_measure_value', \n",
    "                              metric_col_suffix = 'hv', \n",
    "                              output_folder_path = outpath_2c, \n",
    "                              video_task_str = 'hv_bw_pws')\n",
    "\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat(bw_hv_edss_df, \n",
    "            group_col = 'bingoEHR_EDSS_measure_value', \n",
    "            metric_col_suffix = 'hv',\n",
    "            output_folder_path = outpath_3c, \n",
    "            video_task_str = 'hv_bw_pws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1ca18-f6b1-48ef-8c98-62e1c55b11cf",
   "metadata": {},
   "source": [
    "### each video metric vs T25FW time category  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab450a-e808-453f-b28e-bb540c57b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person preferred walk \n",
    "outpath_4 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_t25fw_group')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_pws_t25fw_df, \n",
    "                              group_col = 't25fw_group_cat', \n",
    "                              metric_col_suffix = 'zv', \n",
    "                              output_folder_path = outpath_4, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat(bw_zv_pws_t25fw_df, \n",
    "            group_col = 't25fw_group_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_4, \n",
    "            video_task_str = 'zv_bw_pws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfa27ca-9ca0-4991-8601-855c913fa053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in person fast walk \n",
    "outpath_4b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_t25fw_group')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_fw_t25fw_df,\n",
    "                              group_col = 't25fw_group_cat', \n",
    "                              metric_col_suffix = 'zv',\n",
    "                              output_folder_path = outpath_4b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "\n",
    "boxplot_cat(bw_zv_fw_t25fw_df, \n",
    "            group_col = 't25fw_group_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_4b, \n",
    "            video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a32a29-7a0c-4aba-8f69-5bdb5e301d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos \n",
    "# in person fast walk \n",
    "outpath_4c = os.path.join(out_path, 'hv_vs_bw_pws_metric_by_t25fw_group')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_hv_t25fw_df, \n",
    "                              group_col = 't25fw_group_cat', \n",
    "                              metric_col_suffix = 'hv', \n",
    "                              output_folder_path = outpath_4c, \n",
    "                              video_task_str = 'hv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat(bw_hv_t25fw_df, \n",
    "            group_col = 't25fw_group_cat', \n",
    "            metric_col_suffix = 'hv',\n",
    "            output_folder_path = outpath_4c, \n",
    "            video_task_str = 'hv_bw_pws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c8445-3836-4ed1-ac40-e9da01d62985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73afe9f3-502f-4c36-90b5-a1c4568dd027",
   "metadata": {},
   "source": [
    "## Quartiles \n",
    "- See matt notes - group into quartiles, mean of each main metric + EDSS + T25FW\n",
    "- ANOVA for each group\n",
    "- plot after see data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30aad5-ff1a-4b11-816a-bf000c50cedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4d03692-836c-470a-98e4-1e2529385fe4",
   "metadata": {},
   "source": [
    "## Other future ideas\n",
    "- One plot\n",
    "    - home and in-person preferred walk\n",
    "    - color dots by home vs in-person --> do they show similar trend?\n",
    "- one plot\n",
    "    - video vs mat: mat one color and video another? \n",
    "- Remove outliers if needed??\n",
    "- update to only include one mat metric per participant, if they have two home videso\n",
    "- for metrics vs clinical outcomes AND vid metric vs mat metric\n",
    "    - NOTE!! - TRY FOR ALL HOME VIDEOS AND FOR ONLY GAIT VERTICAL LEFT AND GAIT VERTICAL RIGHT (ONE VID PER PARTICIPANT)\n",
    "    - quartiles\n",
    "    - something like val steps + EDSS plots: plot metric at each EDSS level in scatter chart (x = EDSS, y = metric 1) \n",
    "- cluster, PCA, kernel: predict edss given set of metrics (from zeno, then say X amount of people at home able to collect good videos)\n",
    "- longitudanl from people with multiple follow ups?\n",
    "- binary classifier/cutoff score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
