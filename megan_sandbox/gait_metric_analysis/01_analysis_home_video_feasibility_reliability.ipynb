{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f623f36e-4a00-4f7d-ae45-011dbd7f1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f01c5-72f1-4809-b39c-3a52daf01b11",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302face2-9186-4b67-bd81-74bd2c109687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df input should be merged df - both video and bw data \n",
    "\n",
    "def print_video_counts(df):\n",
    "    # number of zeno videos and participants included \n",
    "    print('total videos - df length: ' + \n",
    "          str(len(df))) \n",
    "\n",
    "    print('unique demographic_diagnosis in df: ' + \n",
    "         str(pd.unique(df['demographic_diagnosis'])))\n",
    "    \n",
    "    print('num videos with demographic_diagnosis == HC: ' + \n",
    "         str(len(df[df['demographic_diagnosis'] == 'HC']))) \n",
    "\n",
    "    print('num videos demographic_diagnosis == MS: ' + \n",
    "         str(len(df[df['demographic_diagnosis'] == 'MS']))) \n",
    "\n",
    "    print('------')\n",
    "\n",
    "    print('unique id_video (participants) in df: ' + \n",
    "          str(len(pd.unique(df['id_video'])))) \n",
    "\n",
    "    print('num participants with demographic_diagnosis == HC: ' + \n",
    "         str(len(pd.unique(df['id_video'][df['demographic_diagnosis'] == 'HC'])))) \n",
    "    \n",
    "    print('num participants demographic_diagnosis == MS: ' + \n",
    "         str(len(pd.unique(df['id_video'][df['demographic_diagnosis'] == 'MS']))))\n",
    "\n",
    "    print('------') \n",
    "    \n",
    "    print('number of participants with multiple videos in dataset: ' + \n",
    "         str(df['id_video'][df['id_video'].duplicated()].nunique()))\n",
    "\n",
    "    print('number of participants with one video: ' + \n",
    "          str((df['id_video'].value_counts() == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68e9496-eb51-4916-aaa0-ae25b72f3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of same metrics from difference data sources (left vs right videos)\n",
    "\n",
    "def metric_correlation_rl(df, left_columns, right_columns, output_folder_path): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    # create empty list to store results \n",
    "    corr_results_all = [] \n",
    "    clean_df = pd.DataFrame() \n",
    "    \n",
    "    for metric_i, current_metric in enumerate(left_columns): \n",
    "        current_left_col = left_columns[metric_i]\n",
    "        current_right_col = right_columns[metric_i]\n",
    "\n",
    "        # Drop rows with NaN values in either column - required to run spearman r \n",
    "        clean_df = df.dropna(subset=[current_left_col, current_right_col])\n",
    "        \n",
    "        # plot \n",
    "        sns.lmplot(x = current_right_col, y = current_left_col, data = clean_df, ci = None)\n",
    "        # Set the x and y axis limits to the same range\n",
    "        # plt.axis('square')  \n",
    "       # min_val = min(clean_df[current_left_col].min(), clean_df[current_left_col].min())  \n",
    "       # max_val = max(clean_df[current_left_col].max(), clean_df[current_left_col].max())  \n",
    "       # plt.xlim(min_val, max_val)\n",
    "       # plt.ylim(min_val, max_val) \n",
    "        plt.savefig(os.path.join(output_folder_path, str(current_left_col) +  '_.png'))\n",
    "        plt.close()\n",
    "\n",
    "        # run spearman correlation and append   \n",
    "        statistic, p_value = stats.spearmanr(clean_df[current_right_col], clean_df[current_left_col])\n",
    "        corr_results_all.append({'bw_column': current_right_col, \n",
    "                                 'video_column': current_left_col, \n",
    "                                 'corr_method': 'spearman', \n",
    "                                 'rs': statistic, \n",
    "                                 'p_value' : p_value,\n",
    "                                 'n observations': len(clean_df)})\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    corr_results_df = pd.DataFrame(corr_results_all)\n",
    "    corr_results_df = corr_results_df.round(3)\n",
    "\n",
    "    return corr_results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e35b509-9a7f-4f25-9c48-a24bf5b07439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same columns as metric correlations \n",
    "def calculate_metric_mean_diff(df, left_columns, right_columns, output_folder_path):\n",
    "    # one dot = participant \n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path) \n",
    "        \n",
    "    mean_error_all = [] \n",
    "\n",
    "    for metric_i, current_metric in enumerate(left_columns): \n",
    "        current_left_col = left_columns[metric_i]\n",
    "        current_right_col = right_columns[metric_i]\n",
    "\n",
    "        # Drop rows with NaN values in either column \n",
    "        clean_df = df.dropna(subset=[current_left_col, current_right_col])\n",
    "\n",
    "        current_metric_diff = clean_df[current_right_col] - clean_df[current_left_col]\n",
    "        current_mean_diff = current_metric_diff.mean()\n",
    "        current_abs_mean_diff = abs(current_metric_diff).mean()\n",
    "\n",
    "        # calculate mean ground truth data \n",
    "        rl_mean = clean_df[[current_left_col, current_right_col]].mean().mean()\n",
    "        mean_err_per = (current_mean_diff / rl_mean) * 100 \n",
    "        mae_per = (current_abs_mean_diff / rl_mean) * 100 \n",
    "\n",
    "        # plot \n",
    "        fig, ax1 = plt.subplots()\n",
    "        sns.boxplot(y=current_metric_diff, ax=ax1, fill = False, dodge = True, fliersize = 0)\n",
    "        sns.stripplot(y = current_metric_diff, ax = ax1, color = 'black', dodge = True)\n",
    "        fig.suptitle('Right - Left Video')\n",
    "        ax1.set_title(current_right_col)\n",
    "        # center plot at zero\n",
    "        ymin, ymax = plt.ylim()\n",
    "        plt.ylim(min(ymin, -ymax), max(ymax, -ymin))\n",
    "        plt.ylabel('Error')\n",
    "\n",
    "        # add line at zero\n",
    "        plt.axhline(y=0, color='grey', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder_path, str(current_left_col + '_diff_box.png')))\n",
    "        plt.close()\n",
    "\n",
    "        # mean difference \n",
    "        mean_error_all.append({'right_col': current_right_col, \n",
    "                               'left_col': current_left_col,\n",
    "                               'n' : len(clean_df), \n",
    "                               'mean_all_l_and_r_metrics' : rl_mean,\n",
    "                               'mean_difference': current_mean_diff, \n",
    "                               'mean_abs_difference' : current_abs_mean_diff, \n",
    "                               'mean_diff_%_of_mean' : mean_err_per,\n",
    "                               'mean_abs_diff_%_of_mean' : mae_per})\n",
    "\n",
    "    \n",
    "     # Create DataFrame with results\n",
    "    mean_error_df = pd.DataFrame(mean_error_all)\n",
    "    mean_error_df = mean_error_df.round(3)\n",
    "    \n",
    "    return mean_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e80cd59-37b2-4a32-9b0a-c2f3e371553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same columns as metric correlation \n",
    "\n",
    "def bland_altman_plot(df, left_columns, right_columns, output_folder_path):\n",
    "     \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    for metric_i, current_metric in enumerate(left_columns): \n",
    "        current_right_col = right_columns[metric_i]\n",
    "        current_left_col = left_columns[metric_i]\n",
    "\n",
    "        clean_df = df.dropna(subset=[current_left_col, current_right_col])\n",
    "    \n",
    "        # Compute the mean and the difference\n",
    "        mean_measurements = (clean_df[current_right_col] + clean_df[current_left_col]) / 2\n",
    "        diff_measurements = clean_df[current_right_col] - clean_df[current_left_col]  # Difference between measurements\n",
    "\n",
    "        # Mean difference and standard deviation of the difference\n",
    "        mean_diff = np.mean(diff_measurements)\n",
    "        std_diff = np.std(diff_measurements)\n",
    "\n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(mean_measurements, diff_measurements, alpha=1)\n",
    "    \n",
    "        # Add mean difference line and limits of agreement (Â±1.96*std)\n",
    "        plt.axhline(mean_diff, color='black', linestyle='--', label=f'Mean diff: {mean_diff:.2f}')\n",
    "        plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=f'+1.96 SD: {mean_diff + 1.96 * std_diff:.2f}')\n",
    "        plt.axhline(mean_diff - 1.96 * std_diff, color='blue', linestyle='--', label=f'-1.96 SD: {mean_diff - 1.96 * std_diff:.2f}')\n",
    "        plt.axhline(y=0, color='grey', linestyle='--')\n",
    "    \n",
    "        # Labels and title\n",
    "        plt.xlabel('Mean of Right and Left Turns Video Metric') \n",
    "        plt.ylabel('Right Video - Left Video Metric')\n",
    "        plt.suptitle('Right vs Left')\n",
    "        plt.title(current_right_col)\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_folder_path,  str(current_left_col + '_blandalt.png')))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae2d8d7-0afe-43d8-a0ed-21ac6e79c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge home video data with preferred walking speed mat data \n",
    "# participants walk at preferred pace at home \n",
    "\n",
    "def merge_bw_hv(bw_df, hv_df, out_path):\n",
    "    # filter bw ids dataset to only those included in video data set \n",
    "    hv_in_bw_df = bw_df[bw_df['bw_id'].isin(hv_df['bw_id'])]\n",
    "   # hv_in_bw_df.to_csv(os.path.join(out_path, 'hv_id_in_bw_df.csv')) # save excel \n",
    "\n",
    "    print('total bw rows with id in video dataset') \n",
    "    print(len(hv_in_bw_df))\n",
    "\n",
    "    # Track used rows from zv_in_bw_df\n",
    "    used_indices = set()\n",
    "\n",
    "    # Helper function to find the closest date\n",
    "    def find_closest_date_unique(row, in_bw_df):\n",
    "        # Filter rows with the same 'bw_id' and not already used\n",
    "        filtered_df = in_bw_df[(in_bw_df['bw_id'] == row['bw_id'])] \n",
    "        if filtered_df.empty:\n",
    "            return None\n",
    "        \n",
    "        # Find the closest date\n",
    "        closest_idx = (filtered_df['trialdate'] - row['video_date']).abs().idxmin()\n",
    "        # used_indices.add(closest_idx)  # Mark the row as used\n",
    "        return filtered_df.loc[closest_idx]\n",
    "\n",
    "    # Apply the helper function row-wise\n",
    "    closest_rows = hv_df.apply(\n",
    "        lambda row: find_closest_date_unique(row, hv_in_bw_df), axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    # Merge the original `hv df` with `closest_rows_df`\n",
    "    merged_bw_hv_df = hv_df.merge(closest_rows, left_index=True, right_index=True, suffixes=('', '_closest'))\n",
    "\n",
    "    # add column for date diff \n",
    "    merged_bw_hv_df['bw_hv_abs_date_diff'] = abs(merged_bw_hv_df['trialdate'] - merged_bw_hv_df['video_date'])\n",
    "    \n",
    "    # check same ID for each row \n",
    "    print('mismatched home video vs brainwalk id')\n",
    "    print(sum(merged_bw_hv_df['bw_id'] != merged_bw_hv_df['bw_id']))\n",
    "    \n",
    "    return merged_bw_hv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a9a7d-b41b-4a74-9e9a-93c41a1972ee",
   "metadata": {},
   "source": [
    "# Load and Format Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7122e325-ccc6-4ddd-96ff-04c952e0a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version \n",
    "version = '004' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bc9fd2-f918-497a-955b-734c243c6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folder \n",
    "output_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                           version, \n",
    "                           'home_feasibility_reliability') \n",
    "                           \n",
    "if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8419f9dc-4564-4c5f-97e9-793ca0416707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created in analysis_video_vs_mat_and_outcomes script, need to run that script first  \n",
    "bw_hv_pws_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis',\n",
    "                              version, \n",
    "                              'hv_bw_merged.csv') \n",
    "bw_hv_pws_df = pd.read_csv(bw_hv_pws_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd86ce4-6266-4cbe-8ea0-45fd3f8e0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vids included in analysis \n",
    "included_vids_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code', \n",
    "                                  'gait_bw_home_outputs_' + version, \n",
    "                                  'gait_bw_home_outputs_' + version + '_included_videos.csv') \n",
    "included_vids = pd.read_csv(included_vids_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc46f952-204f-4e57-9e97-0ff6128dd7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BW long, demographic data only \n",
    "bw_df = pd.read_excel(r'C:\\Users\\mmccu\\AppData\\Local\\Temp\\ccsecure\\2025_01_24_BrainWalk_AllData_Long_MM.xlsx', \n",
    "                     index_col = None, \n",
    "                     usecols = ['bw_id', 'record_id', 'trialdate', 'visit_date', 'demoEHR_DiseaseDuration',\n",
    "                                'clean_sex', 'demoEHR_Age', 'demographic_diagnosis', 'bingoEHR_DX_MS DX', 'clean_race',\t\n",
    "                                'clean_ethnicity', 'bingoEHR_EDSS_measure_value', 'msfcEHR_T25FW SPEED AVG']) \n",
    "\n",
    "bw_df_ms = bw_df.loc[bw_df['demographic_diagnosis'] == 'MS', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9461e382-6061-49ac-ab68-1c9423c9df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for ordinal EDSS severity and t25fw \n",
    "bw_hv_pws_df['edss_severity_cat'] = pd.Categorical(bw_hv_pws_df['edss_severity_cat'], categories=[\"mild\", \"moderate\", \"severe\"], ordered=True)\n",
    "bw_hv_pws_df['t25fw_group_cat'] = pd.Categorical(bw_hv_pws_df['t25fw_group_cat'], categories=[\"under_6\", \"6_to_8\", \"over_8\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3064f6b2-186f-4f7e-b5d8-49dec87123b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only video columns \n",
    "hv_subset_cols =  [col for col in bw_hv_pws_df.columns if col.endswith('hv')] \n",
    "hv_subset_df = bw_hv_pws_df.loc[:, hv_subset_cols]\n",
    "\n",
    "# make one row per date and id combo - one row with both left and right video \n",
    "hv_subset_wide_df = hv_subset_df.pivot(index='id_date_pose_hv', columns='task_pose_hv').reset_index()\n",
    "hv_subset_wide_df.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in hv_subset_wide_df.columns]\n",
    "hv_subset_wide_df = hv_subset_wide_df.drop(['video_id_date_name_pose_hv_gait_vertical_left', 'video_id_date_name_pose_hv_gait_vertical_right', \n",
    "                                            'walk_segment_pose_hv_gait_vertical_left', 'walk_segment_pose_hv_gait_vertical_right',\n",
    "                                            'foot1_pose_hv_gait_vertical_left', 'foot1_pose_hv_gait_vertical_right'],\n",
    "                                          axis = 1)\n",
    "hv_subset_wide_df.head()\n",
    "hv_subset_wide_df.to_csv(os.path.join(output_path, 'hv_metrics_only_wide.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d882885-d6ee-4a43-b53e-db30882fd0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_hv_colnames = [col for col in hv_subset_wide_df.columns if col.endswith('left')] \n",
    "right_hv_colnames = [col for col in hv_subset_wide_df.columns if col.endswith('right')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49408310-b99f-4429-8936-db8ff0875eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames_per_second_pose_hv_gait_vertical_left\n",
      "frames_per_second_pose_hv_gait_vertical_right\n",
      "------------\n",
      "total_video_duration_sec_pose_hv_gait_vertical_left\n",
      "total_video_duration_sec_pose_hv_gait_vertical_right\n",
      "------------\n",
      "walking_segmets_n_pose_hv_gait_vertical_left\n",
      "walking_segmets_n_pose_hv_gait_vertical_right\n",
      "------------\n",
      "walking_segments_duration_mean_pose_hv_gait_vertical_left\n",
      "walking_segments_duration_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "walking_segments_duration_median_pose_hv_gait_vertical_left\n",
      "walking_segments_duration_median_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_time_mean_sec_pose_hv_gait_vertical_left\n",
      "stride_time_mean_sec_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_time_median_sec_pose_hv_gait_vertical_left\n",
      "stride_time_median_sec_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_time_std_pose_hv_gait_vertical_left\n",
      "stride_time_std_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_time_cv_pose_hv_gait_vertical_left\n",
      "stride_time_cv_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_time_max_pose_hv_gait_vertical_left\n",
      "stride_time_max_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_time_min_pose_hv_gait_vertical_left\n",
      "stride_time_min_pose_hv_gait_vertical_right\n",
      "------------\n",
      "mean_cadence_step_per_min_pose_hv_gait_vertical_left\n",
      "mean_cadence_step_per_min_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_width_mean_cm_pose_hv_gait_vertical_left\n",
      "stride_width_mean_cm_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_width_median_cm_pose_hv_gait_vertical_left\n",
      "stride_width_median_cm_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_width_std_pose_hv_gait_vertical_left\n",
      "stride_width_std_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_width_cv_pose_hv_gait_vertical_left\n",
      "stride_width_cv_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_width_max_pose_hv_gait_vertical_left\n",
      "stride_width_max_pose_hv_gait_vertical_right\n",
      "------------\n",
      "stride_width_min_pose_hv_gait_vertical_left\n",
      "stride_width_min_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_gait_cycle_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_gait_cycle_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_stance_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_stance_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_stance_per_mean_pose_hv_gait_vertical_left\n",
      "foot1_stance_per_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_swing_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_swing_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_swing_per_mean_pose_hv_gait_vertical_left\n",
      "foot1_swing_per_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_ini_double_support_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_ini_double_support_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_term_double_support_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_term_double_support_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_tot_double_support_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_tot_double_support_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_double_support_per_mean_pose_hv_gait_vertical_left\n",
      "foot1_double_support_per_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_single_support_time_mean_pose_hv_gait_vertical_left\n",
      "foot1_single_support_time_mean_pose_hv_gait_vertical_right\n",
      "------------\n",
      "foot1_single_support_per_mean_pose_hv_gait_vertical_left\n",
      "foot1_single_support_per_mean_pose_hv_gait_vertical_right\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# double check if using this script - left and right are ordered the same \n",
    "    # first right metric is same as first left metric \n",
    "\n",
    "for colname_i, current_metric in enumerate(left_hv_colnames): \n",
    "    print(left_hv_colnames[colname_i])\n",
    "    print(right_hv_colnames[colname_i])\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a72fcb-7ffb-47fa-b26d-6fe22b90efe9",
   "metadata": {},
   "source": [
    "## Test-Retest Reliability \n",
    "- how similar are metrics sent by same person on the same day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60a578bd-e5d9-4b07-9abb-d0ca74976b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson R correlation for each metric \n",
    "corr_out_path1 = os.path.join(output_path, 'test_retest', 'right_vs_left_metric_correlation')\n",
    "\n",
    "hv_lr_corr_results_df = metric_correlation_rl(hv_subset_wide_df, left_hv_colnames, right_hv_colnames, corr_out_path1)\n",
    "hv_lr_corr_results_df.to_csv(os.path.join(corr_out_path1, 'correlation_results_rl.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "920ac167-e691-40f1-8676-ac04dfd88cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Difference and Mean Absolute Difference Right vs Left \n",
    "mean_diff_path = os.path.join(output_path, 'test_retest', 'diff_right_vs_left')\n",
    "mean_diff_df = calculate_metric_mean_diff(hv_subset_wide_df, left_hv_colnames, right_hv_colnames, mean_diff_path)\n",
    "mean_diff_df.to_csv(os.path.join(mean_diff_path, 'right_left_diff_results_rl.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8ddc9-ff65-49c0-9cc7-9f438b433115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bland altman \n",
    "ba_path = os.path.join(output_path, 'test_retest', 'right_vs_left_metric_blandalt')\n",
    "bland_altman_plot(hv_subset_wide_df, left_hv_colnames, right_hv_colnames, ba_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40543d-d1b7-461f-ae3d-24156cad4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICC ? not sure if another measure is more appropriate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803c28c-287c-4d33-a550-ed3917557962",
   "metadata": {},
   "source": [
    "## Feasibility\n",
    "- compare demographics between groups\n",
    "- 12/20/24 - just comparing ppl who sent videos vs usable videos\n",
    "- \n",
    "- To - do: check in with coordinators to confirm list of consented people is correct\n",
    "   - once confirmed - can do 1) all MS participants vs those who consented AND 2) all people who consented vs those who actually sent videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027d190-d70a-4ffc-85ca-3a8a86334078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feasibility outpath \n",
    "feas_outpath = os.path.join(output_path, 'feasibility')\n",
    "if not os.path.exists(feas_outpath):\n",
    "    os.makedirs(feas_outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62127c82-dea8-44c8-9458-c814cdaad66b",
   "metadata": {},
   "source": [
    "### All videos sent VS Videos included in analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077f33d-9e46-42b0-83bc-e55de63b9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BW-ID and date for all gait_vertical_videos \n",
    "# start fom original pose, save .csv\n",
    "home_video_folder_path = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Walking home videos for analysis'\n",
    "\n",
    "ALLOWED_VID_FORMATS = [\"asf\", \"avi\", \"gif\", \"m4v\",\n",
    "                       \"mkv\", \"mov\", \"mp4\", \"mpeg\",\n",
    "                       \"mpg\", \"ts\", \"wmv\", \"webm\"]\n",
    "\n",
    "\n",
    "# loop through all files in input path \n",
    "video_files_all = []\n",
    "for (dir_path, dir_names, file_names) in os.walk(home_video_folder_path):\n",
    "    for file_name in file_names: \n",
    "        name, ext = os.path.splitext(file_name)\n",
    "        ext = ext.lower()[1:]\n",
    "        current_raw_data_in_path = os.path.join(dir_path, file_name) # full path to files \n",
    "        # save full path to file if it meets requirements to run in analysis \n",
    "        if (ext in ALLOWED_VID_FORMATS) & ('gait_vertical' in name): \n",
    "            parent1, date = os.path.split(dir_path)\n",
    "            parent2, bw_id = os.path.split(parent1)\n",
    "            video_files_all.append((name, date, bw_id))\n",
    "\n",
    "video_files_all_df = pd.DataFrame(video_files_all,  columns = ['file_name', 'video_date', 'bw_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2495427-0589-4eb4-86b3-bc69618a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(video_files_all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c25b16-6302-41c4-8476-0e46e87e8325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format date of all videos \n",
    "video_files_all_df['video_date'] = pd.to_datetime(video_files_all_df['video_date'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3a145-f09a-4044-9a25-f47b71e1ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set video num column in all videos df \n",
    "    # 1 = first date videos were sent by that participant (could be multiple videos but first set of videos), 2 = second set of videos sent, etc \n",
    "    ## NEED TO REDO MANUALLY IF VIDEO ORDER CHANGES \n",
    "\n",
    "video_files_all_df['video_set_num'] = 1\n",
    "\n",
    "row_video_set_num2 = [4,5, 23, 24, 50, 51, 54, 55]\n",
    "video_files_all_df.iloc[row_video_set_num2, 3] = 2\n",
    "video_files_all_df.to_csv(os.path.join(output_path, 'home_video_files_all.csv'))\n",
    "video_files_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a1410-e5b3-4694-b84a-7591b36215cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all video files with brainwalk data \n",
    "video_files_all_w_bw_df = merge_bw_hv(bw_df_ms, video_files_all_df, output_path)\n",
    "video_files_all_w_bw_df.to_csv(os.path.join(output_path, 'home_vids_all_w_bw.csv'))\n",
    "print('rows (participants) in included videos')\n",
    "print(len(video_files_all_w_bw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e3d007-560b-4f1e-9476-c7d3f18109c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format included vids df \n",
    "\n",
    "# add bw id and video date to zv df \n",
    "included_vids['bw_id'] = included_vids['included_vids'].str.extract(r'(BW-\\d{4})')\n",
    "\n",
    "# new idea \n",
    "included_vids['video_date'] = included_vids['included_vids'].str.replace('gait_vertical_left_', '')\n",
    "included_vids['video_date'] = included_vids['video_date'].str.replace('gait_vertical_right_', '')\n",
    "included_vids['video_date'] = included_vids['video_date'].str[8:]\n",
    "included_vids['video_date'] = pd.to_datetime(included_vids['video_date'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db546c94-f968-4ee1-b185-49951de1d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add video num col to included videos df using info from all videos df \n",
    "    # merge/join - video num for each id/date combo in included should match video num for the same id/date combo in all df  \n",
    "print('check same length after merge') \n",
    "print(len(included_vids))\n",
    "video_files_all_to_merge = video_files_all_df.drop_duplicates(subset=['bw_id', 'video_date'])\n",
    "included_vids = included_vids.merge(right = video_files_all_to_merge, how = 'left', on = ['bw_id', 'video_date'])\n",
    "included_vids.to_csv(os.path.join(feas_outpath, 'home_vids_included_in_analysis.csv'))\n",
    "print(len(included_vids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39ad65-402d-47db-8fe0-f6e10f670baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only include unique combo of id, date, and video set num  \n",
    "unique_video_files_all = video_files_all_df.drop_duplicates(subset=['bw_id', 'video_date', 'video_set_num'])\n",
    "unique_included_vids = included_vids.drop_duplicates(subset=['bw_id', 'video_date', 'video_set_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb355c-bb64-430b-bc24-c4ae917cbff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(video_files_all_df))\n",
    "print(len(unique_video_files_all))\n",
    "\n",
    "print(len(included_vids))\n",
    "print(len(unique_included_vids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e3c2c-a69d-4ae7-972d-fece9c023dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants with no videos from a set of videos incuded in analysis \n",
    "    # if they sent two videos on one day and only one was included in analysis, they are counted as \"includd\" \n",
    "    # if all the videos they sent on one day were excluded, they are \"not_included\" \n",
    "\n",
    "# Perform a left join to find matches\n",
    "merged = unique_video_files_all.merge(\n",
    "    unique_included_vids,\n",
    "    on=['video_date', 'bw_id', 'video_set_num'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Filter rows that are in df_all but not in df_included\n",
    "not_included = merged[merged['_merge'] == 'left_only']\n",
    "\n",
    "# Drop the '_merge' column to clean up\n",
    "not_included = not_included.drop(columns=['_merge', 'included_vids', 'file_name_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325923e6-3099-4882-8267-7d9a01076f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge unique_included_vids w bw demographic data \n",
    "included_vids_w_bw = merge_bw_hv(bw_df_ms, unique_included_vids, output_path)\n",
    "included_vids_w_bw.to_csv(os.path.join(output_path, 'home_vids_included_in_analysis_w_bw.csv'))\n",
    "print('rows (participants) in included videos')\n",
    "print(len(included_vids_w_bw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d40f132-8781-42d5-820b-80be1d88bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge not_included w bw demographic data \n",
    "exluded_vids_w_bw = merge_bw_hv(bw_df_ms, not_included, output_path)\n",
    "exluded_vids_w_bw.to_csv(os.path.join(output_path, 'home_vids_excluded_from_analysis_w_bw.csv'))\n",
    "print('rows (participants) in excluded videos')\n",
    "print(len(exluded_vids_w_bw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b799f45-009e-4886-8eff-9440ab5319c5",
   "metadata": {},
   "source": [
    "### compare demographics between included and excluded\n",
    "- TBD on scripts below, may need to fix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906db3c0-6a0a-40a6-9278-b058db3404b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_vids_w_bw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac2652-1daf-49ff-a531-3be646c4084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distribution_var(group1_data, group2_data): \n",
    "    # Test normally distributed  \n",
    "    inc_shapiro_stat, inc_shapiro_p = stats.shapiro(group1_data)\n",
    "    print('group 1 distribution') \n",
    "    print(round(inc_shapiro_p, 3))\n",
    "    if inc_shapiro_p > 0.05:\n",
    "        print(\"Data looks normally distributed (fail to reject H0)\")\n",
    "    else:\n",
    "        print(\"Data does not look normally distributed (reject H0)\")\n",
    "\n",
    "\n",
    "    exc_shapiro_stat, exc_shapiro_p = stats.shapiro(group2_data)\n",
    "    print('group 2 distribution') \n",
    "    print(round(exc_shapiro_p, 3))\n",
    "    if exc_shapiro_p > 0.05:\n",
    "        print(\"Data looks normally distributed (fail to reject H0)\")\n",
    "    else:\n",
    "        print(\"Data does not look normally distributed (reject H0)\")\n",
    "\n",
    "\n",
    "    # test similar variance \n",
    "    print('test similar variance')\n",
    "    statistic, sd_p_value = stats.levene(group1_data, group2_data) \n",
    "    print(sd_p_value)\n",
    "    if sd_p_value > 0.05:\n",
    "        print(\"Fail to reject the null hypothesis: Variances are equal.\")\n",
    "    else:\n",
    "        print(\"Reject the null hypothesis: Variances are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03db76-c893-472b-a55d-1b2bbad500b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demoEHR_DiseaseDuration    \n",
    "    # continous - compare of two groups means, unpaired -> t-test \n",
    "\n",
    "\n",
    "test_distribution_var(group1_data = included_vids_w_bw['demoEHR_DiseaseDuration'], \n",
    "                      group2_data = exluded_vids_w_bw['demoEHR_DiseaseDuration'])\n",
    "\n",
    "plt.hist(included_vids_w_bw['demoEHR_DiseaseDuration'], label = 'included') \n",
    "plt.hist(exluded_vids_w_bw['demoEHR_DiseaseDuration'], label = 'excluded')\n",
    "plt.title('demoEHR_DiseaseDuration')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# t-test \n",
    "print('t-test p val')\n",
    "manwhit_stat_dur, manwhit_p_dur = stats.mannwhitneyu(included_vids_w_bw['demoEHR_DiseaseDuration'], exluded_vids_w_bw['demoEHR_DiseaseDuration'])\n",
    "print(manwhit_p_dur)\n",
    "if manwhit_p_dur > 0.05:\n",
    "    print(\"Fail to reject the null hypothesis: Means are equal.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis: Means are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17500fa-a330-4b53-8681-da655e250968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demoEHR_Age - continous, unpaired, t-test \n",
    "test_distribution_var(group1_data = included_vids_w_bw['demoEHR_Age'], \n",
    "                      group2_data = exluded_vids_w_bw['demoEHR_Age'])\n",
    "\n",
    "plt.hist(included_vids_w_bw['demoEHR_Age'], label = 'included') \n",
    "plt.hist(exluded_vids_w_bw['demoEHR_Age'], label = 'excluded')\n",
    "plt.title('demoEHR_Age')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# t-test \n",
    "print('t-test p val')\n",
    "manwhit_stat_age, manwhit_p_value_age = stats.mannwhitneyu(included_vids_w_bw['demoEHR_Age'], exluded_vids_w_bw['demoEHR_Age'])\n",
    "print(manwhit_p_value_age)\n",
    "if manwhit_p_value_age > 0.05:\n",
    "    print(\"Fail to reject the null hypothesis: Means are equal.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis: Means are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a0166-9aca-40cc-9b93-6ce42066ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msfcEHR_T25FW SPEED AVG      \n",
    "    # continuous - t test \n",
    "test_distribution_var(group1_data = included_vids_w_bw['msfcEHR_T25FW SPEED AVG'], \n",
    "                      group2_data = exluded_vids_w_bw['msfcEHR_T25FW SPEED AVG'])\n",
    "\n",
    "plt.hist(included_vids_w_bw['msfcEHR_T25FW SPEED AVG'], label = 'included') \n",
    "plt.hist(exluded_vids_w_bw['msfcEHR_T25FW SPEED AVG'], label = 'excluded')\n",
    "plt.title('msfcEHR_T25FW SPEED AVG')\n",
    "plt.legend()\n",
    "\n",
    "# man whitney u - no normal \n",
    "print('mann whitney u test p value')\n",
    "man_stat_t25fw, manw_pvalue_t25fw = stats.mannwhitneyu(included_vids_w_bw['msfcEHR_T25FW SPEED AVG'], exluded_vids_w_bw['msfcEHR_T25FW SPEED AVG'],\n",
    "                                          nan_policy='omit') \n",
    "print(manw_pvalue_t25fw)\n",
    "if manw_pvalue_t25fw > 0.05:\n",
    "    print(\"Fail to reject the null hypothesis: Means are equal.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis: Means are not equal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053baea6-2b32-43b4-8cb3-59f99896d8ff",
   "metadata": {},
   "source": [
    "### confirm if right test below? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbaf450-9652-43b9-85f7-720145c915c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bingoEHR_EDSS_measure_value   \n",
    "test_distribution_var(group1_data = included_vids_w_bw['bingoEHR_EDSS_measure_value'], \n",
    "                      group2_data = exluded_vids_w_bw['bingoEHR_EDSS_measure_value'])\n",
    "\n",
    "plt.hist(included_vids_w_bw['bingoEHR_EDSS_measure_value'], label = 'included') \n",
    "plt.hist(exluded_vids_w_bw['bingoEHR_EDSS_measure_value'], label = 'excluded')\n",
    "plt.title('bingoEHR_EDSS_measure_value')\n",
    "plt.legend()\n",
    "\n",
    "# Mann whitney u test ? \n",
    "# man whitney u - no normal \n",
    "print('mann whitney u test p value')\n",
    "man_stat_edss, manw_pvalue_edss = stats.mannwhitneyu(included_vids_w_bw['bingoEHR_EDSS_measure_value'], exluded_vids_w_bw['bingoEHR_EDSS_measure_value'],\n",
    "                                          nan_policy='omit') \n",
    "print(manw_pvalue_edss)\n",
    "if manw_pvalue_edss > 0.05:\n",
    "    print(\"Fail to reject the null hypothesis: Means are equal.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis: Means are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293239ad-b6f2-467c-ad94-e529c6d9223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_freq_table(group1_data, group2_data): \n",
    "    value_counts_df1 = group1_data.value_counts()\n",
    "    value_counts_df2 = group2_data.value_counts()\n",
    "\n",
    "    # Create a contingency table\n",
    "    print('For chi-squared: expected counts should not be less than 2') \n",
    "    print('or no more than 20% of expected values should be less than 5') \n",
    "    print('if assumption not met - use Fishers exact test') \n",
    "    contingency_table = pd.DataFrame({\n",
    "        'DF1': value_counts_df1,\n",
    "        'DF2': value_counts_df2\n",
    "    }).fillna(0)  \n",
    "    print(contingency_table)\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c32aa6-0e68-4d3d-8570-78a07d456768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demoEHR_GENDER     \n",
    "    # chi squared - two cateogrical aoutcomes \n",
    "\n",
    "contingency_table = check_freq_table(group1_data = included_vids_w_bw['clean_sex'], \n",
    "                                     group2_data = exluded_vids_w_bw['clean_sex'])\n",
    "\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Display results\n",
    "print(\"Chi-squared Statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae0beee-cc5c-469b-98db-7043df9757f1",
   "metadata": {},
   "source": [
    "### cofirm appropriate test with such small sample size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d341d6-9c6d-4047-9fa7-3e751f0b2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bingoEHR_DX_MS DX\n",
    "contingency_table2 = check_freq_table(group1_data = included_vids_w_bw['bingoEHR_DX_MS DX'], \n",
    "                                     group2_data = exluded_vids_w_bw['bingoEHR_DX_MS DX'])\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table2)\n",
    "\n",
    "# Display results\n",
    "print(\"Chi-squared Statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefddd2-d0fd-4267-bde5-efabc7b183ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demoEHR_REC_1\n",
    "contingency_table3 = check_freq_table(group1_data = included_vids_w_bw['clean_race'], \n",
    "                                     group2_data = exluded_vids_w_bw['clean_race'])\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table3)\n",
    "\n",
    "# Display results\n",
    "print(\"Chi-squared Statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c2e7f-4a6d-4abe-8dc0-f2984d29e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demoEHR_REC_2 \n",
    "contingency_table4 = check_freq_table(group1_data = included_vids_w_bw['clean_ethnicity'], \n",
    "                                     group2_data = exluded_vids_w_bw['clean_ethnicity'])\n",
    "\n",
    "# Perform chi-squared test\n",
    "chi2, p, dof, expected = stats.chi2_contingency(contingency_table4)\n",
    "\n",
    "# Display results\n",
    "print(\"Chi-squared Statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b0fb1-ab1b-4e23-8034-37a10aca84da",
   "metadata": {},
   "source": [
    "## for below - see demographics table scripts to load consented and all bw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b570b9-7955-430b-bf24-d90c54b099db",
   "metadata": {},
   "outputs": [],
   "source": [
    "error, think demographics might be better than script above for comparing each group \n",
    "check and maybe redo scripts above "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994af00-1b5e-4353-b971-dc3f57b33b2c",
   "metadata": {},
   "source": [
    "### consented vs sent any videos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74e40f-d2ee-496c-94b8-b9018c1b30aa",
   "metadata": {},
   "source": [
    "### consented vs did not consent to home videos \n",
    "- not sure what is appropriate - not everyone approached or asked to send videos? confirm with coordinators "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
