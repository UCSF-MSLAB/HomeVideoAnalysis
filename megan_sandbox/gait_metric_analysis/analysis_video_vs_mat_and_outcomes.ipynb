{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17dcd527-3bf6-4eb3-9c12-f7debb72c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ccb540-2f7e-4d6e-b326-8ca9fabf42d4",
   "metadata": {},
   "source": [
    "# Gait Metric Analysis \n",
    "- For zeno videos: accuracy of video metrics vs mat metrics\n",
    "- For zeno and home videos: associations of video metrics with clinical outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5fbdf-17c4-4778-be5d-608fbf883466",
   "metadata": {},
   "source": [
    "# Define Analysis Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92dfca59-601b-4fce-a880-ebfdb5f0a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ordinal value of EDSS severity \n",
    "# 0-2 (mild), 2.5-4 (moderate), 4.5+ (severe)\n",
    "\n",
    "# Function to categorize EDSS severity\n",
    "def categorize_edss(edss_value):\n",
    "    if 0 <= edss_value <= 2:\n",
    "        return 1, 'mild'\n",
    "    elif 2.5 <= edss_value <= 4:\n",
    "        return 2, 'moderate'\n",
    "    elif edss_value >= 4.5:\n",
    "        return 3, 'severe'\n",
    "    else:\n",
    "        return None, None  # Handle cases outside the defined ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5210fe62-0199-461c-81c9-a35b61d5c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ordinal value for T25FW \n",
    "def categorize_t25fw(t25fw_value):\n",
    "    if 0 <= t25fw_value < 6:\n",
    "        return 1, 'under_6'\n",
    "    elif 6 <= t25fw_value <= 7.99:\n",
    "        return 2, '6_to_8'\n",
    "    elif t25fw_value >= 8:\n",
    "        return 3, 'over_8'\n",
    "    else:\n",
    "        return None, None  # Handle cases outside the defined ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf7737a-517f-44de-9b24-86c8a492998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = gait_vertical_PWS_1 or gait_vertical_FW_1\n",
    "def merge_bw_zv(bw_df, zv_df, task, out_path):\n",
    "\n",
    "    # filter zv to only include one task (bw drop columns, zv drop rows) \n",
    "    zv_task_df = zv_df[zv_df['task_pose_zv'] == task]\n",
    "    print('confirm all one task')\n",
    "    print(pd.unique(zv_task_df['task_pose_zv']))\n",
    "\n",
    "    print('total zeno videos') \n",
    "    print(len(zv_task_df))\n",
    "\n",
    "    # drop bw columns to only include one task \n",
    "    if task == 'gait_vertical_PWS_1':\n",
    "        bw_df = bw_df.drop(['FW_stridetimesecmean', 'FW_stridetimeseccv','FW_cadencestepsminmean','FW_totaldsupportmean', \n",
    "                            'FW_singlesupportmean','FW_totaldsupportratiolr', 'FW_singlesupportratiolr', \n",
    "                            'FW_stridewidthcmmean','FW_stridewidthcmsd'], axis = 1)\n",
    "    elif task == 'gait_vertical_FW_1':\n",
    "         bw_df = bw_df.drop(['PWS_stridetimesecmean', 'PWS_stridetimeseccv','PWS_cadencestepsminmean','PWS_totaldsupportmean', \n",
    "                             'PWS_singlesupportmean','PWS_totaldsupportratiolr', 'PWS_singlesupportratiolr', \n",
    "                             'PWS_stridewidthcmmean','PWS_stridewidthcmsd'], axis = 1)\n",
    "        \n",
    "\n",
    "    # filter bw ids dataset to only those included in video data set \n",
    "    zv_in_bw_df = bw_df[bw_df['bw_id'].isin(zv_task_df['id_video'])]\n",
    "    zv_in_bw_df.to_csv(os.path.join(out_path, 'zv_id_in_bw_df_' + task + '.csv')) # save excel \n",
    "\n",
    "    print('total bw rows with id in video dataset') \n",
    "    print(len(zv_in_bw_df))\n",
    "\n",
    "    # merge bw data set rows with zeno videos rows \n",
    "        # merge bw data set rows with zeno videos rows \n",
    "        # id and date needs to be the same \n",
    "        # should only use each brainwalk visit once - once PWS_1 video per person \n",
    "\n",
    "    merged_bw_zv = []\n",
    "\n",
    "    # Loop through each row in zv_task_df\n",
    "    for index, zv_row in zv_task_df.iterrows():\n",
    "   \n",
    "        current_id = zv_row['id_video']\n",
    "        current_date = zv_row['visit_date_video']\n",
    "        zv_row_df = pd.DataFrame([zv_row])\n",
    "\n",
    "        # Find rows in brainwalk data set with same id and same date as current zv data \n",
    "        zv_in_bw_current_id_rows = zv_in_bw_df[(zv_in_bw_df['bw_id'] == current_id) & (zv_in_bw_df['visit_date'] == current_date)]\n",
    "        #zv_in_bw_current_id_date_rows = zv_in_bw_current_id_rows[zv_in_bw_current_id_rows['visit_date'] == current_date]\n",
    "   \n",
    "        if len(zv_in_bw_current_id_rows) == 1: \n",
    "            bw_row_to_merge = zv_in_bw_current_id_rows\n",
    "            # merge bw and zv, store merged row\n",
    "            merged_row = zv_row_df.merge(bw_row_to_merge, left_on='id_video', right_on='bw_id')\n",
    "            merged_bw_zv.append(merged_row)\n",
    "        \n",
    "        # if more than one row for the id and date, pick one with least na values \n",
    "        elif len(zv_in_bw_current_id_rows) > 1:\n",
    "            bw_row_to_merge = zv_in_bw_current_id_rows.loc[[zv_in_bw_current_id_rows.isna().sum(axis=1).idxmin()]]\n",
    "            # merge bw and zv, store merged row\n",
    "            merged_row = zv_row_df.merge(bw_row_to_merge, left_on='id_video', right_on='bw_id')\n",
    "            merged_bw_zv.append(merged_row)\n",
    "\n",
    "            print('multiple rows for the id and date combo')\n",
    "            print(current_id)\n",
    "            print(current_date)\n",
    "\n",
    "        else: \n",
    "            print('No matching id and daterow from video vs mat')\n",
    "            print(current_id)\n",
    "            print(current_date)\n",
    "\n",
    "\n",
    "    # merge all bw and zv data together \n",
    "    merged_bw_zv_df = pd.concat(merged_bw_zv)\n",
    "    merged_bw_zv_df = merged_bw_zv_df.reset_index(drop=True) # reset index \n",
    "\n",
    "    # check same ID for each row \n",
    "    print('mismatched zeno video vs brainwalk id')\n",
    "    print(sum(merged_bw_zv_df['id_video'] != merged_bw_zv_df['bw_id']))\n",
    "\n",
    "    print('mismatched zeno video vs brainwalk date')\n",
    "    print(sum(merged_bw_zv_df['visit_date_video'] != merged_bw_zv_df['visit_date']))\n",
    "\n",
    "    # saved merged df for future reference \n",
    "    merged_bw_zv_df.to_csv(os.path.join(out_path,  'zv_bw_merged_' + task + '.csv'))\n",
    "\n",
    "    return merged_bw_zv_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ef8a0e-b80e-45cf-813b-4beeaa2213b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge home video data with preferred walking speed mat data \n",
    "# participants walk at preferred pace at home \n",
    "\n",
    "def merge_bw_hv(bw_df, hv_df, task, out_path):\n",
    "    # filter zv to only include one task (bw drop columns, zv drop rows) \n",
    "    hv_task_df = hv_df[hv_df['task_pose_hv'] == task]\n",
    "    print('confirm all one task')\n",
    "    print(pd.unique(hv_task_df['task_pose_hv']))\n",
    "\n",
    "    print('total home videos') \n",
    "    print(len(hv_task_df))\n",
    "\n",
    "    # drop FW data from bw dataset \n",
    "   # bw_df = bw_df.drop(['FW_stridetimesecmean', 'FW_stridetimeseccv','FW_cadencestepsminmean','FW_totaldsupportmean',\n",
    "                     #   'FW_singlesupportmean','FW_totaldsupportratiolr', 'FW_singlesupportratiolr', \n",
    "                     #   'FW_stridewidthcmmean','FW_stridewidthcmsd'], axis = 1)\n",
    "\n",
    "    # filter bw ids dataset to only those included in video data set \n",
    "    hv_in_bw_df = bw_df[bw_df['bw_id'].isin(hv_task_df['id_video'])]\n",
    "    hv_in_bw_df.to_csv(os.path.join(out_path, 'hv_id_in_bw_df.csv')) # save excel \n",
    "\n",
    "    print('total bw rows with id in video dataset') \n",
    "    print(len(hv_in_bw_df))\n",
    "\n",
    "    # Track used rows from zv_in_bw_df\n",
    "    used_indices = set()\n",
    "\n",
    "    # Helper function to find the closest date\n",
    "    def find_closest_date_unique(row, in_bw_df):\n",
    "        # Filter rows with the same 'bw_id' and not already used\n",
    "        filtered_df = in_bw_df[(in_bw_df['bw_id'] == row['id_video'])] # & (~in_bw_df.index.isin(used_indices)) - add after video'] for unique only\n",
    "        if filtered_df.empty:\n",
    "            return None\n",
    "        \n",
    "        # Find the closest date\n",
    "        closest_idx = (filtered_df['visit_date'] - row['visit_date_video']).abs().idxmin()\n",
    "       # used_indices.add(closest_idx)  # Mark the row as used\n",
    "        return filtered_df.loc[closest_idx]\n",
    "\n",
    "    # Apply the helper function row-wise\n",
    "    closest_rows = hv_task_df.apply(\n",
    "        lambda row: find_closest_date_unique(row, hv_in_bw_df), axis=1\n",
    "    )\n",
    "    \n",
    "    # Convert the results into a DataFrame\n",
    "   # closest_rows_df = pd.DataFrame(closest_rows.tolist(), index=hv_task_df.index)\n",
    "\n",
    "    # Merge the original `zv_task_df` with `closest_rows_df`\n",
    "    merged_bw_hv_df = hv_task_df.merge(closest_rows, left_index=True, right_index=True, suffixes=('', '_closest'))\n",
    "\n",
    "    # add column for date diff \n",
    "    merged_bw_hv_df['bw_hv_abs_date_diff'] = abs(merged_bw_hv_df['visit_date'] - merged_bw_hv_df['visit_date_video'])\n",
    "    \n",
    "    # check same ID for each row \n",
    "    print('mismatched home video vs brainwalk id')\n",
    "    print(sum(merged_bw_hv_df['id_video'] != merged_bw_hv_df['bw_id']))\n",
    "    \n",
    "    return merged_bw_hv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d52986d6-49e3-4e4f-969e-cbef4138d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df input should be merged df - both video and bw data \n",
    "\n",
    "def print_video_counts(df):\n",
    "    # number of zeno videos and participants included \n",
    "    print('total videos - df length: ' + \n",
    "          str(len(df))) \n",
    "\n",
    "    print('unique demographic_diagnosis in df: ' + \n",
    "         str(pd.unique(df['demographic_diagnosis'])))\n",
    "    \n",
    "    print('num videos with demographic_diagnosis == HC: ' + \n",
    "         str(len(df[df['demographic_diagnosis'] == 'HC']))) \n",
    "\n",
    "    print('num videos demographic_diagnosis == MS: ' + \n",
    "         str(len(df[df['demographic_diagnosis'] == 'MS']))) \n",
    "\n",
    "    print('------')\n",
    "\n",
    "    print('unique id_video (participants) in df: ' + \n",
    "          str(len(pd.unique(df['id_video'])))) \n",
    "\n",
    "    print('num participants with demographic_diagnosis == HC: ' + \n",
    "         str(len(pd.unique(df['id_video'][df['demographic_diagnosis'] == 'HC'])))) \n",
    "    \n",
    "    print('num participants demographic_diagnosis == MS: ' + \n",
    "         str(len(pd.unique(df['id_video'][df['demographic_diagnosis'] == 'MS']))))\n",
    "\n",
    "    print('------') \n",
    "    \n",
    "    print('number of participants with multiple videos in dataset: ' + \n",
    "         str(df['id_video'][df['id_video'].duplicated()].nunique()))\n",
    "\n",
    "    print('number of participants with one video: ' + \n",
    "          str((df['id_video'].value_counts() == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230ebae8-f41c-46c6-8731-d9f7a0139164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols to check \n",
    "    # string, either - PWS, FW, t25fw, or edss \n",
    "\n",
    "def drop_cols_missing_data(df, cols_to_check):\n",
    "    # drop row if all PWS mat vars are nan\n",
    "    if cols_to_check == 'pws': \n",
    "        subset_columns = ['PWS_stridetimesecmean',\n",
    "                          'PWS_stridetimeseccv',\n",
    "                          'PWS_cadencestepsminmean',\n",
    "                          'PWS_totaldsupportmean',\n",
    "                          'PWS_singlesupportmean', \n",
    "                          'PWS_totaldsupportratiolr',\n",
    "                          'PWS_singlesupportratiolr',\n",
    "                          'PWS_stridewidthcmmean', \n",
    "                          'PWS_stridewidthcmsd']\n",
    "\n",
    "    # drop row if all FW mat vars are nan \n",
    "    elif cols_to_check == 'fw':\n",
    "        subset_columns = ['FW_stridetimesecmean',\n",
    "                          'FW_stridetimeseccv',\n",
    "                          'FW_cadencestepsminmean',\n",
    "                          'FW_totaldsupportmean',\n",
    "                          'FW_singlesupportmean', \n",
    "                          'FW_totaldsupportratiolr',\n",
    "                          'FW_singlesupportratiolr',\n",
    "                          'FW_stridewidthcmmean', \n",
    "                          'FW_stridewidthcmsd']\n",
    "        \n",
    "    # drop row if edss is nan\n",
    "    elif cols_to_check == 'edss':\n",
    "        subset_columns = ['bingoEHR_EDSS_measure_value']\n",
    "\n",
    "    # drop row is tw5fw is nan \n",
    "    elif cols_to_check == 't25fw':\n",
    "        subset_columns = ['msfcEHR_T25FW SPEED AVG']\n",
    "\n",
    "    df_missing_rows_dropped = df.dropna(axis = 0, \n",
    "                                        how = 'all',\n",
    "                                        subset = subset_columns)\n",
    "\n",
    "    return df_missing_rows_dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeada4be-d309-47a9-a0a3-69ad6eabb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normality: histograms and shapiro test \n",
    "def hist_and_shapiro(df, hist_out_path): \n",
    "    results = []\n",
    "    histogram_folder = os.path.join(hist_out_path, 'histograms')\n",
    "    if not os.path.exists(histogram_folder):\n",
    "        os.makedirs(histogram_folder)\n",
    "\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'float64':\n",
    "            # histogram \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(df[column], bins=30, color='skyblue', edgecolor='black')\n",
    "            plt.title(f'Histogram of {column}')\n",
    "            plt.xlabel(column)\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(histogram_folder, f'{column}.png'))\n",
    "            plt.close()\n",
    "\n",
    "            # shapiro wilks test \n",
    "            # check for missing data \n",
    "            non_missing_data = df[column].dropna()\n",
    "            n = len(non_missing_data) \n",
    "\n",
    "            if n > 3: \n",
    "                # Perform Shapiro-Wilk test\n",
    "                stat, p_value = stats.shapiro(non_missing_data)  \n",
    "            else: \n",
    "                stat = np.nan\n",
    "                p_value = np.nan \n",
    "            \n",
    "            results.append({'Column': column, 'non_missing_observations': n, 'Statistic': stat, 'P-value': p_value})\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    shapiro_results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # if p value less than 0.05, data is not normally distributed \n",
    "    shapiro_results_df['normal'] = shapiro_results_df['P-value'].apply(lambda x: 'no' if x < .05 else 'yes')\n",
    "    shapiro_results_df['test'] = shapiro_results_df['P-value'].apply(lambda x: 'spearman' if x < .05 else 'pearson')\n",
    "    shapiro_results_df.round(3)\n",
    "    \n",
    "    return(shapiro_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db504ab-edfd-4d96-afb1-525f5f8dfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of same metrics from difference data sources \n",
    "\n",
    "def metric_correlation(df, video_columns, bw_columns, output_folder_path): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    # create empty list to store results \n",
    "    corr_results_all = [] \n",
    "    clean_df = pd.DataFrame() \n",
    "    \n",
    "    for metric_i, current_metric in enumerate(video_columns): \n",
    "        current_vid_col = video_columns[metric_i]\n",
    "        current_bw_col = bw_columns[metric_i]\n",
    "\n",
    "        # Drop rows with NaN values in either column - required to run spearman r \n",
    "        clean_df = df.dropna(subset=[current_vid_col, current_bw_col])\n",
    "        \n",
    "        # plot \n",
    "        #sns.lmplot(x = current_bw_col, y = current_vid_col, data = clean_df, ci = None)\n",
    "        sns.scatterplot(x = current_bw_col, y = current_vid_col, data = clean_df)\n",
    "        # Set the x and y axis limits to the same range\n",
    "     #   plt.axis('square')  \n",
    "      #  min_val = min(clean_df[current_vid_col].min(), clean_df[current_vid_col].min())  \n",
    "      #  max_val = max(clean_df[current_vid_col].max(), clean_df[current_vid_col].max())  \n",
    "      #  plt.xlim(min_val, max_val)\n",
    "      #  plt.ylim(min_val, max_val) \n",
    "        plt.savefig(os.path.join(output_folder_path, str(current_vid_col + '_vs_' + current_bw_col + '.png')))\n",
    "        plt.close()\n",
    "\n",
    "        # run spearman correlation and append   \n",
    "        statistic, p_value = stats.spearmanr(clean_df[current_bw_col], clean_df[current_vid_col])\n",
    "        corr_results_all.append({'bw_column': current_bw_col, \n",
    "                                 'video_column': current_vid_col, \n",
    "                                 'corr_method': 'spearman' , \n",
    "                                 'rs': statistic, \n",
    "                                 'p_value' : p_value,\n",
    "                                 'n observations': len(clean_df)})\n",
    "\n",
    "    # Create DataFrame with results\n",
    "    corr_results_df = pd.DataFrame(corr_results_all)\n",
    "    corr_results_df = corr_results_df.round(3)\n",
    "\n",
    "    return corr_results_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df230d94-7571-4f14-9679-ca67a840df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same columns as metric correlations \n",
    "def calculate_metric_mean_error(df, video_columns, bw_columns, units, output_folder_path):\n",
    "    # one dot = participant \n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path) \n",
    "        \n",
    "    mean_error_all = [] \n",
    "\n",
    "    for metric_i, current_metric in enumerate(video_columns): \n",
    "        current_vid_col = video_columns[metric_i]\n",
    "        current_bw_col = bw_columns[metric_i]\n",
    "        current_unit = units[metric_i]\n",
    "\n",
    "        # Drop rows with NaN values in either column \n",
    "        clean_df = df.dropna(subset=[current_vid_col, current_bw_col])\n",
    "\n",
    "        current_metric_diff = clean_df[current_bw_col] - clean_df[current_vid_col]\n",
    "        current_mean_diff = current_metric_diff.mean()\n",
    "        current_abs_mean_diff = abs(current_metric_diff).mean()\n",
    "\n",
    "        # calculate mean ground truth data \n",
    "        bw_mean = clean_df[current_bw_col].mean()\n",
    "        mean_err_per = (current_mean_diff / bw_mean) * 100 \n",
    "        mae_per = (current_abs_mean_diff / bw_mean) * 100 \n",
    "\n",
    "        # plot \n",
    "        fig, ax1 = plt.subplots()\n",
    "        sns.boxplot(y=current_metric_diff, ax=ax1, fill = False, dodge = True, fliersize = 0)\n",
    "        sns.stripplot(y = current_metric_diff, ax = ax1, color = 'black', dodge = True)\n",
    "        fig.suptitle('Mat Metric - Video Metric')\n",
    "        ax1.set_title(current_bw_col + ' - ' + current_vid_col)\n",
    "        # center plot at zero\n",
    "        ymin, ymax = plt.ylim()\n",
    "        plt.ylim(min(ymin, -ymax), max(ymax, -ymin))\n",
    "        plt.ylabel(current_unit)\n",
    "        # add line at zero\n",
    "        plt.axhline(y=0, color='grey', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder_path, str(current_vid_col + '_vs_' + current_bw_col + '_diff_box.png')))\n",
    "        plt.close()\n",
    "\n",
    "        # mean difference \n",
    "        mean_error_all.append({'bw_column': current_bw_col, \n",
    "                               'video_column': current_vid_col,\n",
    "                               'n' : len(clean_df), \n",
    "                               'bw_metric_mean' : bw_mean,\n",
    "                               'mean_error': current_mean_diff, \n",
    "                               'mean_abs_error' : current_abs_mean_diff, \n",
    "                               'mean_error_%_of_mean' : mean_err_per,\n",
    "                               'mae_%_of_mean' : mae_per})\n",
    "\n",
    "    \n",
    "     # Create DataFrame with results\n",
    "    mean_error_df = pd.DataFrame(mean_error_all)\n",
    "    mean_error_df = mean_error_df.round(3)\n",
    "    \n",
    "    return mean_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0813fa-e903-4806-ab12-771b8746d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use same columns as metric correlation \n",
    "\n",
    "def bland_altman_plot(df, video_columns, bw_columns, units, output_folder_path):\n",
    "     \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    for metric_i, current_metric in enumerate(video_columns): \n",
    "        current_bw_col = bw_columns[metric_i]\n",
    "        current_vid_col = video_columns[metric_i]\n",
    "        current_unit = current_unit = units[metric_i]\n",
    "\n",
    "        clean_df = df.dropna(subset=[current_vid_col, current_bw_col])\n",
    "\n",
    "    \n",
    "        # Compute the mean and the difference\n",
    "        mean_measurements = (clean_df[current_bw_col] + clean_df[current_vid_col]) / 2\n",
    "        diff_measurements = clean_df[current_bw_col] - clean_df[current_vid_col]  # Difference between measurements\n",
    "\n",
    "        # Mean difference and standard deviation of the difference\n",
    "        mean_diff = np.mean(diff_measurements)\n",
    "        std_diff = np.std(diff_measurements)\n",
    "\n",
    "        # Plot the data\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(mean_measurements, diff_measurements, alpha=0.5)\n",
    "    \n",
    "        # Add mean difference line and limits of agreement (±1.96*std)\n",
    "        plt.axhline(mean_diff, color='black', linestyle='--', label=f'Mean diff: {mean_diff:.2f}')\n",
    "        plt.axhline(mean_diff + 1.96 * std_diff, color='red', linestyle='--', label=f'+1.96 SD: {mean_diff + 1.96 * std_diff:.2f}')\n",
    "        plt.axhline(mean_diff - 1.96 * std_diff, color='blue', linestyle='--', label=f'-1.96 SD: {mean_diff - 1.96 * std_diff:.2f}')\n",
    "        plt.axhline(y=0, color='grey', linestyle='--')\n",
    "    \n",
    "        # Labels and title\n",
    "        plt.xlabel('Mean of Zeno Mat vs Video Pose Metric (' + current_unit + ')') \n",
    "        plt.ylabel('Zeno mat - Video Pose Metric (' + current_unit + ')')\n",
    "        plt.title(current_bw_col + ' vs ' + current_vid_col)\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_folder_path,  str(current_vid_col + '_vs_' + current_bw_col + '_blandalt.png')))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d6d762-9181-49a0-8cd4-a2f46fa74e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation with clinical outcomes \n",
    "def outcome_correlation(df, output_folder_path, video_task_str, outcome_str): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    if not os.path.exists(os.path.join(output_folder_path, 'edss_plot')):\n",
    "        os.makedirs(os.path.join(output_folder_path, 'edss_plot'))\n",
    "\n",
    "    if not os.path.exists(os.path.join(output_folder_path, 't25fw_plot')):\n",
    "        os.makedirs(os.path.join(output_folder_path, 't25fw_plot'))\n",
    "\n",
    "    # drop date time columns \n",
    "    if 'bw_hv_abs_date_diff' in df.columns:\n",
    "        df = df.drop(columns=['bw_hv_abs_date_diff'])\n",
    "        \n",
    "    # drop nonnumeric columns \n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    ordinal_cols = df.select_dtypes(include=['category']).columns\n",
    "\n",
    "    # Keep only numeric and ordinal columns\n",
    "    df_num = df[numeric_cols.union(ordinal_cols)]\n",
    "\n",
    "    # Create an empty DataFrame to store the Spearman correlation coefficients\n",
    "    n_cols = df_num.shape[1]\n",
    "\n",
    "    corr_matrix = pd.DataFrame(np.zeros((n_cols, n_cols)), columns=df_num.columns, index=df_num.columns)\n",
    "    pvalue_matrix = pd.DataFrame(np.zeros((n_cols, n_cols)), columns=df_num.columns, index=df_num.columns)\n",
    "    n_videos_matrix = pd.DataFrame(np.zeros((n_cols, n_cols)), columns=df_num.columns, index=df_num.columns)\n",
    "    \n",
    "    # Compute Spearman correlation for each pair of columns\n",
    "    for col1 in df_num.columns:\n",
    "        for col2 in df_num.columns:\n",
    "            # drop rows if col1 and col2 are both nan\n",
    "            df_num_clean = df.dropna(subset=[col1, col2])\n",
    "\n",
    "            # spearman correlation \n",
    "            corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
    "\n",
    "            # save results in matrix \n",
    "            corr_matrix.loc[col1, col2] = corr\n",
    "            pvalue_matrix.loc[col1, col2] = p_value\n",
    "            n_videos_matrix.loc[col1, col2] = len(df_num_clean) # number of rows with data for both columns \n",
    "\n",
    "            if col1 == 'bingoEHR_EDSS_measure_value':\n",
    "                sns.scatterplot(data=df_num_clean, x=col1, y=col2) \n",
    "                plt.savefig(os.path.join(output_folder_path, 'edss_plot', str(video_task_str + '_' + col2 + '.png')))\n",
    "                plt.close()\n",
    "\n",
    "            if col1 == 'msfcEHR_T25FW SPEED AVG': \n",
    "                sns.scatterplot(data=df_num_clean, x=col1, y=col2) \n",
    "                plt.savefig(os.path.join(output_folder_path, 't25fw_plot', str(video_task_str + '_' + col2 + '.png')))\n",
    "                plt.close()\n",
    "\n",
    "    #  Plot and save the heatmap \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, annot=False, cmap=\"coolwarm\", center=0)\n",
    "    plt.title(\"Spearman Rank Correlation Heatmap\")\n",
    "    plt.savefig(os.path.join(output_folder_path,  video_task_str + '_' + outcome_str + '_heatmap.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # select specific columns from the three matrices and concatenate into single data frame \n",
    "    if outcome_str == 'edss': \n",
    "        corr_df = pd.concat([corr_matrix['bingoEHR_EDSS_measure_value'],\n",
    "                             pvalue_matrix['bingoEHR_EDSS_measure_value'],\n",
    "                             n_videos_matrix['bingoEHR_EDSS_measure_value'],\n",
    "                             corr_matrix['edss_severity_cat'],\n",
    "                             pvalue_matrix['edss_severity_cat'],\n",
    "                             n_videos_matrix['edss_severity_cat']],\n",
    "                            axis = 1)\n",
    "        \n",
    "        corr_df.columns = ['edss_score_statistic', 'edss_score_p_value', 'edss_score_n_videos',\n",
    "                           'edss_severity_cat_statistic', 'edss_severity_cat_p_value', 'edss_severity_n_videos']\n",
    "\n",
    "    elif outcome_str == 't25fw': \n",
    "        corr_df = pd.concat([corr_matrix['msfcEHR_T25FW SPEED AVG'],\n",
    "                             pvalue_matrix['msfcEHR_T25FW SPEED AVG'],\n",
    "                             n_videos_matrix['msfcEHR_T25FW SPEED AVG']], \n",
    "                     axis = 1)\n",
    "        \n",
    "        corr_df.columns = ['t25fw_correlation_statistic', 't25fw_correlation_p_value', 't25fw_correlation_n_videos']\n",
    "\n",
    "\n",
    "    corr_df = corr_df.round(3)\n",
    "\n",
    "    return corr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a60147-243e-44dc-91f4-8695c3249ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ttest_anova_assumptions(df, group_col, vid_metric_col_suffix, mat_metric_col_prefix, output_folder_path, video_task_str): \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only video metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, \n",
    "        df_metrics.columns.str.endswith(vid_metric_col_suffix) | df_metrics.columns.str.startswith(mat_metric_col_prefix)]\n",
    "\n",
    "    # count number of cateogries in group_col \n",
    "    x_cat_groups = df[group_col].unique()\n",
    "    print('groups')\n",
    "    print(x_cat_groups)\n",
    "\n",
    "    # create save folder for histograms \n",
    "    if not os.path.exists(os.path.join(output_folder_path, 'check_normality')):\n",
    "        os.makedirs(os.path.join(output_folder_path, 'check_normality'))\n",
    "    \n",
    "    # loop through each metric column and plot vs group_col variable histogram \n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns): \n",
    "\n",
    "        # check normality of each y column, grouped by current x value \n",
    "        plt.figure(figsize = (10,6))\n",
    "\n",
    "        # Save for storing shapiro results and standard deviation \n",
    "        results_text_on_plot = []\n",
    "        \n",
    "        for current_group in x_cat_groups: \n",
    "            current_group_values = df[df[group_col] == current_group][current_metric_col]\n",
    "            sns.histplot(data = current_group_values, alpha = 0.5, label = f'Group {current_group}')\n",
    "\n",
    "            if current_group_values.count() > 3:\n",
    "                # perform shapiro walks test for normality \n",
    "                stat, p_value = stats.shapiro(current_group_values, nan_policy='omit')\n",
    "                # save standard deviation for each group \n",
    "                sd = current_group_values.std(skipna = True)\n",
    "                \n",
    "            else:  \n",
    "                stat = np.nan\n",
    "                p_value = np.nan\n",
    "                sd = np.nan\n",
    "\n",
    "            results_text_on_plot.append((current_group, np.round(stat, decimals=3), np.round(p_value, decimals = 3), np.round(sd, decimals = 3)))\n",
    "\n",
    "        # plot title and legend \n",
    "        plt.title('Metric Values by group') \n",
    "        plt.legend()\n",
    "        \n",
    "        # Annotate Shapiro-Wilk results on the plot\n",
    "        plt.text(0.05, 0.95, 'Hypothesis test assumptions', transform=plt.gca().transAxes)\n",
    "        text_y_position = 0.9  # Start near the top of the plot\n",
    "        for result in results_text_on_plot:\n",
    "            current_group, stat, p_value, sd = result\n",
    "            plt.text(\n",
    "                0.05, text_y_position, \n",
    "                f'Group {current_group}: Shapiro Stat ={stat}, Shapiro p={p_value}, SD = {sd}', \n",
    "                transform=plt.gca().transAxes\n",
    "            )\n",
    "            text_y_position -= 0.05  # Move down for the next annotation\n",
    "        \n",
    "        plt.savefig(os.path.join(output_folder_path, 'check_normality', current_metric_col + '_hist.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c9df0d-dcf5-4619-81c0-f74a6b640492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_cat_allmetrics(df, group_col, metric_col_suffix, output_folder_path, video_task_str): \n",
    "\n",
    "    # create save folder for boxplots \n",
    "    if not os.path.exists(os.path.join(output_folder_path, 'all_video_metrics')):\n",
    "        os.makedirs(os.path.join(output_folder_path, 'all_video_metrics'))\n",
    "    \n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "\n",
    "    # loop through each metric column and plot boxplot with individual data points, grouped by group_col on x axis \n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns): \n",
    "        \n",
    "        # BOXPLOT \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.boxplot(data=df, x=group_col, y=current_metric_col, width = 0.75, fliersize=0,  fill = False)\n",
    "        # Add in points to show each observation\n",
    "        sns.stripplot(data=df, x=group_col, y=current_metric_col, size=4, color=\".3\")\n",
    "        ax.set_title(f'{current_metric_col} vs {group_col}') \n",
    "\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "        # Save the plot\n",
    "        fig_path = os.path.join(output_folder_path, 'all_video_metrics', video_task_str + '_' + current_metric_col + '.png')\n",
    "        fig.savefig(fig_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8bb7b4-4931-4018-b7bb-35239eb82fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann whitney U function - loop through all y vals \n",
    "def mannwhitneyu_all_metrics(df, group_col, group_1, group_2, metric_col_suffix, output_folder_path, video_task_str): \n",
    "    \n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "\n",
    "    # loop through each metric column, group by group 1 or two, run mann whitney on this group \n",
    "    stats_results = []\n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns): \n",
    "        group1_data = df[df[group_col] == group_1][current_metric_col]\n",
    "        group1_n = group1_data.count()\n",
    "        group2_data = df[df[group_col] == group_2][current_metric_col] \n",
    "        group2_n = group2_data.count()\n",
    "        U1, p = stats.mannwhitneyu(group1_data, group2_data, nan_policy='omit')\n",
    "        stats_results.append((current_metric_col, group_col, \n",
    "                              group_1, group1_n, \n",
    "                              round(group1_data.mean(),3),round(group1_data.median(),3), round(group1_data.std(),3),\n",
    "                              group_2, group2_n, \n",
    "                              round(group2_data.mean(),3),round(group2_data.median(),3), round(group2_data.std(),3),\n",
    "                              'mannwhitneyu', round(U1, 3), round(p, 3)))\n",
    "\n",
    "    # create save folder for excel  \n",
    "    if not os.path.exists(os.path.join(output_folder_path, 'all_video_metrics')):\n",
    "        os.makedirs(os.path.join(output_folder_path, 'all_video_metrics'))\n",
    "\n",
    "    stats_results_df = pd.DataFrame(stats_results, columns = ['metric', group_col, \n",
    "                                                              'group1', 'group1_n', \n",
    "                                                              'group1_mean', 'group1_median', 'group1_std',\n",
    "                                                              'group2', 'group2_n', \n",
    "                                                              'group2_mean', 'group2_median', 'group2_std',\n",
    "                                                              'stats_test', \n",
    "                                                              'U1', 'p'])\n",
    "    \n",
    "    stats_results_df.to_csv(os.path.join(output_folder_path, 'all_video_metrics', 'mannwhitney_' + video_task_str + '.csv'))\n",
    "    return(stats_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeedc929-041c-402b-a461-80242c3f1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal Wallace and Dunn's test function for three groups \n",
    "def kruskalwallace_all_metrics(df, group_col, group_1, group_2, group_3, metric_col_suffix, output_folder_path, video_task_str):\n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics\n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "\n",
    "    # loop through each metric column, group by three groups and run kruskal wallace \n",
    "    stats_results = []\n",
    "    for col_i, current_metric_col in enumerate(df_metrics.columns):\n",
    "        group1_data = df[df[group_col] == group_1][current_metric_col]\n",
    "        group1_n = group1_data.count()\n",
    "        group2_data = df[df[group_col] == group_2][current_metric_col]\n",
    "        group2_n = group2_data.count()\n",
    "        group3_data = df[df[group_col] == group_3][current_metric_col]\n",
    "        group3_n = group3_data.count()\n",
    "         \n",
    "        H_stat, p = stats.kruskal(group1_data, group2_data, group3_data, nan_policy = 'omit') \n",
    "        stats_results.append((current_metric_col, group_col, \n",
    "                              group_1, group1_n, \n",
    "                              round(group1_data.mean(),3),round(group1_data.median(),3), round(group1_data.std(),3),\n",
    "                              group_2, group2_n,\n",
    "                              round(group2_data.mean(),3),round(group2_data.median(),3), round(group2_data.std(),3),\n",
    "                              group_3, group3_n,\n",
    "                              round(group3_data.mean(),3),round(group3_data.median(),3), round(group3_data.std(),3),\n",
    "                              'kruskal', round(H_stat, 3), round(p, 3))) \n",
    "\n",
    "    # save results for each metric\n",
    "    stats_results_df = pd.DataFrame(stats_results, \n",
    "                                    columns = ['metric', group_col, \n",
    "                                               'group1', 'group1_n', \n",
    "                                               'group1_mean', 'group1_median', 'group1_std',\n",
    "                                               'group2', 'group2_n', \n",
    "                                               'group2_mean', 'group2_median', 'group2_std',\n",
    "                                               'group3', 'group3_n',\n",
    "                                               'group3_mean', 'group3_median', 'group3_std',\n",
    "                                               'stats_test', 'H', 'p'])\n",
    "\n",
    "\n",
    "    # create save folder for excel  \n",
    "    if not os.path.exists(os.path.join(output_folder_path, 'all_video_metrics')):\n",
    "        os.makedirs(os.path.join(output_folder_path,'all_video_metrics'))\n",
    "        \n",
    "    stats_results_df.to_csv(os.path.join(output_folder_path, 'all_video_metrics', 'kruskal_' + video_task_str + '.csv'))\n",
    "    return(stats_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0c60014-73a2-4887-8be9-b7ff7191249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_vid_and_mat_inperson(video_pws_columns, video_fw_columns, mat_pws_columns, \n",
    "                                   mat_fw_columns, pws_data, fw_data, group_col,\n",
    "                                   output_folder_path):\n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    # preferred walking speed ----------------------------------\n",
    "    for metric_i, current_metric in enumerate(video_pws_columns):\n",
    "        current_vid_pws_column = video_pws_columns[metric_i]\n",
    "        current_mat_pws_column = mat_pws_columns[metric_i]\n",
    "\n",
    "        # only select vars needed for plotting \n",
    "        subset_pws_df = pws_data.loc[:, ['id_date_pose_zv', 'task_pose_zv', group_col, current_vid_pws_column, current_mat_pws_column]]\n",
    "\n",
    "        # rename var - add pws to be able to differentiate from fw video data \n",
    "        new_current_vid_pws_column = 'pws_' + current_vid_pws_column\n",
    "        subset_pws_df.rename(columns = {current_vid_pws_column : new_current_vid_pws_column}, inplace = True)\n",
    "\n",
    "        # melt long \n",
    "        pws_long_df = pd.melt(subset_pws_df,\n",
    "                          id_vars=['id_date_pose_zv', group_col],  # Columns to keep\n",
    "                          value_vars=[new_current_vid_pws_column, current_mat_pws_column],  \n",
    "                          var_name='data_source',  \n",
    "                          value_name='metric_value')\n",
    "        \n",
    "\n",
    "        # fast walking speed -----------------------------\n",
    "        current_vid_fw_column = video_fw_columns[metric_i]\n",
    "        current_mat_fw_column = mat_fw_columns[metric_i]\n",
    "\n",
    "        # only select vars needed for plotting \n",
    "        subset_fw_df = fw_data.loc[:, ['id_date_pose_zv', 'task_pose_zv', group_col, current_vid_fw_column, current_mat_fw_column]]\n",
    "\n",
    "        # rename var - add fw to be able to differentiate from pws video data \n",
    "        new_current_vid_fw_column = 'fw_' + current_vid_fw_column\n",
    "        subset_fw_df.rename(columns = {current_vid_fw_column : new_current_vid_fw_column}, inplace = True)\n",
    "\n",
    "        # melt long \n",
    "        fw_long_df = pd.melt(subset_fw_df,\n",
    "                          id_vars=['id_date_pose_zv', group_col],  # Columns to keep\n",
    "                          value_vars=[new_current_vid_fw_column, current_mat_fw_column],  \n",
    "                          var_name='data_source',  \n",
    "                          value_name='metric_value')\n",
    "        \n",
    "        # merge pw and fw and plot \n",
    "        all_long_df = pd.concat([pws_long_df, fw_long_df], ignore_index = True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.boxplot(data=all_long_df, x=group_col, y='metric_value', hue='data_source', dodge = True, fliersize=0, fill = False)\n",
    "        sns.stripplot(data=all_long_df, x=group_col, y='metric_value', hue ='data_source', dodge = True,  size=4, legend = False)\n",
    "        plt.savefig(os.path.join(output_folder_path, current_metric + '_all_by' + group_col + '.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "082e135e-6aba-4220-b252-50ace9f05e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_vid_and_mat_home(video_pws_columns, mat_pws_columns, mat_fw_columns, \n",
    "                             home_df,  group_col, output_folder_path):\n",
    "    \n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "    \n",
    "    for metric_i, current_metric in enumerate(video_pws_columns):\n",
    "        current_vid_pws_column = video_pws_columns[metric_i]\n",
    "        current_mat_pws_column = mat_pws_columns[metric_i]\n",
    "        current_mat_fw_column = mat_fw_columns[metric_i]\n",
    "\n",
    "        # only select vars needed for plotting \n",
    "        subset_home_df = home_df.loc[:, ['id_date_pose_hv', 'task_pose_hv', group_col, \n",
    "                                              current_vid_pws_column, current_mat_pws_column, current_mat_fw_column]]\n",
    "\n",
    "        # rename var - add pws for legend \n",
    "        new_current_vid_pws_column = 'pws_' + current_vid_pws_column\n",
    "        subset_home_df.rename(columns = {current_vid_pws_column : new_current_vid_pws_column}, inplace = True)\n",
    "\n",
    "        # melt long \n",
    "        home_long_df = pd.melt(subset_home_df,\n",
    "                          id_vars=['id_date_pose_hv', group_col],  # Columns to keep\n",
    "                          value_vars=[new_current_vid_pws_column, current_mat_pws_column, current_mat_fw_column],  \n",
    "                          var_name='data_source',  \n",
    "                          value_name='metric_value')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.boxplot(data=home_long_df, x=group_col, y='metric_value', hue='data_source', dodge = True, fliersize=0, fill = False)\n",
    "        sns.stripplot(data=home_long_df, x=group_col, y='metric_value', hue ='data_source', dodge = True,  size=4, legend = False)\n",
    "        plt.savefig(os.path.join(output_folder_path, current_metric + '_all_by' + group_col + '.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "beda4fc7-dacd-421c-89b4-16ade8b2bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_quartile_analysis(df, metric_col_suffix, anova_kruskal_cols, output_folder_path): \n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # select numeric values with metric_col_suffix (either all zv or hv) - only metrics \n",
    "    df_metrics = df.select_dtypes(include=['number'])\n",
    "    df_metrics = df_metrics.loc[:, df_metrics.columns.str.endswith(metric_col_suffix)]\n",
    "    \n",
    "    if metric_col_suffix == 'zv': \n",
    "        df_metrics = df_metrics.drop('walk_segment_pose_zv', axis = 1)\n",
    "    elif metric_col_suffix == 'hv':\n",
    "        df_metrics = df_metrics.drop('walk_segment_pose_hv', axis = 1)\n",
    "        \n",
    "    video_columns = df_metrics.columns \n",
    "    \n",
    "    # make blank df to store new quartile columns names \n",
    "    quartile_col_names = []\n",
    "    \n",
    "    # add new column with quartile and calculate describe stats for each metric quartiles \n",
    "    for metric_i, current_metric in enumerate(video_columns):\n",
    "    \n",
    "        # new column - for each metric, 1 = 0-.25 quantile, 2 = .25-.5, 3 = .5-.75, 4 = .75-1\n",
    "        df = df.copy()\n",
    "        df.loc[:, current_metric + '_quartile'] = pd.qcut(df[current_metric], \n",
    "                                                       q = 4, \n",
    "                                                       labels = ['Quartile 1',\n",
    "                                                                 'Quartile 2',\n",
    "                                                                 'Quartile 3',\n",
    "                                                                 'Quartile 4'])\n",
    "        quartile_col_names.append(current_metric + '_quartile')\n",
    "        \n",
    "        # group by the quartile columns and calculate describe stats for each metrics columns; save .csv \n",
    "        current_metric_descr_df = df.groupby([current_metric + '_quartile'], sort=True, observed = True).describe().round(3)\n",
    "        current_metric_descr_df.to_csv(os.path.join(output_folder_path,  current_metric + '_describe_by_quartile.csv'))\n",
    "\n",
    "    # Compare differences in metrics and outcomes between each video metrics quartile \n",
    "    # just run kruskal. describe by summary statistics saved as individual .csv file for each video metric \n",
    "\n",
    "    # save blank array to save results \n",
    "    print('running kruskal and plotting boxplots for each quartile')\n",
    "    for quartile_col_i, current_quartile_col in enumerate(quartile_col_names):\n",
    "        stats_results = []\n",
    "        for stats_test_i, current_values_col in enumerate(anova_kruskal_cols): \n",
    "            # ---------------------------------------------------------\n",
    "            # compare groups of current values col by quartile of current metric (current_quartile_col) \n",
    "            q1_data = df[df[current_quartile_col] == 'Quartile 1'][current_values_col]\n",
    "            q2_data = df[df[current_quartile_col] == 'Quartile 2'][current_values_col]\n",
    "            q3_data = df[df[current_quartile_col] == 'Quartile 3'][current_values_col]\n",
    "            q4_data = df[df[current_quartile_col] == 'Quartile 4'][current_values_col]\n",
    "\n",
    "            H_stat, p = stats.kruskal(q1_data, q2_data, q3_data, q4_data, nan_policy = 'omit')     \n",
    "            stats_results.append((current_quartile_col, current_values_col,\n",
    "                                  'kruskal', round(H_stat, 3), round(p, 3))) \n",
    "\n",
    "            # boxplot  ---------------------------------------------------\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            sns.boxplot(data=df, x=current_quartile_col, y=current_values_col, width = 0.75, fliersize=0,  fill = False)\n",
    "            # Add in points to show each observation\n",
    "            sns.stripplot(data=df, x=current_quartile_col, y=current_values_col, size=4, color=\".3\")\n",
    "            ax.set_ylim(bottom=0)\n",
    "\n",
    "            # Save the plot\n",
    "            fig_path = os.path.join(output_folder_path, \n",
    "                                    current_quartile_col + '_' + current_values_col + '_boxplot.png')\n",
    "            fig.savefig(fig_path)\n",
    "            plt.close()\n",
    "\n",
    "        # -----------------------------------------------\n",
    "        # save on .csv file per metric grouped by quartile \n",
    "        stats_results_df = pd.DataFrame(stats_results,\n",
    "                                        columns = ['quartile_grouped_by', 'values_compared_column',\n",
    "                                               'stats_test', 'H', 'p'])\n",
    "        stats_results_df.to_csv(os.path.join(output_folder_path,  current_quartile_col + '_kruskal_by_quartile.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30facf65-f1fd-4b9c-876b-68424a297269",
   "metadata": {},
   "source": [
    "# Run analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84f2f84-10a5-4061-b70b-49e3cd0342ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Manually update output folder, load data, and format columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a0f4b0e-1592-470f-9742-04c8d63ed063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version \n",
    "version = '004'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a80658de-3535-40fb-ba83-ba9946b4d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output folders \n",
    "#merged_data_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis\\004'\n",
    "merged_data_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                                version)\n",
    "\n",
    "# out_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis\\004\\video_vs_mat_and_outcomes'\n",
    "out_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                        version, \n",
    "                        'video_vs_mat_and_outcomes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04277eab-b4c4-4f02-a0c5-b22fcad3b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load variables of interest \n",
    "\n",
    "# zeno video metrics \n",
    "zv_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code',\n",
    "                       'gait_bw_zeno_outputs_' + version, \n",
    "                       'gait_bw_zeno_outputs_' + version +'_pose_metrics_all.csv')\n",
    "      \n",
    "zv_df = pd.read_csv(zv_path, index_col = 0)\n",
    "\n",
    "# home video metrics \n",
    "hv_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code',\n",
    "                       'gait_bw_home_outputs_' + version, \n",
    "                       'gait_bw_home_outputs_' + version + '_pose_metrics_all.csv')\n",
    "                       \n",
    "hv_df = pd.read_csv(hv_path, index_col = 0)\n",
    "\n",
    "# BW and zeno mat metrics \n",
    "# decrypted file - may need to decrypt again if says file doesn't exit \n",
    "# copied file saved in Megan Project folder in Brainwalk box. \n",
    "# if issues decrypting, try copying original file again and then decrypting \n",
    "bw_df = pd.read_excel(r'C:\\Users\\mmccu\\AppData\\Local\\Temp\\ccsecure\\2024_10_15_BrainWalk_AllData_Long_MM.xlsx', \n",
    "                     index_col = None, \n",
    "                     usecols = ['bw_id', 'record_id', 'visit_date', 'demoEHR_DiseaseDuration',\n",
    "                                'demoEHR_GENDER', 'demoEHR_Age', 'demographic_diagnosis', 'bingoEHR_DX_MS DX', 'demoEHR_REC_1',\t\n",
    "                                'demoEHR_REC_2', 'bingoEHR_EDSS_measure_value', 'msfcEHR_T25FW SPEED AVG',\n",
    "                                'falls_number', 'falls_since_lastsurvey', 'near_falls', 'near_falls_no', \n",
    "                                'strength_lt_leg', 'strength_max', 'strength_rt_leg', 'sum_total_scores',\n",
    "                                'PWS_stridetimesecmean', 'PWS_stridetimeseccv','PWS_cadencestepsminmean','PWS_totaldsupportmean', \n",
    "                                'PWS_singlesupportmean','PWS_totaldsupportratiolr', 'PWS_singlesupportratiolr', \n",
    "                                'PWS_stridewidthcmmean','PWS_stridewidthcmsd',\n",
    "                                'FW_stridetimesecmean', 'FW_stridetimeseccv','FW_cadencestepsminmean','FW_totaldsupportmean', \n",
    "                                'FW_singlesupportmean','FW_totaldsupportratiolr', 'FW_singlesupportratiolr', \n",
    "                                'FW_stridewidthcmmean','FW_stridewidthcmsd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c9442af-6e45-4706-a7cf-0ef07dfb49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename zeno video variables \n",
    "# ad zv to all zeno volumn names \n",
    "zv_df = zv_df.add_suffix('_zv')\n",
    "\n",
    "# add bw id and video date to zv df \n",
    "zv_df['id_video'] = zv_df['id_date_pose_zv'].str.extract(r'(BW-\\d{4})')\n",
    "zv_df['visit_date_video'] = zv_df['id_date_pose_zv'].str[8:]\n",
    "zv_df['visit_date_video'] = pd.to_datetime(zv_df['visit_date_video'].str.replace('_', '-'), format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc5f4877-573c-4051-b1bc-e26cd7d723d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\3253129783.py:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  hv_df['visit_date_video'] = pd.to_datetime(hv_df['visit_date_video'], errors = 'coerce')\n"
     ]
    }
   ],
   "source": [
    "# add hv to all home column names \n",
    "hv_df = hv_df.add_suffix('_hv')\n",
    "\n",
    "# add bw id and video date to hv df \n",
    "hv_df['id_video'] = hv_df['id_date_pose_hv'].str.extract(r'(BW-\\d{4})')\n",
    "hv_df['visit_date_video'] = hv_df['id_date_pose_hv'].str[8:]\n",
    "hv_df['visit_date_video'] = pd.to_datetime(hv_df['visit_date_video'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e6a3716-a614-44d9-9f47-e6456a225ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bw_id</th>\n",
       "      <th>record_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>demoEHR_DiseaseDuration</th>\n",
       "      <th>demoEHR_GENDER</th>\n",
       "      <th>demoEHR_Age</th>\n",
       "      <th>bingoEHR_DX_MS DX</th>\n",
       "      <th>demoEHR_REC_1</th>\n",
       "      <th>demoEHR_REC_2</th>\n",
       "      <th>bingoEHR_EDSS_measure_value</th>\n",
       "      <th>...</th>\n",
       "      <th>near_falls</th>\n",
       "      <th>near_falls_no</th>\n",
       "      <th>strength_lt_leg</th>\n",
       "      <th>strength_max</th>\n",
       "      <th>strength_rt_leg</th>\n",
       "      <th>sum_total_scores</th>\n",
       "      <th>edss_severity_num</th>\n",
       "      <th>edss_severity_cat</th>\n",
       "      <th>t25fw_group_num</th>\n",
       "      <th>t25fw_group_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BW-0001</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BW-0006</td>\n",
       "      <td>10</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>64.0</td>\n",
       "      <td>PPMS (Primary-progressive Multiple Sclerosis)</td>\n",
       "      <td>WhiteAsian</td>\n",
       "      <td>WhiteNonHispanic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BW-0086</td>\n",
       "      <td>100</td>\n",
       "      <td>2023-08-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BW-0087</td>\n",
       "      <td>101</td>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BW-0088</td>\n",
       "      <td>102</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>pending</td>\n",
       "      <td>Other/Decline/Unknown</td>\n",
       "      <td>Other/Decline/Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6_to_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bw_id  record_id visit_date  demoEHR_DiseaseDuration demoEHR_GENDER  \\\n",
       "0  BW-0001          1 2022-08-26                      NaN            NaN   \n",
       "1  BW-0006         10 2022-09-26                     17.0         Female   \n",
       "2  BW-0086        100 2023-08-08                      NaN            NaN   \n",
       "3  BW-0087        101 2023-01-18                      NaN            NaN   \n",
       "4  BW-0088        102 2023-01-23                      0.0         Female   \n",
       "\n",
       "   demoEHR_Age                              bingoEHR_DX_MS DX  \\\n",
       "0          NaN                                            NaN   \n",
       "1         64.0  PPMS (Primary-progressive Multiple Sclerosis)   \n",
       "2          NaN                                            NaN   \n",
       "3          NaN                                            NaN   \n",
       "4         33.0                                        pending   \n",
       "\n",
       "           demoEHR_REC_1          demoEHR_REC_2  bingoEHR_EDSS_measure_value  \\\n",
       "0                    NaN                    NaN                          NaN   \n",
       "1             WhiteAsian       WhiteNonHispanic                          3.0   \n",
       "2                    NaN                    NaN                          NaN   \n",
       "3                    NaN                    NaN                          NaN   \n",
       "4  Other/Decline/Unknown  Other/Decline/Unknown                          NaN   \n",
       "\n",
       "   ...  near_falls  near_falls_no  strength_lt_leg  strength_max  \\\n",
       "0  ...         NaN            NaN              NaN           NaN   \n",
       "1  ...          No            NaN              NaN           NaN   \n",
       "2  ...          No            NaN              NaN           NaN   \n",
       "3  ...         Yes            5.0              NaN           NaN   \n",
       "4  ...         Yes            NaN              NaN           NaN   \n",
       "\n",
       "   strength_rt_leg  sum_total_scores  edss_severity_num  edss_severity_cat  \\\n",
       "0              NaN              46.0                NaN                NaN   \n",
       "1              NaN              46.0                2.0           moderate   \n",
       "2              NaN              46.0                NaN                NaN   \n",
       "3              NaN              46.0                NaN                NaN   \n",
       "4              NaN              46.0                NaN                NaN   \n",
       "\n",
       "   t25fw_group_num  t25fw_group_cat  \n",
       "0              NaN              NaN  \n",
       "1              1.0          under_6  \n",
       "2              NaN              NaN  \n",
       "3              NaN              NaN  \n",
       "4              2.0           6_to_8  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add columns for ordinal EDSS severity and t25fw \n",
    "bw_df['edss_severity_num'], bw_df['edss_severity_cat'] = zip(*bw_df['bingoEHR_EDSS_measure_value'].apply(categorize_edss))\n",
    "bw_df['edss_severity_cat'] = pd.Categorical(bw_df['edss_severity_cat'], categories=[\"mild\", \"moderate\", \"severe\"], ordered=True)\n",
    "\n",
    "# Apply the function to create new columns\n",
    "bw_df['t25fw_group_num'], bw_df['t25fw_group_cat'] = zip(*bw_df['msfcEHR_T25FW SPEED AVG'].apply(categorize_t25fw))\n",
    "bw_df['t25fw_group_cat'] = pd.Categorical(bw_df['t25fw_group_cat'], categories=[\"under_6\", \"6_to_8\", \"over_8\"], ordered=True)\n",
    "bw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c51e9-2601-43e1-883b-b96ed7971ed5",
   "metadata": {},
   "source": [
    "### Merge video data with brainwalk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "945d66a2-d05a-4679-b902-895fe28063ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm all one task\n",
      "['gait_vertical_PWS_1']\n",
      "total zeno videos\n",
      "253\n",
      "total bw rows with id in video dataset\n",
      "285\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0010\n",
      "2022-10-05 00:00:00\n",
      "multiple rows for the id and date combo\n",
      "BW-0010\n",
      "2023-10-18 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0031\n",
      "2023-04-21 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2024-04-08 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0063\n",
      "2024-07-15 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0067\n",
      "2024-01-09 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0092\n",
      "2024-08-19 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0110\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0121\n",
      "2022-07-20 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0162\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0166\n",
      "2024-06-17 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0277\n",
      "2024-08-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0322\n",
      "2024-06-10 00:00:00\n",
      "mismatched zeno video vs brainwalk id\n",
      "0\n",
      "mismatched zeno video vs brainwalk date\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# zeno videos - preferred walking speed \n",
    "bw_zv_pws_df = merge_bw_zv(bw_df, zv_df, 'gait_vertical_PWS_1', merged_data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b89bbf1-5ddb-447e-abbe-e1b8ca7ecdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- print bw_zv_pws_df video counts ----\n",
      "total videos - df length: 241\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 34\n",
      "num videos demographic_diagnosis == MS: 207\n",
      "------\n",
      "unique id_video (participants) in df: 177\n",
      "num participants with demographic_diagnosis == HC: 33\n",
      "num participants demographic_diagnosis == MS: 144\n",
      "------\n",
      "number of participants with multiple videos in dataset: 62\n",
      "number of participants with one video: 115\n"
     ]
    }
   ],
   "source": [
    "print('----- print bw_zv_pws_df video counts ----')\n",
    "print_video_counts(bw_zv_pws_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80492797-2579-463c-83e1-7b32ca6e7aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm all one task\n",
      "['gait_vertical_FW_1']\n",
      "total zeno videos\n",
      "245\n",
      "total bw rows with id in video dataset\n",
      "281\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0010\n",
      "2022-10-05 00:00:00\n",
      "multiple rows for the id and date combo\n",
      "BW-0010\n",
      "2023-10-18 00:00:00\n",
      "multiple rows for the id and date combo\n",
      "BW-0023\n",
      "2023-10-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0031\n",
      "2023-04-21 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0036\n",
      "2024-04-02 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2023-05-02 00:00:00\n",
      "multiple rows for the id and date combo\n",
      "BW-0044\n",
      "2023-11-30 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2024-04-08 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0063\n",
      "2024-07-15 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0067\n",
      "2024-01-09 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0110\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0162\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0166\n",
      "2024-06-17 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0277\n",
      "2024-08-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0322\n",
      "2024-06-10 00:00:00\n",
      "mismatched zeno video vs brainwalk id\n",
      "0\n",
      "mismatched zeno video vs brainwalk date\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# zeno videos - fast walking speed \n",
    "bw_zv_fw_df = merge_bw_zv(bw_df, zv_df, 'gait_vertical_FW_1', merged_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5697b901-6db0-4ba7-b5df-855211d1cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- print bw_zv_fw_df video counts ----\n",
      "total videos - df length: 233\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 37\n",
      "num videos demographic_diagnosis == MS: 196\n",
      "------\n",
      "unique id_video (participants) in df: 176\n",
      "num participants with demographic_diagnosis == HC: 35\n",
      "num participants demographic_diagnosis == MS: 141\n",
      "------\n",
      "number of participants with multiple videos in dataset: 56\n",
      "number of participants with one video: 120\n"
     ]
    }
   ],
   "source": [
    "print('---- print bw_zv_fw_df video counts ----')\n",
    "print_video_counts(bw_zv_fw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7a73db1-4a98-42d1-949a-b78f11228d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirm all one task\n",
      "['gait_vertical_right']\n",
      "total home videos\n",
      "31\n",
      "total bw rows with id in video dataset\n",
      "51\n",
      "mismatched home video vs brainwalk id\n",
      "0\n",
      "confirm all one task\n",
      "['gait_vertical_left']\n",
      "total home videos\n",
      "30\n",
      "total bw rows with id in video dataset\n",
      "50\n",
      "mismatched home video vs brainwalk id\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# home videos - merge home videos and BW \n",
    "bw_hv_r_pws_df = merge_bw_hv(bw_df, hv_df, 'gait_vertical_right', merged_data_path)\n",
    "bw_hv_l_pws_df = merge_bw_hv(bw_df, hv_df, 'gait_vertical_left', merged_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57443032-f6b4-400d-855d-54e5e08a0751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- print bw_hv_pws_df video counts ----\n",
      "total videos - df length: 61\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 61\n",
      "------\n",
      "unique id_video (participants) in df: 27\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 27\n",
      "------\n",
      "number of participants with multiple videos in dataset: 26\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# concatenate right and left \n",
    "bw_hv_pws_df = pd.concat([bw_hv_r_pws_df, bw_hv_l_pws_df], axis = 0).sort_index()\n",
    "bw_hv_pws_df['edss_severity_cat'] = pd.Categorical(bw_hv_pws_df['edss_severity_cat'], categories=[\"mild\", \"moderate\", \"severe\"], ordered=True)\n",
    "print('---- print bw_hv_pws_df video counts ----')\n",
    "print_video_counts(bw_hv_pws_df)\n",
    "\n",
    "# save merged df  \n",
    "bw_hv_pws_df.to_csv(os.path.join(merged_data_path,  'hv_bw_merged.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8692bd80-7ddd-44db-a878-9fa05717f99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_date_pose_hv</th>\n",
       "      <th>video_id_date_name_pose_hv</th>\n",
       "      <th>task_pose_hv</th>\n",
       "      <th>total_video_duration_sec_pose_hv</th>\n",
       "      <th>walking_segmets_n_pose_hv</th>\n",
       "      <th>walking_segments_duration_mean_pose_hv</th>\n",
       "      <th>walking_segments_duration_median_pose_hv</th>\n",
       "      <th>stride_time_mean_sec_pose_hv</th>\n",
       "      <th>stride_time_median_sec_pose_hv</th>\n",
       "      <th>stride_time_std_pose_hv</th>\n",
       "      <th>...</th>\n",
       "      <th>near_falls_no</th>\n",
       "      <th>strength_lt_leg</th>\n",
       "      <th>strength_max</th>\n",
       "      <th>strength_rt_leg</th>\n",
       "      <th>sum_total_scores</th>\n",
       "      <th>edss_severity_num</th>\n",
       "      <th>edss_severity_cat</th>\n",
       "      <th>t25fw_group_num</th>\n",
       "      <th>t25fw_group_cat</th>\n",
       "      <th>bw_hv_abs_date_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BW-0018\\10-24-23</td>\n",
       "      <td>gait_vertical_left_BW-0018_10-24-23</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>26.80</td>\n",
       "      <td>1</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1.008</td>\n",
       "      <td>1.050</td>\n",
       "      <td>0.171</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BW-0018\\10-24-23</td>\n",
       "      <td>gait_vertical_right_BW-0018_10-24-23</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>24.40</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BW-0023\\05-05-23</td>\n",
       "      <td>gait_vertical_left_BW-0023_05-05-23</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>35.97</td>\n",
       "      <td>4</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.027</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.066</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>171 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BW-0023\\05-05-23</td>\n",
       "      <td>gait_vertical_right_BW-0023_05-05-23</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>38.47</td>\n",
       "      <td>5</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.070</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>171 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BW-0023\\10-23-23</td>\n",
       "      <td>gait_vertical_left_BW-0023_10-23-23</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>36.10</td>\n",
       "      <td>3</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.087</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I can easily raise it and keep it raised</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>under_6</td>\n",
       "      <td>0 days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_date_pose_hv            video_id_date_name_pose_hv  \\\n",
       "0  BW-0018\\10-24-23   gait_vertical_left_BW-0018_10-24-23   \n",
       "1  BW-0018\\10-24-23  gait_vertical_right_BW-0018_10-24-23   \n",
       "2  BW-0023\\05-05-23   gait_vertical_left_BW-0023_05-05-23   \n",
       "3  BW-0023\\05-05-23  gait_vertical_right_BW-0023_05-05-23   \n",
       "4  BW-0023\\10-23-23   gait_vertical_left_BW-0023_10-23-23   \n",
       "\n",
       "          task_pose_hv  total_video_duration_sec_pose_hv  \\\n",
       "0   gait_vertical_left                             26.80   \n",
       "1  gait_vertical_right                             24.40   \n",
       "2   gait_vertical_left                             35.97   \n",
       "3  gait_vertical_right                             38.47   \n",
       "4   gait_vertical_left                             36.10   \n",
       "\n",
       "   walking_segmets_n_pose_hv  walking_segments_duration_mean_pose_hv  \\\n",
       "0                          1                                    3.17   \n",
       "1                          1                                    2.40   \n",
       "2                          4                                    4.42   \n",
       "3                          5                                    4.78   \n",
       "4                          3                                    4.19   \n",
       "\n",
       "   walking_segments_duration_median_pose_hv  stride_time_mean_sec_pose_hv  \\\n",
       "0                                      3.17                         1.008   \n",
       "1                                      2.40                           NaN   \n",
       "2                                      4.33                         1.027   \n",
       "3                                      4.63                         1.070   \n",
       "4                                      3.83                         0.998   \n",
       "\n",
       "   stride_time_median_sec_pose_hv  stride_time_std_pose_hv  ...  \\\n",
       "0                           1.050                    0.171  ...   \n",
       "1                             NaN                      NaN  ...   \n",
       "2                           1.033                    0.066  ...   \n",
       "3                           1.033                    0.098  ...   \n",
       "4                           0.983                    0.087  ...   \n",
       "\n",
       "   near_falls_no                           strength_lt_leg  strength_max  \\\n",
       "0            NaN  I can easily raise it and keep it raised           0.0   \n",
       "1            NaN  I can easily raise it and keep it raised           0.0   \n",
       "2            2.0  I can easily raise it and keep it raised           0.0   \n",
       "3            2.0  I can easily raise it and keep it raised           0.0   \n",
       "4            2.0  I can easily raise it and keep it raised           0.0   \n",
       "\n",
       "                            strength_rt_leg  sum_total_scores  \\\n",
       "0  I can easily raise it and keep it raised               2.0   \n",
       "1  I can easily raise it and keep it raised               2.0   \n",
       "2  I can easily raise it and keep it raised              15.0   \n",
       "3  I can easily raise it and keep it raised              15.0   \n",
       "4  I can easily raise it and keep it raised              15.0   \n",
       "\n",
       "   edss_severity_num  edss_severity_cat  t25fw_group_num  t25fw_group_cat  \\\n",
       "0                2.0           moderate              1.0          under_6   \n",
       "1                2.0           moderate              1.0          under_6   \n",
       "2                2.0           moderate              1.0          under_6   \n",
       "3                2.0           moderate              1.0          under_6   \n",
       "4                2.0           moderate              1.0          under_6   \n",
       "\n",
       "   bw_hv_abs_date_diff  \n",
       "0               0 days  \n",
       "1               0 days  \n",
       "2             171 days  \n",
       "3             171 days  \n",
       "4               0 days  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_hv_pws_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078571e-6f63-40df-8231-e26521116935",
   "metadata": {},
   "source": [
    "### Drop rows with missing brainwalk mat data \n",
    "- use these data frames when comparing the video metrics to mat metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ecffbf2-0cf8-41f6-b572-1d24706d860f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 237\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 34\n",
      "num videos demographic_diagnosis == MS: 203\n",
      "------\n",
      "unique id_video (participants) in df: 175\n",
      "num participants with demographic_diagnosis == HC: 33\n",
      "num participants demographic_diagnosis == MS: 142\n",
      "------\n",
      "number of participants with multiple videos in dataset: 60\n",
      "number of participants with one video: 115\n"
     ]
    }
   ],
   "source": [
    "# zeno preferred walk - participants with pws videos and pws mat metrics\n",
    "bw_zv_pws_df_2 = drop_cols_missing_data(bw_zv_pws_df, cols_to_check = 'pws')\n",
    "print_video_counts(bw_zv_pws_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "590de1d6-a836-428b-a45b-e8f6459b2768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 230\n",
      "unique demographic_diagnosis in df: ['MS' 'HC']\n",
      "num videos with demographic_diagnosis == HC: 37\n",
      "num videos demographic_diagnosis == MS: 193\n",
      "------\n",
      "unique id_video (participants) in df: 173\n",
      "num participants with demographic_diagnosis == HC: 35\n",
      "num participants demographic_diagnosis == MS: 138\n",
      "------\n",
      "number of participants with multiple videos in dataset: 56\n",
      "number of participants with one video: 117\n"
     ]
    }
   ],
   "source": [
    "# zeno fast walk - participants with FWS videos and fWS mat metrics\n",
    "bw_zv_fw_df_2 = drop_cols_missing_data(bw_zv_fw_df, cols_to_check = 'fw')\n",
    "print_video_counts(bw_zv_fw_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e748f27-660e-4a0a-b980-8cdf92ecdf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 55\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 55\n",
      "------\n",
      "unique id_video (participants) in df: 24\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 24\n",
      "------\n",
      "number of participants with multiple videos in dataset: 23\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and pws mat metrics \n",
    "bw_hv_pws_df_2 = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 'pws')\n",
    "print_video_counts(bw_hv_pws_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f795a127-ad8e-4529-8e49-839751fbb066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 61\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 61\n",
      "------\n",
      "unique id_video (participants) in df: 27\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 27\n",
      "------\n",
      "number of participants with multiple videos in dataset: 26\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and fw mat metrics \n",
    "bw_hv_fw_df_2 = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 'fw')\n",
    "print_video_counts(bw_hv_fw_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292152e6-9770-40cf-9963-777fc375253f",
   "metadata": {},
   "source": [
    "### Drop rows with missing brainwalk clinical outcomes measures \n",
    "- use these data frames when comparing video metrics to clinical outcomes (ie - exclude participants with missing edss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39702a4c-5609-4c36-a8c2-307e6b0e7a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 146\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 146\n",
      "------\n",
      "unique id_video (participants) in df: 124\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 124\n",
      "------\n",
      "number of participants with multiple videos in dataset: 22\n",
      "number of participants with one video: 102\n"
     ]
    }
   ],
   "source": [
    "# zeno preferred walk - participants with pws videos and t25fw \n",
    "bw_zv_pws_t25fw_df = drop_cols_missing_data(bw_zv_pws_df, cols_to_check = 't25fw')\n",
    "print_video_counts(bw_zv_pws_t25fw_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f25ccac-ee2d-416b-b0f7-f9736d60e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 198\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 198\n",
      "------\n",
      "unique id_video (participants) in df: 137\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 137\n",
      "------\n",
      "number of participants with multiple videos in dataset: 59\n",
      "number of participants with one video: 78\n"
     ]
    }
   ],
   "source": [
    "# zeno preferred walk - participants with pws videos and edss \n",
    "bw_zv_pws_edss_df = drop_cols_missing_data(bw_zv_pws_df, cols_to_check = 'edss')\n",
    "print_video_counts(bw_zv_pws_edss_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1d436b6-bd47-494d-9f71-9049fd1117f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 145\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 145\n",
      "------\n",
      "unique id_video (participants) in df: 122\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 122\n",
      "------\n",
      "number of participants with multiple videos in dataset: 22\n",
      "number of participants with one video: 100\n"
     ]
    }
   ],
   "source": [
    "# zeno fast walk - participants with fw videos and t25fw \n",
    "bw_zv_fw_t25fw_df = drop_cols_missing_data(bw_zv_fw_df, cols_to_check = 't25fw')\n",
    "print_video_counts(bw_zv_fw_t25fw_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85152e92-513c-4d6c-989e-59bdfbe12740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 191\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 191\n",
      "------\n",
      "unique id_video (participants) in df: 137\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 137\n",
      "------\n",
      "number of participants with multiple videos in dataset: 53\n",
      "number of participants with one video: 84\n"
     ]
    }
   ],
   "source": [
    "# zeno fast walk - participants with fw videos and edss \n",
    "bw_zv_fw_edss_df = drop_cols_missing_data(bw_zv_fw_df, cols_to_check = 'edss')\n",
    "print_video_counts(bw_zv_fw_edss_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dbdbf45-15f0-4f6d-84c6-fa029c0e46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 57\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 57\n",
      "------\n",
      "unique id_video (participants) in df: 26\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 26\n",
      "------\n",
      "number of participants with multiple videos in dataset: 25\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and t25fw \n",
    "bw_hv_t25fw_df = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 't25fw')\n",
    "print_video_counts(bw_hv_t25fw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f26002b-15c2-4554-bf3e-1c8a6ddc238b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total videos - df length: 59\n",
      "unique demographic_diagnosis in df: ['MS']\n",
      "num videos with demographic_diagnosis == HC: 0\n",
      "num videos demographic_diagnosis == MS: 59\n",
      "------\n",
      "unique id_video (participants) in df: 26\n",
      "num participants with demographic_diagnosis == HC: 0\n",
      "num participants demographic_diagnosis == MS: 26\n",
      "------\n",
      "number of participants with multiple videos in dataset: 25\n",
      "number of participants with one video: 1\n"
     ]
    }
   ],
   "source": [
    "# home videos - participants with home videos and edss \n",
    "bw_hv_edss_df = drop_cols_missing_data(bw_hv_pws_df, cols_to_check = 'edss')\n",
    "print_video_counts(bw_hv_edss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412d0bc-7044-4803-91d7-38b236e52d7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Correlation: Mat Metrics vs Video Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c052781-9a12-42b7-b5d0-f764d2ad38e4",
   "metadata": {},
   "source": [
    "### Check Normality and save histograms \n",
    "Checks normality and plots histogram for each column in dataframe where type == float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17f0fe54-9164-4614-96ae-580d78826b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWS Zeno Videos - video of walk on mat \n",
    "hist_out_path_1 = (os.path.join(out_path, '00_hist_shapiro_all', 'zv_vs_bw_pws'))\n",
    "if not os.path.exists(hist_out_path_1):\n",
    "    os.makedirs(hist_out_path_1)\n",
    "     \n",
    "bw_zv_pws_2_shapiro = hist_and_shapiro(bw_zv_pws_df_2, hist_out_path_1)\n",
    "\n",
    "# save in test normality folder\n",
    "bw_zv_pws_2_shapiro.to_csv(os.path.join(hist_out_path_1, 'zv_vs_bw_pws_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e064e87-a31a-4db8-93cc-7c3f1b711146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FWS Zeno Videos - video of walk on mat \n",
    "hist_out_path_2 = (os.path.join(out_path, '00_hist_shapiro_all', 'zv_vs_bw_fw'))\n",
    "if not os.path.exists(hist_out_path_2):\n",
    "    os.makedirs(hist_out_path_2)\n",
    "\n",
    "bw_zv_fw_2_shapiro = hist_and_shapiro(bw_zv_fw_df_2, hist_out_path_2)\n",
    "\n",
    "# save in test normality folder\n",
    "bw_zv_fw_2_shapiro.to_csv(os.path.join(hist_out_path_2, 'zv_vs_bw_fw_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18a88d04-3515-4902-9df1-97ce4861d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos - video closest to walk on mat date \n",
    "hist_out_path_3 = (os.path.join(out_path, '00_hist_shapiro_all', 'hv_all_vs_bw_pws'))\n",
    "if not os.path.exists(hist_out_path_3):\n",
    "    os.makedirs(hist_out_path_3)\n",
    "\n",
    "bw_hv_pws_2_shapiro = hist_and_shapiro(bw_hv_pws_df_2, hist_out_path_3)\n",
    "\n",
    "# save in test normality folder \n",
    "bw_hv_pws_2_shapiro.to_csv(os.path.join(hist_out_path_3, 'hv_all_vs_bw_pws_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3dfc53a-05dd-469e-a3dc-9b40b08f596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos - video closest to walk on mat date \n",
    "hist_out_path_4 = (os.path.join(out_path, '00_hist_shapiro_all', 'hv_all_vs_bw_fw'))\n",
    "if not os.path.exists(hist_out_path_4):\n",
    "    os.makedirs(hist_out_path_4)\n",
    "\n",
    "bw_hv_fw_2_shapiro = hist_and_shapiro(bw_hv_fw_df_2, hist_out_path_4)\n",
    "\n",
    "# save in test normality folder \n",
    "bw_hv_fw_2_shapiro.to_csv(os.path.join(hist_out_path_4, 'hv_all_vs_bw_fw_shapiro_results.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcec32-0175-4042-b252-b0d7ea9a2bad",
   "metadata": {},
   "source": [
    "### Run correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc50aa82-284b-45f5-b60d-9e0d8fca048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cols to compare \n",
    "# column pairs to evaluate matching metrics \n",
    "# for each of the column pairs below (zv 1 vs bw1, zv 2 vs bw 3, etc), run and save correlation \n",
    "zv_colnames = ['stride_time_median_sec_pose_zv', \n",
    "               'stride_time_mean_sec_pose_zv',\n",
    "               'foot1_gait_cycle_time_mean_pose_zv',\n",
    "               'stride_time_cv_pose_zv', \n",
    "               'mean_cadence_step_per_min_pose_zv',\n",
    "               'foot1_double_support_per_mean_pose_zv',\n",
    "               'foot1_single_support_per_mean_pose_zv',\n",
    "               'stride_width_median_cm_pose_zv',\n",
    "               'stride_width_mean_cm_pose_zv',\n",
    "               'stride_width_std_pose_zv']\n",
    "\n",
    "hv_colnames = ['stride_time_median_sec_pose_hv', \n",
    "               'stride_time_mean_sec_pose_hv',\n",
    "               'foot1_gait_cycle_time_mean_pose_hv', \n",
    "               'stride_time_cv_pose_hv', \n",
    "               'mean_cadence_step_per_min_pose_hv',\n",
    "               'foot1_double_support_per_mean_pose_hv',\n",
    "               'foot1_single_support_per_mean_pose_hv',\n",
    "               'stride_width_median_cm_pose_hv',\n",
    "               'stride_width_mean_cm_pose_hv',\n",
    "               'stride_width_std_pose_hv']\n",
    "               \n",
    "bw_pws_colnames = ['PWS_stridetimesecmean', \n",
    "                   'PWS_stridetimesecmean',\n",
    "                   'PWS_stridetimesecmean',\n",
    "                   'PWS_stridetimeseccv',\n",
    "                   'PWS_cadencestepsminmean',\n",
    "                   'PWS_totaldsupportmean',\n",
    "                   'PWS_singlesupportmean', \n",
    "                   'PWS_stridewidthcmmean',\n",
    "                   'PWS_stridewidthcmmean',\n",
    "                   'PWS_stridewidthcmsd']\n",
    "\n",
    "bw_fw_colnames = ['FW_stridetimesecmean', \n",
    "                  'FW_stridetimesecmean', \n",
    "                  'FW_stridetimesecmean', \n",
    "                  'FW_stridetimeseccv',\n",
    "                   'FW_cadencestepsminmean',\n",
    "                   'FW_totaldsupportmean',\n",
    "                   'FW_singlesupportmean', \n",
    "                   'FW_stridewidthcmmean',\n",
    "                  'FW_stridewidthcmmean',\n",
    "                   'FW_stridewidthcmsd']\n",
    "\n",
    "units = ['seconds',\n",
    "         'seconds',\n",
    "         'seconds',\n",
    "         'CV%',\n",
    "         'steps/min',\n",
    "         '%',\n",
    "         '%', \n",
    "         'cm',\n",
    "         'cm',\n",
    "         'cm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3351cbd-96b4-4543-9369-a0fd5bb72c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PWS Zeno Videos - video of walk on mat \n",
    "corr_out_path1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_correlation')\n",
    "\n",
    "bw_zv_pws_corr_results_df = metric_correlation(bw_zv_pws_df_2, zv_colnames, bw_pws_colnames, corr_out_path1)\n",
    "bw_zv_pws_corr_results_df.to_csv(os.path.join(corr_out_path1, 'bw_zv_pws_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb847f93-5a81-4387-b459-563919a853e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FW Zeno Videos - video of walk on mat \n",
    "corr_out_path2 = os.path.join(out_path, 'zv_vs_bw_fw_metric_correlation')\n",
    "\n",
    "bw_zv_fw_corr_results_df = metric_correlation(bw_zv_fw_df_2, zv_colnames, bw_fw_colnames, corr_out_path2)\n",
    "bw_zv_fw_corr_results_df.to_csv(os.path.join(corr_out_path2, 'bw_zv_fw_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd0ebe2f-64a9-4497-a07a-2b98c6218d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos - video closest to PWS walk on mat date \n",
    "corr_out_path3 = os.path.join(out_path, 'hv_vs_bw_pws_metric_correlation')\n",
    "\n",
    "bw_hv_pws_corr_results_df = metric_correlation(bw_hv_pws_df_2, hv_colnames, bw_pws_colnames, corr_out_path3)\n",
    "bw_hv_pws_corr_results_df.to_csv(os.path.join(corr_out_path3, 'bw_hv_pws_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5908604c-fe49-4480-9ffd-370e9aebe799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos - video closest to FW walk on mat date \n",
    "corr_out_path4 = os.path.join(out_path, 'hv_vs_bw_fw_metric_correlation')\n",
    "\n",
    "bw_hv_pws_corr_results_df = metric_correlation(bw_hv_pws_df_2, hv_colnames, bw_fw_colnames, corr_out_path4)\n",
    "bw_hv_pws_corr_results_df.to_csv(os.path.join(corr_out_path4, 'bw_hv_fw_metric_correlation.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61ed39-3f24-4d35-b25f-dea20d595eef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mean Error: BW mat metrics vs Zeno video metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7915cc7a-ca32-4d45-8738-af625de6b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeno video vs brainwalk mat: preferred walking speed \n",
    "mae_out_path1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_mean_error')\n",
    "\n",
    "bw_zv_pws_mae_df = calculate_metric_mean_error(bw_zv_pws_df_2, zv_colnames, bw_pws_colnames, units, mae_out_path1)\n",
    "bw_zv_pws_mae_df.to_csv(os.path.join(mae_out_path1, 'bw_zv_pws_metric_mean_error_mae.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4465ea1a-ff75-44fe-bd32-a0c566a0dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeno video vs brainwalk mat: fast walking speed \n",
    "mae_out_path2 = os.path.join(out_path, 'zv_vs_bw_fw_metric_mean_error')\n",
    "\n",
    "bw_zv_fw_mae_df = calculate_metric_mean_error(bw_zv_fw_df_2, zv_colnames, bw_fw_colnames, units, mae_out_path2)\n",
    "bw_zv_fw_mae_df.to_csv(os.path.join(mae_out_path2, 'bw_zv_fw_metric_mean_error_mae.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b36558-0e88-4be2-967f-20c3f5088a44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bland Altman: BW mat metrics vs Zeno video metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8c298a0-e096-4d6f-afda-b4954631ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preferred walking speed \n",
    "bland_alt_path1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_BlandAlt')\n",
    "bland_altman_plot(bw_zv_pws_df_2, zv_colnames, bw_pws_colnames, units, bland_alt_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18c7fe21-8b41-4811-836b-0d93f9e5956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast walking speed \n",
    "# preferred walking speed \n",
    "bland_alt_path2 = os.path.join(out_path, 'zv_vs_bw_fw_metric_BlandAlt')\n",
    "bland_altman_plot(bw_zv_fw_df_2, zv_colnames, bw_fw_colnames, units, bland_alt_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37492011-116a-468c-9515-b118f9e12914",
   "metadata": {},
   "source": [
    "## Correlation of Gait Metrics vs Clinical Outcomes \n",
    "- includes both mat and video gait metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7687f55-b0af-4aec-8076-87f22e7e0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In person zeno videos + mat at PWS vs EDSS score and EDSS severity \n",
    "outcome_corr_path1 = os.path.join(out_path, 'zv_vs_bw_pws_outcome_corr')\n",
    "zv_pws_vs_edss_corr = outcome_correlation(bw_zv_pws_edss_df, outcome_corr_path1, 'zv_bw_pws', 'edss')\n",
    "zv_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path1, 'zv_bw_pws_edss_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e6eacb8-1e3c-4e59-8730-ef899596dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n"
     ]
    }
   ],
   "source": [
    "# In person zeno videos at PWS vs T25FW \n",
    "outcome_corr_path1 = os.path.join(out_path, 'zv_vs_bw_pws_outcome_corr')\n",
    "zv_pws_vs_t25fw_corr = outcome_correlation(bw_zv_pws_t25fw_df, outcome_corr_path1, 'zv_bw_pws', 't25fw')\n",
    "zv_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path1, 'zv_bw_pws_t25fw_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56615f74-bc23-4c17-97b4-68df48833126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In person zeno videos + mat at FW vs EDSS score and EDSS Severity \n",
    "outcome_corr_path2 = os.path.join(out_path, 'zv_vs_bw_fw_outcome_corr')\n",
    "zv_fw_vs_edss_corr = outcome_correlation(bw_zv_fw_edss_df, outcome_corr_path2, 'zv_bw_fw', 'edss')\n",
    "zv_fw_vs_edss_corr.to_csv(os.path.join(outcome_corr_path2, 'zv_bw_fw_edss_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8d4f0e37-3a88-43a2-b070-eb43e974dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n"
     ]
    }
   ],
   "source": [
    "# in person zeno videos + mat at FW vs T25FW \n",
    "outcome_corr_path2 = os.path.join(out_path, 'zv_vs_bw_fw_outcome_corr')\n",
    "zv_fw_vs_t25fw_corr = outcome_correlation(bw_zv_fw_t25fw_df, outcome_corr_path2, 'zv_bw_fw', 't25fw')\n",
    "zv_fw_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path2, 'zv_bw_fw_t25fw_corr.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3aeba-ccf4-41dd-b30c-48a0e06bce50",
   "metadata": {},
   "source": [
    "### Not sure if enough videos for correlation\n",
    "Especially for only right or only left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42fa3af2-788f-4b66-b1a3-8dfb3755bc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n"
     ]
    }
   ],
   "source": [
    "# bw home videos + in-person pws speed vs EDSS score and EDSS severity \n",
    "# all videos - can be two rows per particiant, one for gait vertical right and one for gait vertical left \n",
    "outcome_corr_path3 = os.path.join(out_path, 'hv_vs_bw_pws_outcome_corr')\n",
    "hv_pws_vs_edss_corr = outcome_correlation(bw_hv_edss_df, outcome_corr_path3, 'hv_all_bw_pws', 'edss')\n",
    "hv_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_all_bw_pws_edss_corr.csv'))\n",
    "\n",
    "\n",
    "# only \"gait_vertical_left\" \n",
    "bw_hv_edss_df_left = bw_hv_edss_df.loc[bw_hv_edss_df['task_pose_hv'] == 'gait_vertical_left']\n",
    "hv_left_pws_vs_edss_corr = outcome_correlation(bw_hv_edss_df_left, outcome_corr_path3, 'hv_left_bw_pws', 'edss')\n",
    "hv_left_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_left_bw_pws_edss_corr.csv'))\n",
    "\n",
    "# only \"gait_vertical_right\" \n",
    "bw_hv_edss_df_right = bw_hv_edss_df.loc[bw_hv_edss_df['task_pose_hv'] == 'gait_vertical_right']\n",
    "hv_right_pws_vs_edss_corr = outcome_correlation(bw_hv_edss_df_right, outcome_corr_path3, 'hv_right_bw_pws', 'edss')\n",
    "hv_right_pws_vs_edss_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_right_bw_pws_edss_corr.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e4b8eff-708d-49ed-afdf-e8f42d100123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n",
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\4217889786.py:37: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, p_value = stats.spearmanr(df_num_clean[col1], df_num_clean[col2])\n"
     ]
    }
   ],
   "source": [
    "# bw_hv_t25fw_df\n",
    "# bw home videos + in-person pws speed vs T25FW \n",
    "outcome_corr_path3 = os.path.join(out_path, 'hv_vs_bw_pws_outcome_corr')\n",
    "hv_pws_vs_t25fw_corr = outcome_correlation(bw_hv_t25fw_df, outcome_corr_path3, 'hv_all_bw_pws', 't25fw')\n",
    "hv_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_all_bw_pws_t25fw_corr.csv'))\n",
    "\n",
    "# only \"gait_vertical_left\" \n",
    "bw_hv_t25fw_df_left = bw_hv_t25fw_df.loc[bw_hv_t25fw_df['task_pose_hv'] == 'gait_vertical_left']\n",
    "hv_left_pws_vs_t25fw_corr = outcome_correlation(bw_hv_t25fw_df_left, outcome_corr_path3, 'hv_left_bw_pws', 't25fw')\n",
    "hv_left_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_left_bw_pws_t25fw_corr.csv'))\n",
    "\n",
    "# only \"gait_vertical_right\" \n",
    "bw_hv_t25fw_df_right = bw_hv_t25fw_df.loc[bw_hv_t25fw_df['task_pose_hv'] == 'gait_vertical_right']\n",
    "hv_right_pws_vs_t25fw_corr = outcome_correlation(bw_hv_t25fw_df_right, outcome_corr_path3, 'hv_right_bw_pws', 't25fw')\n",
    "hv_right_pws_vs_t25fw_corr.to_csv(os.path.join(outcome_corr_path3, 'hv_right_bw_pws_t25fw_corr.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76327b-1705-4d7a-bf48-7a4dd836def1",
   "metadata": {},
   "source": [
    "## Analyze difference between categorical groups (diagnoses, edss severity, etc)\n",
    "- To-do: currently all non-parametric test, check individually before writing manuscript - most seem non-parametric but some should maybe be t-test or anova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59a7a4-a2ea-4b40-9625-8678c38e6ab8",
   "metadata": {},
   "source": [
    "### All video metrics by HC vs MS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9305ebce-76f2-4109-b9f3-a538edb66129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['MS' 'HC']\n"
     ]
    }
   ],
   "source": [
    "# in person preferred walk \n",
    "outpath_1 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_demographic_diagnosis')\n",
    "bw_zv_pws_df_2.loc[:, 'demographic_diagnosis'] = pd.Categorical(bw_zv_pws_df_2.loc[:,'demographic_diagnosis'], categories=['MS', 'HC'], ordered=True)\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_pws_df_2, \n",
    "                              group_col = 'demographic_diagnosis', \n",
    "                              vid_metric_col_suffix = 'zv',\n",
    "                              mat_metric_col_prefix = 'PWS_',\n",
    "                              output_folder_path = outpath_1, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat_allmetrics(bw_zv_pws_df_2, \n",
    "            group_col = 'demographic_diagnosis', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_1, \n",
    "            video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "# Mannwhitneyu test \n",
    "pws_demographic_diagnosis_results =  mannwhitneyu_all_metrics(bw_zv_pws_df_2,\n",
    "                                group_col = 'demographic_diagnosis',\n",
    "                                group_1 = 'HC', \n",
    "                                group_2 = 'MS', \n",
    "                                metric_col_suffix = 'zv', \n",
    "                                output_folder_path = outpath_1, \n",
    "                                video_task_str = 'zv_bw_pws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc3ff5b4-082b-4e77-9553-11f67186e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['MS' 'HC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_21076\\3786783435.py:61: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(output_folder_path, 'check_normality', current_metric_col + '_hist.png'))\n"
     ]
    }
   ],
   "source": [
    "# in person fast walk\n",
    "outpath_1b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_demographic_diagnosis')\n",
    "bw_zv_fw_df_2.loc[:, 'demographic_diagnosis'] = pd.Categorical(bw_zv_fw_df_2.loc[:,'demographic_diagnosis'], categories=['MS', 'HC'], ordered=True)\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_fw_df_2, \n",
    "                              group_col = 'demographic_diagnosis', \n",
    "                              vid_metric_col_suffix = 'zv',\n",
    "                              mat_metric_col_prefix = 'FW_',\n",
    "                              output_folder_path = outpath_1b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat_allmetrics(bw_zv_fw_df_2, \n",
    "            group_col = 'demographic_diagnosis', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_1b, \n",
    "            video_task_str = 'zv_bw_fw')\n",
    "\n",
    "# Mannwhitneyu test \n",
    "pws_demographic_diagnosis_results =  mannwhitneyu_all_metrics(bw_zv_fw_df_2,\n",
    "                                group_col = 'demographic_diagnosis',\n",
    "                                group_1 = 'HC', \n",
    "                                group_2 = 'MS', \n",
    "                                metric_col_suffix = 'zv', \n",
    "                                output_folder_path = outpath_1b, \n",
    "                                video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c55fc9c-a14a-486e-8bf6-27074c16a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home video - not applicable - only MS participants "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe985869-f95c-4ae1-affc-5398a791e53b",
   "metadata": {},
   "source": [
    "### All video metrics by EDSS severity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba89f934-3fd0-4c59-a717-1d94768d6509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moderate', 'mild', 'severe']\n",
      "Categories (3, object): ['mild' < 'moderate' < 'severe']\n"
     ]
    }
   ],
   "source": [
    "print(bw_zv_pws_edss_df['edss_severity_cat'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e2bab31-0a41-4f99-a4ac-05cee00e77d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['moderate', 'mild', 'severe']\n",
      "Categories (3, object): ['mild' < 'moderate' < 'severe']\n"
     ]
    }
   ],
   "source": [
    "# in person preferred walk \n",
    "outpath_2 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_edss_severity')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_pws_edss_df, \n",
    "                              group_col = 'edss_severity_cat', \n",
    "                              vid_metric_col_suffix = 'zv', \n",
    "                              mat_metric_col_prefix = 'PWS_',\n",
    "                              output_folder_path = outpath_2, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat_allmetrics(bw_zv_pws_edss_df, \n",
    "            group_col = 'edss_severity_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_2, \n",
    "            video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "zv_pws_edss_severity_kruskal = kruskalwallace_all_metrics(df = bw_zv_pws_edss_df,\n",
    "                                                          group_col = 'edss_severity_cat',\n",
    "                                                          group_1 = 'mild',\n",
    "                                                          group_2 = 'moderate',\n",
    "                                                          group_3 = 'severe',\n",
    "                                                          metric_col_suffix = 'zv',\n",
    "                                                          output_folder_path = outpath_2,\n",
    "                                                          video_task_str = 'zv_bw_pws')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf68893b-dbe2-4df7-a1bd-1e01e3bc7f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['moderate', 'mild', 'severe']\n",
      "Categories (3, object): ['mild' < 'moderate' < 'severe']\n"
     ]
    }
   ],
   "source": [
    "# in person fast walk \n",
    "outpath_2b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_edss_severity')\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_zv_fw_edss_df, \n",
    "                              group_col = 'edss_severity_cat', \n",
    "                              vid_metric_col_suffix = 'zv', \n",
    "                              mat_metric_col_prefix = 'FW_',\n",
    "                              output_folder_path = outpath_2b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat_allmetrics(bw_zv_fw_edss_df, \n",
    "            group_col = 'edss_severity_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_2b, \n",
    "            video_task_str = 'zv_bw_fw')\n",
    "\n",
    "zv_fw_edss_severity_kruskal = kruskalwallace_all_metrics(df = bw_zv_fw_edss_df,\n",
    "                                                          group_col = 'edss_severity_cat',\n",
    "                                                          group_1 = 'mild',\n",
    "                                                          group_2 = 'moderate',\n",
    "                                                          group_3 = 'severe',\n",
    "                                                          metric_col_suffix = 'zv',\n",
    "                                                          output_folder_path = outpath_2b,\n",
    "                                                          video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48df83c1-6d71-40da-aed3-e953abe34136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['moderate', 'severe', 'mild']\n",
      "Categories (3, object): ['mild' < 'moderate' < 'severe']\n"
     ]
    }
   ],
   "source": [
    "# home videos \n",
    "outpath_2c = os.path.join(out_path, 'hv_vs_bw_pws_metric_by_edss_severity')\n",
    "\n",
    "# histograms \n",
    "check_ttest_anova_assumptions(bw_hv_edss_df, \n",
    "                              group_col = 'edss_severity_cat', \n",
    "                              vid_metric_col_suffix = 'hv', \n",
    "                              mat_metric_col_prefix = 'PWS_',\n",
    "                              output_folder_path = outpath_2c, \n",
    "                              video_task_str = 'hv_bw_pws')\n",
    "\n",
    "\n",
    "# boxplots \n",
    "boxplot_cat_allmetrics(bw_hv_edss_df, \n",
    "            group_col = 'edss_severity_cat', \n",
    "            metric_col_suffix = 'hv',\n",
    "            output_folder_path = outpath_2c, \n",
    "            video_task_str = 'hv_bw_pws')\n",
    "\n",
    "hv_pws_edss_severity_kruskal = kruskalwallace_all_metrics(df = bw_hv_edss_df,\n",
    "                                                          group_col = 'edss_severity_cat',\n",
    "                                                          group_1 = 'mild',\n",
    "                                                          group_2 = 'moderate',\n",
    "                                                          group_3 = 'severe',\n",
    "                                                          metric_col_suffix = 'hv',\n",
    "                                                          output_folder_path = outpath_2c,\n",
    "                                                          video_task_str = 'hv_bw_pws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b1ca18-f6b1-48ef-8c98-62e1c55b11cf",
   "metadata": {},
   "source": [
    "### All Video metrics by T25FW time category  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "13ab450a-e808-453f-b28e-bb540c57b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['6_to_8', 'under_6', 'over_8']\n",
      "Categories (3, object): ['under_6' < '6_to_8' < 'over_8']\n"
     ]
    }
   ],
   "source": [
    "# in person preferred walk \n",
    "outpath_4 = os.path.join(out_path, 'zv_vs_bw_pws_metric_by_t25fw_group')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_pws_t25fw_df, \n",
    "                              group_col = 't25fw_group_cat', \n",
    "                              vid_metric_col_suffix = 'zv', \n",
    "                              mat_metric_col_prefix = 'PWS_',\n",
    "                              output_folder_path = outpath_4, \n",
    "                              video_task_str = 'zv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat_allmetrics(bw_zv_pws_t25fw_df, \n",
    "            group_col = 't25fw_group_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_4, \n",
    "            video_task_str = 'zv_bw_pws')\n",
    "\n",
    "zv_bw_pws_kruskal = kruskalwallace_all_metrics(df = bw_zv_pws_t25fw_df,\n",
    "                                                          group_col = 't25fw_group_cat',\n",
    "                                                          group_1 = 'under_6',\n",
    "                                                          group_2 = '6_to_8',\n",
    "                                                          group_3 = 'over_8',\n",
    "                                                          metric_col_suffix = 'zv',\n",
    "                                                          output_folder_path = outpath_4,\n",
    "                                                          video_task_str = 'zv_bw_pws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cfa27ca-9ca0-4991-8601-855c913fa053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['6_to_8', 'under_6', 'over_8']\n",
      "Categories (3, object): ['under_6' < '6_to_8' < 'over_8']\n"
     ]
    }
   ],
   "source": [
    "# in person fast walk \n",
    "outpath_4b = os.path.join(out_path, 'zv_vs_bw_fw_metric_by_t25fw_group')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_zv_fw_t25fw_df,\n",
    "                              group_col = 't25fw_group_cat', \n",
    "                              vid_metric_col_suffix = 'zv',\n",
    "                              mat_metric_col_prefix = 'FW_',\n",
    "                              output_folder_path = outpath_4b, \n",
    "                              video_task_str = 'zv_bw_fw')\n",
    "\n",
    "\n",
    "boxplot_cat_allmetrics(bw_zv_fw_t25fw_df, \n",
    "            group_col = 't25fw_group_cat', \n",
    "            metric_col_suffix = 'zv',\n",
    "            output_folder_path = outpath_4b, \n",
    "            video_task_str = 'zv_bw_fw')\n",
    "\n",
    "zv_bw_fw_kruskal = kruskalwallace_all_metrics(df = bw_zv_fw_t25fw_df,\n",
    "                                                          group_col = 't25fw_group_cat',\n",
    "                                                          group_1 = 'under_6',\n",
    "                                                          group_2 = '6_to_8',\n",
    "                                                          group_3 = 'over_8',\n",
    "                                                          metric_col_suffix = 'zv',\n",
    "                                                          output_folder_path = outpath_4b,\n",
    "                                                          video_task_str = 'zv_bw_fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55a32a29-7a0c-4aba-8f69-5bdb5e301d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups\n",
      "['under_6' '6_to_8' 'over_8']\n"
     ]
    }
   ],
   "source": [
    "# home videos \n",
    "outpath_4c = os.path.join(out_path, 'hv_vs_bw_pws_metric_by_t25fw_group')\n",
    "\n",
    "# dataset = participants with MS \n",
    "check_ttest_anova_assumptions(bw_hv_t25fw_df, \n",
    "                              group_col = 't25fw_group_cat', \n",
    "                              vid_metric_col_suffix = 'hv', \n",
    "                              mat_metric_col_prefix = 'PWS_', \n",
    "                              output_folder_path = outpath_4c, \n",
    "                              video_task_str = 'hv_bw_pws')\n",
    "\n",
    "\n",
    "\n",
    "boxplot_cat_allmetrics(bw_hv_t25fw_df, \n",
    "            group_col = 't25fw_group_cat', \n",
    "            metric_col_suffix = 'hv',\n",
    "            output_folder_path = outpath_4c, \n",
    "            video_task_str = 'hv_bw_pws')\n",
    "\n",
    "hv_bw_pws_kruskal = kruskalwallace_all_metrics(df = bw_hv_t25fw_df,\n",
    "                                                          group_col = 't25fw_group_cat',\n",
    "                                                          group_1 = 'under_6',\n",
    "                                                          group_2 = '6_to_8',\n",
    "                                                          group_3 = 'over_8',\n",
    "                                                          metric_col_suffix = 'hv',\n",
    "                                                          output_folder_path = outpath_4c,\n",
    "                                                          video_task_str = 'hv_bw_pws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afec62d-68f3-454b-bbe0-b1b9b7f5d39a",
   "metadata": {},
   "source": [
    "### Boxplots - trends between video and mat on single plot, only video metrics with corresponding Zeno mat metric \n",
    "- in-person: mat pws, mat fw, in-person vid pws, in-perso vid fw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f39b4416-af9e-4de0-ae20-68d2277c35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-person videos - EDSS severity \n",
    "output_path_1 = os.path.join(out_path, 'zv_bw_pws_and_fw_by_edss_severity')\n",
    "\n",
    "boxplot_vid_and_mat_inperson(video_pws_columns = zv_colnames,\n",
    "                               video_fw_columns = zv_colnames, \n",
    "                               mat_pws_columns = bw_pws_colnames, \n",
    "                               mat_fw_columns = bw_fw_colnames, \n",
    "                               pws_data = bw_zv_pws_edss_df,\n",
    "                               fw_data = bw_zv_fw_edss_df,\n",
    "                               group_col = 'edss_severity_cat', \n",
    "                               output_folder_path = output_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93536d7f-cf2c-4855-ba49-e1189bc90bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-person videos - T25FW groups \n",
    "output_path_2 = os.path.join(out_path, 'zv_bw_pws_and_fw_by_t25fw')\n",
    "\n",
    "boxplot_vid_and_mat_inperson(video_pws_columns = zv_colnames,\n",
    "                               video_fw_columns = zv_colnames, \n",
    "                               mat_pws_columns = bw_pws_colnames, \n",
    "                               mat_fw_columns = bw_fw_colnames, \n",
    "                               pws_data = bw_zv_pws_t25fw_df,\n",
    "                               fw_data = bw_zv_fw_t25fw_df,\n",
    "                               group_col = 't25fw_group_cat', \n",
    "                               output_folder_path = output_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10df33d-1f6e-4c5d-9306-7d71fc32434b",
   "metadata": {},
   "source": [
    "- home: home vid pws, mat pws + mat fw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c2a800e-8eed-4477-b1f8-86c70f287272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos - EDSS severity \n",
    "output_path_3 = os.path.join(out_path, 'hv_bw_pws_and_fw_by_edss_severity')\n",
    "\n",
    "boxplot_vid_and_mat_home(video_pws_columns = hv_colnames, \n",
    "                         mat_pws_columns = bw_pws_colnames, \n",
    "                         mat_fw_columns = bw_fw_colnames,\n",
    "                         home_df = bw_hv_edss_df, \n",
    "                         group_col = 'edss_severity_cat',\n",
    "                         output_folder_path = output_path_3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d43c959-2cb9-41bb-9eb6-6c5bddd94f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos - T25FW groups \n",
    "output_path_4 = os.path.join(out_path, 'hv_bw_pws_and_fw_by_t25fw')\n",
    "\n",
    "boxplot_vid_and_mat_home(video_pws_columns = hv_colnames, \n",
    "                         mat_pws_columns = bw_pws_colnames, \n",
    "                         mat_fw_columns = bw_fw_colnames,\n",
    "                         home_df = bw_hv_t25fw_df, \n",
    "                         group_col = 't25fw_group_cat',\n",
    "                         output_folder_path = output_path_4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afe9f3-502f-4c36-90b5-a1c4568dd027",
   "metadata": {},
   "source": [
    "## Quartiles \n",
    "- Group into metric quartiles and calculate summary \n",
    "- Kruskal wallace  for each group\n",
    "- plot after see data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "979580eb-43ff-4aa0-85a4-d0865a7ae612",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: Index([1.0, 2.0, 2.0, 3.0, 8.0], dtype='float64', name='walking_segmets_n_pose_zv').\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m anova_kruskal_cols \u001b[38;5;241m=\u001b[39m zv_colnames \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbingoEHR_EDSS_measure_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsfcEHR_T25FW SPEED AVG\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m      3\u001b[0m output_1 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(out_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzv_vs_bw_pws_quartiles\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmetric_quartile_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbw_zv_pws_df_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmetric_col_suffix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43manova_kruskal_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manova_kruskal_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_1\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[19], line 25\u001b[0m, in \u001b[0;36mmetric_quartile_analysis\u001b[1;34m(df, metric_col_suffix, anova_kruskal_cols, output_folder_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_i, current_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(video_columns):\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# new column - for each metric, 1 = 0-.25 quantile, 2 = .25-.5, 3 = .5-.75, 4 = .75-1\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 25\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[:, current_metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_quartile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqcut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuartile 1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuartile 2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuartile 3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuartile 4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     quartile_col_names\u001b[38;5;241m.\u001b[39mappend(current_metric \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_quartile\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# group by the quartile columns and calculate describe stats for each metrics columns; save .csv \u001b[39;00m\n",
      "File \u001b[1;32m~\\venv_home_video_analysis_2\\lib\\site-packages\\pandas\\core\\reshape\\tile.py:340\u001b[0m, in \u001b[0;36mqcut\u001b[1;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[0;32m    336\u001b[0m quantiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, q \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_integer(q) \u001b[38;5;28;01melse\u001b[39;00m q\n\u001b[0;32m    338\u001b[0m bins \u001b[38;5;241m=\u001b[39m x_idx\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mquantile(quantiles)\n\u001b[1;32m--> 340\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m \u001b[43m_bins_to_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[1;32m~\\venv_home_video_analysis_2\\lib\\site-packages\\pandas\\core\\reshape\\tile.py:443\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    447\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[0;32m    449\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Bin edges must be unique: Index([1.0, 2.0, 2.0, 3.0, 8.0], dtype='float64', name='walking_segmets_n_pose_zv').\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "# in-person preferred walking speed video metrics \n",
    "anova_kruskal_cols = zv_colnames + ['bingoEHR_EDSS_measure_value'] + ['msfcEHR_T25FW SPEED AVG'] \n",
    "output_1 = os.path.join(out_path, 'zv_vs_bw_pws_quartiles')\n",
    "\n",
    "metric_quartile_analysis(bw_zv_pws_df_2, \n",
    "                         metric_col_suffix = 'zv', \n",
    "                         anova_kruskal_cols = anova_kruskal_cols, \n",
    "                         output_folder_path = output_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e07592-0ea7-402f-9abb-a76c6a188384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-person fast walking speed video metrics \n",
    "anova_kruskal_cols = zv_colnames + ['bingoEHR_EDSS_measure_value'] + ['msfcEHR_T25FW SPEED AVG'] \n",
    "output_2 = os.path.join(out_path, 'zv_vs_bw_fw_quartiles')\n",
    "\n",
    "metric_quartile_analysis(bw_zv_fw_df_2, \n",
    "                         metric_col_suffix = 'zv', \n",
    "                         anova_kruskal_cols = anova_kruskal_cols, \n",
    "                         output_folder_path = output_2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb7f48c-ba49-49d2-a015-86e162155601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos \n",
    "anova_kruskal_cols = hv_colnames + ['bingoEHR_EDSS_measure_value'] + ['msfcEHR_T25FW SPEED AVG'] \n",
    "output_3 = os.path.join(out_path, 'hv_vs_bw_pws_quartiles')\n",
    "\n",
    "metric_quartile_analysis(bw_hv_pws_df_2, \n",
    "                         metric_col_suffix = 'hv', \n",
    "                         anova_kruskal_cols = anova_kruskal_cols, \n",
    "                         output_folder_path = output_3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d03692-836c-470a-98e4-1e2529385fe4",
   "metadata": {},
   "source": [
    "## Other future ideas\n",
    "- Remove outliers if needed??\n",
    "- update to only include one mat metric per participant, if they have two home videso\n",
    "- cluster, PCA, kernel: predict edss given set of metrics (from zeno, then say X amount of people at home able to collect good videos)\n",
    "- longitudanl from people with multiple follow ups?\n",
    "- Random forrest - decision tree\n",
    "- binary classifier/cutoff score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
