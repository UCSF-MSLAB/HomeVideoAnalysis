{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4df7ad1-4a45-4989-ac57-7f121ac7a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe6b3b-75c4-4033-90ce-bb24f1c0cf37",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62fab78-2d4d-4394-8f54-42a884cabecf",
   "metadata": {},
   "source": [
    "Note - need to run analysis_video_vs_mat_and_outcomes script on both home and in-person videos first. That script created merged file used below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a825ec-dc48-44cd-9e2d-157f2eb35c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6547690b-40da-44b8-830c-0c7e571e1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis',\n",
    "                           version, \n",
    "                          'video_visit_participant_counts')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a924b00b-0577-4626-b0f4-49081311c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_df = pd.read_excel(r'C:\\Users\\mmccu\\AppData\\Local\\Temp\\ccsecure\\2024_10_15_BrainWalk_AllData_Long_MM.xlsx', \n",
    "                     index_col = None, \n",
    "                     usecols = ['bw_id', 'record_id', 'visit_date', 'demoEHR_DiseaseDuration',\n",
    "                                'demoEHR_GENDER', 'demoEHR_Age', 'demographic_diagnosis', 'bingoEHR_DX_MS DX', 'demoEHR_REC_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606d2bdf-a959-488c-9793-07b03cc8b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeno videos \n",
    "# all in-person videos \n",
    "zv_all_videos_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis\\all_zeno_videos.csv'\n",
    "zv_all_videos_df = pd.read_csv(zv_all_videos_path, index_col = 0)\n",
    "zv_all_videos_df.rename(columns={'bw_id': 'id_video'}, inplace=True)\n",
    "\n",
    "\n",
    "# included video .csv files - all videos included in analysis \n",
    "zv_included_videos_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code',\n",
    "                                       'gait_bw_zeno_outputs_' + version,\n",
    "                                       'gait_bw_zeno_outputs_' + version + '_included_videos.csv') \n",
    "zv_included_videos_df = pd.read_csv(zv_included_videos_path, index_col = 0)\n",
    "\n",
    "# data merged w brainwalk \n",
    "# fast walk\n",
    "zv_merged_fw_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                                 version, \n",
    "                                 'zv_bw_merged_gait_vertical_FW_1.csv')\n",
    "zv_merged_fw_df = pd.read_csv(zv_merged_fw_path, index_col = 0)\n",
    "\n",
    "# preferred walk \n",
    "zv_merged_pws_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                                 version, \n",
    "                                 'zv_bw_merged_gait_vertical_PWS_1.csv')\n",
    "zv_merged_pws_df = pd.read_csv(zv_merged_pws_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8029dc4f-8b0e-4438-8b19-9370eaf51b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Home videos \n",
    "hv_all_videos_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis\\all_home_videos.csv'\n",
    "hv_all_videos_df = pd.read_csv(hv_all_videos_path, index_col = 0)\n",
    "hv_all_videos_df.rename(columns={'bw_id': 'id_video'}, inplace=True)\n",
    "\n",
    "# included video .csv files - all videos included in analysis \n",
    "hv_included_videos_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code',\n",
    "                                       'gait_bw_home_outputs_' + version,\n",
    "                                       'gait_bw_home_outputs_' + version + '_included_videos.csv') \n",
    "hv_included_videos_df = pd.read_csv(hv_included_videos_path, index_col = 0)\n",
    "\n",
    "# data merged w brainwalk  \n",
    "hv_merged_bw_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                                 version, \n",
    "                                 'hv_bw_merged.csv')\n",
    "hv_merged_bw_path_df = pd.read_csv(hv_merged_bw_path, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46794b-75ce-4202-81ae-fb92c0eff51b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Merging Functions \n",
    "Merge video dates and ids with brainwalk data --> MS vs HC counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32099d55-9d9e-4f8b-880d-89cc21736ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = gait_vertical_PWS_1 or gait_vertical_FW_1\n",
    "def merge_bw_zv(bw_df, zv_df):\n",
    "    \n",
    "    # filter bw ids dataset to only those included in video data set \n",
    "    zv_in_bw_df = bw_df[bw_df['bw_id'].isin(zv_df['id_video'])]\n",
    "\n",
    "    print('total bw rows with id in video dataset') \n",
    "    print(len(zv_in_bw_df))\n",
    "\n",
    "    # merge bw data set rows with zeno videos rows \n",
    "        # merge bw data set rows with zeno videos rows \n",
    "        # id and date needs to be the same \n",
    "        # should only use each brainwalk visit once - once PWS_1 video per person \n",
    "\n",
    "    merged_bw_zv = []\n",
    "\n",
    "    # Loop through each row in zv_df\n",
    "    for index, zv_row in zv_df.iterrows():\n",
    "        current_id = zv_row['id_video']\n",
    "        current_date = zv_row['video_date']\n",
    "        zv_row_df = pd.DataFrame([zv_row])\n",
    "\n",
    "        # Find rows in brainwalk data set with same id and same date as current zv data \n",
    "        zv_in_bw_current_id_rows = zv_in_bw_df[(zv_in_bw_df['bw_id'] == current_id) & (zv_in_bw_df['visit_date'] == current_date)]\n",
    "        #zv_in_bw_current_id_date_rows = zv_in_bw_current_id_rows[zv_in_bw_current_id_rows['visit_date'] == current_date]\n",
    "   \n",
    "        if len(zv_in_bw_current_id_rows) == 1: \n",
    "            bw_row_to_merge = zv_in_bw_current_id_rows\n",
    "            # merge bw and zv, store merged row\n",
    "            merged_row = zv_row_df.merge(bw_row_to_merge, left_on='id_video', right_on='bw_id')\n",
    "            merged_bw_zv.append(merged_row)\n",
    "        \n",
    "        # if more than one row for the id and date, pick one with least na values \n",
    "        elif len(zv_in_bw_current_id_rows) > 1:\n",
    "            bw_row_to_merge = zv_in_bw_current_id_rows.loc[[zv_in_bw_current_id_rows.isna().sum(axis=1).idxmin()]]\n",
    "            # merge bw and zv, store merged row\n",
    "            merged_row = zv_row_df.merge(bw_row_to_merge, left_on='id_video', right_on='bw_id')\n",
    "            merged_bw_zv.append(merged_row)\n",
    "            print('multiple rows in bw dataset for the id and date combo')\n",
    "            print(current_id)\n",
    "            print(current_date)\n",
    "\n",
    "        else: \n",
    "            print('No matching id and daterow from video vs mat')\n",
    "            print(current_id)\n",
    "            print(current_date)\n",
    "\n",
    "\n",
    "    # merge all bw and zv data together \n",
    "    merged_bw_zv_df = pd.concat(merged_bw_zv)\n",
    "    merged_bw_zv_df = merged_bw_zv_df.reset_index(drop=True) # reset index \n",
    "\n",
    "    # check same ID for each row \n",
    "    print('mismatched zeno video vs brainwalk id')\n",
    "    print(sum(merged_bw_zv_df['id_video'] != merged_bw_zv_df['bw_id']))\n",
    "\n",
    "    print('mismatched zeno video vs brainwalk date')\n",
    "    print(sum(merged_bw_zv_df['video_date'] != merged_bw_zv_df['visit_date']))\n",
    "\n",
    "    return merged_bw_zv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b3dcc2-0cdc-40a2-b2a0-679437bd9ea1",
   "metadata": {},
   "source": [
    "## Summarize Video Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781de436-0986-4102-bffd-d5782d63072b",
   "metadata": {},
   "source": [
    "### All Videos ran through pose estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54aaa537-bbe6-4863-a08f-b7a27da1d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  total number of videos into algorithm and total # videos included \n",
    "    # for figure for each iteration of linear walking algorithm \n",
    "\n",
    "# Zeno Videos \n",
    "zv_total_videos = zv_all_videos_df['file_name'].count()\n",
    "# preferred walking speed \n",
    "zv_total_pws_videos_df = zv_all_videos_df.loc[zv_all_videos_df['file_name'] == 'gait_vertical_PWS_1']\n",
    "zv_total_pws_videos = zv_total_pws_videos_df['file_name'].count()\n",
    "# fast walkign speed \n",
    "zv_total_fw_videos_df = zv_all_videos_df.loc[zv_all_videos_df['file_name'] == 'gait_vertical_FW_1']\n",
    "zv_total_fw_videos = zv_total_fw_videos_df['file_name'].count()\n",
    "\n",
    "# Home Videos -----------------------------------------------------\n",
    "# There originally were XX right turning and XX left turning videos from XX participants \n",
    "hv_total_videos = hv_all_videos_df['file_name'].count()\n",
    "#right \n",
    "hv_total_r_videos_df = hv_all_videos_df.loc[hv_all_videos_df['file_name'].str.contains('gait_vertical_right')]\n",
    "hv_total_r_videos = hv_total_r_videos_df['file_name'].count()\n",
    "# left \n",
    "hv_total_l_videos_df = hv_all_videos_df.loc[hv_all_videos_df['file_name'].str.contains('gait_vertical_left')]\n",
    "hv_total_l_videos = hv_total_l_videos_df['file_name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbf8dab-55b4-4d6e-9c55-0957bc7f7ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total bw rows with id in video dataset\n",
      "331\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0010\n",
      "2022-10-05 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0010\n",
      "2022-10-05 00:00:00\n",
      "multiple rows in bw dataset for the id and date combo\n",
      "BW-0010\n",
      "2023-10-18 00:00:00\n",
      "multiple rows in bw dataset for the id and date combo\n",
      "BW-0010\n",
      "2023-10-18 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0022\n",
      "2023-04-18 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0022\n",
      "2023-04-18 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0031\n",
      "2023-04-21 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0031\n",
      "2023-04-21 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0036\n",
      "2024-04-02 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0036\n",
      "2024-04-02 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2023-05-02 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2023-05-02 00:00:00\n",
      "multiple rows in bw dataset for the id and date combo\n",
      "BW-0044\n",
      "2023-11-30 00:00:00\n",
      "multiple rows in bw dataset for the id and date combo\n",
      "BW-0044\n",
      "2023-11-30 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2024-04-08 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0044\n",
      "2024-04-08 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0063\n",
      "2024-07-15 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0063\n",
      "2024-07-15 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0067\n",
      "2024-01-09 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0067\n",
      "2024-01-09 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0092\n",
      "2024-08-19 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0092\n",
      "2024-08-19 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0110\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0110\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0121\n",
      "2022-07-20 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0162\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0162\n",
      "2024-09-16 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0166\n",
      "2024-06-17 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0166\n",
      "2024-06-17 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0213\n",
      "2024-07-31 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0277\n",
      "2024-08-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0277\n",
      "2024-08-23 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0322\n",
      "2024-06-10 00:00:00\n",
      "No matching id and daterow from video vs mat\n",
      "BW-0322\n",
      "2024-06-10 00:00:00\n",
      "mismatched zeno video vs brainwalk id\n",
      "0\n",
      "mismatched zeno video vs brainwalk date\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# for all Zeno videos \n",
    "# A total of XX adults with a diagnosis of Multiple Sclerosis and a total \n",
    "        # of XX healthy controls were recruited from the University of California, San Francisco (UCSF) \n",
    "\n",
    "zv_all_videos_df['video_date'] = pd.to_datetime(zv_all_videos_df['video_date'].str.replace('_', '-'), format='%Y-%m-%d')\n",
    "\n",
    "# merge bw data with all zeno video data \n",
    "zv_bw_all_videos_df = merge_bw_zv(bw_df, zv_all_videos_df)\n",
    "zv_bw_all_videos_df.to_csv(os.path.join(output_path, 'all_zv_videos_merged_w_bw.csv'))\n",
    "\n",
    "# for all Home videos - as of Jan 13/2025 - only collected home videos from participants with MS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4fd72d-4af7-4fbf-a795-68a5864369d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of videos with bw data - should equal total videos \n",
    "\n",
    "# Zeno Videos \n",
    "zv_bw_total_videos = zv_bw_all_videos_df['file_name'].count()\n",
    "vids_missing_w_bw_merge = zv_total_videos - zv_bw_total_videos \n",
    "\n",
    "# Home Videos - all MS, didn't need to merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b74af6-9d67-43b3-8199-e345c88b145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zeno Videos -  count unique ID w MS  (n participants)\n",
    "zv_bw_all_videos_MS_df = zv_bw_all_videos_df.loc[zv_bw_all_videos_df['demographic_diagnosis'] == 'MS']\n",
    "zv_all_videos_MS_participant_count = zv_bw_all_videos_MS_df['id_video'].nunique()\n",
    "\n",
    "# Zeno Videos - count unique ID w HC  (n participants)\n",
    "zv_bw_all_videos_HC_df = zv_bw_all_videos_df.loc[zv_bw_all_videos_df['demographic_diagnosis'] == 'HC']\n",
    "zv_all_videos_HC_participant_count = zv_bw_all_videos_HC_df['id_video'].nunique()\n",
    "\n",
    "# home videos - all MS, (n participants)\n",
    "hv_all_videos_participant_count = hv_all_videos_df['id_video'].nunique()\n",
    "hv_all_videos_participant_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcf39aca-12bb-4515-bbee-36b079e38b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There originally were XX PWS and XX FW videos from XX participants with MS \n",
    "# and XX PW videos and XX FW videos from XX healthy controls\n",
    "\n",
    "# Zeno videos - FW vs PWS in pwMS \n",
    "zv_all_videos_MS_pws_df = zv_bw_all_videos_MS_df.loc[zv_bw_all_videos_MS_df['file_name'] == 'gait_vertical_PWS_1']\n",
    "zv_all_videos_MS_pws_count = zv_all_videos_MS_pws_df['file_name'].count() \n",
    "\n",
    "zv_all_videos_MS_fw_df = zv_bw_all_videos_MS_df.loc[zv_bw_all_videos_MS_df['file_name'] == 'gait_vertical_FW_1']\n",
    "zv_all_videos_MS_fw_count = zv_all_videos_MS_fw_df['file_name'].count()  \n",
    "\n",
    "# Zeno videos - FW vs PWS in HC \n",
    "zv_all_videos_HC_pws_df = zv_bw_all_videos_HC_df.loc[zv_bw_all_videos_HC_df['file_name'] == 'gait_vertical_PWS_1']\n",
    "zv_all_videos_HC_pws_count = zv_all_videos_HC_pws_df['file_name'].count() \n",
    "\n",
    "zv_all_videos_HC_fw_df = zv_bw_all_videos_HC_df.loc[zv_bw_all_videos_HC_df['file_name'] == 'gait_vertical_FW_1']\n",
    "zv_all_videos_HC_fw_count = zv_all_videos_HC_fw_df['file_name'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63d5c52-6ac1-496c-88b8-d20893107f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dates XX to XX.\n",
    "\n",
    "# Zeno \n",
    "zv_all_videos_first_date = zv_bw_all_videos_df['video_date'].min()\n",
    "zv_all_videos_last_date = zv_bw_all_videos_df['video_date'].max()\n",
    "\n",
    "# Home \n",
    "hv_all_videos_first_date = hv_all_videos_df['video_date'].min()\n",
    "hv_all_videos_last_date = hv_all_videos_df['video_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e106b8-b85d-4ee0-937c-751e2ad282f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#At the time of analysis, XX PwMS and XX healthy controls completed a single visit \n",
    "# and XX PwMS and XX healthy controls greater than one visit (baseline and yearly follow up)\n",
    "\n",
    "# from all videos file:  unique date and id combo --> check for duplicate bw_id \n",
    "\n",
    "# Zeno Videos --------------------------------------------\n",
    "# number of visits (unique id and date combo)\n",
    "zv_all_vids_unique_date_id_df = zv_bw_all_videos_df.drop_duplicates(subset = ['video_date', 'id_video'])\n",
    "zv_all_unique_visits = zv_all_vids_unique_date_id_df['file_name'].count()\n",
    "\n",
    "# participants with MS \n",
    "zv_all_vids_unique_visit_ms = zv_all_vids_unique_date_id_df.loc[zv_all_vids_unique_date_id_df['demographic_diagnosis'] == 'MS']\n",
    "\n",
    "# number of IDs repeated = multiple visits \n",
    "zv_multiple_visits_ms_count = zv_all_vids_unique_visit_ms['id_video'].value_counts()[lambda x: x > 1].count()\n",
    "zv_single_visits_ms_count = zv_all_vids_unique_visit_ms['id_video'].value_counts()[lambda x: x == 1].count()\n",
    "\n",
    "# HC \n",
    "zv_all_vids_unique_visit_hc = zv_all_vids_unique_date_id_df.loc[zv_all_vids_unique_date_id_df['demographic_diagnosis'] == 'HC']\n",
    "\n",
    "# number of IDs repeated = multiple visits \n",
    "zv_multiple_visits_hc_count = zv_all_vids_unique_visit_hc['id_video'].value_counts()[lambda x: x > 1].count()\n",
    "zv_single_visits_hc_count = zv_all_vids_unique_visit_hc['id_video'].value_counts()[lambda x: x == 1].count()\n",
    "\n",
    "# Home Videos ----------------------------------------------\n",
    "# number of visits (unique id and date combo - set of home videos sent back on one day)\n",
    "hv_all_vids_unique_date_id_df = hv_all_videos_df.drop_duplicates(subset = ['video_date', 'id_video'])\n",
    "hv_all_unique_visits = hv_all_vids_unique_date_id_df['file_name'].count()\n",
    "\n",
    "# number of IDs repeated = multiple visits \n",
    "hv_multiple_visits_count = hv_all_vids_unique_date_id_df['id_video'].value_counts()[lambda x: x > 1].count()\n",
    "hv_single_visits_count = hv_all_vids_unique_date_id_df['id_video'].value_counts()[lambda x: x == 1].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c650c5c-8dc3-4cab-b45b-19d51171f7ad",
   "metadata": {},
   "source": [
    "### videos included in analysis \n",
    "- included = videos included after linear walking algorithm\n",
    "- analyzed = included videos with matched BW visit date and data --> need to QA BW dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11912933-c4dc-4360-b5d1-99acecddce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check - do .._bw_merged included videos match the included and excluded file numbers? any lost in the merge with BW? \n",
    "\n",
    "# count num included videos from included .csv then substract # videos in merged .csv (save # lost in merge, same as total values) \n",
    "\n",
    "# Zeno ----------------------------------------- \n",
    "# total included videos - from original script, true # of included vids before merging with brainwalk \n",
    "zv_included_vids_count = zv_included_videos_df['included_vids'].count()\n",
    "\n",
    "# total included videos: pws \n",
    "zv_included_pws_df = zv_included_videos_df.loc[zv_included_videos_df['included_vids'].str.contains('PWS')]\n",
    "zv_included_pws_count = zv_included_pws_df['included_vids'].count()\n",
    "\n",
    "# total included videos: fw \n",
    "zv_included_fw_df = zv_included_videos_df.loc[zv_included_videos_df['included_vids'].str.contains('FW')]\n",
    "zv_included_fw_count = zv_included_fw_df['included_vids'].count()\n",
    "\n",
    "# total_included videos: other tasks? \n",
    "zv_included_otherTask_df = zv_included_videos_df.loc[~zv_included_videos_df['included_vids'].str.contains('FW|PWS')]\n",
    "zv_included_otherTask_count = zv_included_otherTask_df['included_vids'].count()\n",
    "\n",
    "# total analyzed videos after merge with brainwalk data \n",
    "# pws \n",
    "zv_analyzed_pws_count = zv_merged_pws_df['id_date_pose_zv'].count()\n",
    "#fw \n",
    "zv_analyzed_fw_count = zv_merged_fw_df['id_date_pose_zv'].count()\n",
    "\n",
    "# total included (true) - total analyzed (some missing with date issues or wrong task)\n",
    "zv_included_missing_after_merge = zv_included_vids_count - (zv_analyzed_pws_count + zv_analyzed_fw_count) \n",
    "\n",
    "# Home Videos -----------------------------------------------------\n",
    "# total included videos - from original script, true # of included vids before merging with brainwalk \n",
    "hv_included_vids_count = hv_included_videos_df['included_vids'].count()\n",
    "#right\n",
    "hv_included_r_df = hv_included_videos_df.loc[zv_included_videos_df['included_vids'].str.contains('gait_vertical_right')]\n",
    "hv_included_r_count = hv_included_r_df['included_vids'].count()\n",
    "#left \n",
    "hv_included_l_df = hv_included_videos_df.loc[zv_included_videos_df['included_vids'].str.contains('gait_vertical_left')]\n",
    "hv_included_l_count = hv_included_l_df['included_vids'].count()\n",
    "\n",
    "# total analyzed after merge w brainwalkd data\n",
    "hv_analyzed_count = hv_merged_bw_path_df['id_date_pose_hv'].count()\n",
    "hv_included_missing_after_merge = hv_included_vids_count - hv_analyzed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1448fa52-93b3-4a53-9f52-cc3fe1cc3680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_date_pose_zv', 'video_id_date_name_pose_zv', 'task_pose_zv',\n",
       "       'stride_time_mean_sec_pose_zv', 'stride_time_median_sec_pose_zv',\n",
       "       'stride_time_std_pose_zv', 'stride_time_cv_pose_zv',\n",
       "       'stride_time_max_pose_zv', 'stride_time_min_pose_zv',\n",
       "       'mean_cadence_step_per_min_pose_zv', 'stride_width_mean_cm_pose_zv',\n",
       "       'stride_width_median_cm_pose_zv', 'stride_width_std_pose_zv',\n",
       "       'stride_width_cv_pose_zv', 'stride_width_max_pose_zv',\n",
       "       'stride_width_min_pose_zv', 'foot1_gait_cycle_time_mean_pose_zv',\n",
       "       'foot1_stance_time_mean_pose_zv', 'foot1_stance_per_mean_pose_zv',\n",
       "       'foot1_swing_time_mean_pose_zv', 'foot1_swing_per_mean_pose_zv',\n",
       "       'foot1_ini_double_support_time_mean_pose_zv',\n",
       "       'foot1_term_double_support_time_mean_pose_zv',\n",
       "       'foot1_tot_double_support_time_mean_pose_zv',\n",
       "       'foot1_double_support_per_mean_pose_zv',\n",
       "       'foot1_single_support_time_mean_pose_zv',\n",
       "       'foot1_single_support_per_mean_pose_zv', 'walk_segment_pose_zv',\n",
       "       'foot1_pose_zv', 'id_video', 'visit_date_video', 'bw_id', 'record_id',\n",
       "       'visit_date', 'demoEHR_DiseaseDuration', 'demoEHR_GENDER',\n",
       "       'demoEHR_Age', 'bingoEHR_DX_MS DX', 'demoEHR_REC_1', 'demoEHR_REC_2',\n",
       "       'bingoEHR_EDSS_measure_value', 'msfcEHR_T25FW SPEED AVG',\n",
       "       'PWS_cadencestepsminmean', 'PWS_singlesupportmean',\n",
       "       'PWS_singlesupportratiolr', 'PWS_stridetimeseccv',\n",
       "       'PWS_stridetimesecmean', 'PWS_stridewidthcmmean', 'PWS_stridewidthcmsd',\n",
       "       'PWS_totaldsupportmean', 'PWS_totaldsupportratiolr',\n",
       "       'demographic_diagnosis', 'falls_number', 'falls_since_lastsurvey',\n",
       "       'near_falls', 'near_falls_no', 'strength_lt_leg', 'strength_max',\n",
       "       'strength_rt_leg', 'sum_total_scores', 'edss_severity_num',\n",
       "       'edss_severity_cat', 't25fw_group_num', 't25fw_group_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zv_merged_pws_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "080abc5b-37ca-4872-9bc0-d560a11d8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbers based off of videos analyzed \n",
    "    # some true included videos lost when merging brainwalk and need to fix \n",
    "    # get 'missing_after_merge' variables to 0\n",
    "\n",
    "# Zeno---------------------------------\n",
    "# After running the pose estimation through the final version of the linear walking identification algorithm, \n",
    "# at least one linear walking segment was identified in XX PWS and XX FW videos from XX participants with MS \n",
    "# and XX PW videos and XX FW videos from  XX healthy controls\n",
    "\n",
    "# PWS \n",
    "    # MS vs HC \n",
    "zv_analyzed_pws_MS_df = zv_merged_pws_df.loc[zv_merged_pws_df['demographic_diagnosis'] == 'MS']\n",
    "zv_analyzed_pws_MS_count = zv_analyzed_pws_MS_df['demographic_diagnosis'].count()\n",
    "\n",
    "zv_analyzed_pws_HC_df = zv_merged_pws_df.loc[zv_merged_pws_df['demographic_diagnosis'] == 'HC']\n",
    "zv_analyzed_pws_HC_count = zv_analyzed_pws_HC_df['demographic_diagnosis'].count()\n",
    "\n",
    "# unique participants with PWS video analyzed\n",
    "zv_analyzed_pws_MS_participants = zv_analyzed_pws_MS_df['id_video'].nunique()\n",
    "zv_analyzed_pws_HC_participants = zv_analyzed_pws_HC_df['id_video'].nunique()\n",
    "\n",
    "# FW \n",
    "    # MS vs HC \n",
    "zv_analyzed_fw_MS_df = zv_merged_fw_df.loc[zv_merged_fw_df['demographic_diagnosis'] == 'MS']\n",
    "zv_analyzed_fw_MS_count = zv_analyzed_fw_MS_df['demographic_diagnosis'].count()\n",
    "\n",
    "zv_analyzed_fw_HC_df = zv_merged_fw_df.loc[zv_merged_fw_df['demographic_diagnosis'] == 'HC']\n",
    "zv_analyzed_fw_HC_count = zv_analyzed_fw_HC_df['demographic_diagnosis'].count()\n",
    "\n",
    "# unique participant with FW video analyzed\n",
    "zv_analyzed_fw_MS_participants = zv_analyzed_fw_MS_df['id_video'].nunique()\n",
    "zv_analyzed_fw_HC_participants = zv_analyzed_fw_HC_df['id_video'].nunique()\n",
    "\n",
    "# sum FW and PWS analyzed participants \n",
    "# MS \n",
    "zv_analyzed_all_MS_df = pd.concat([zv_analyzed_pws_MS_df, zv_analyzed_fw_MS_df])\n",
    "zv_analyzed_MS_participants = zv_analyzed_all_MS_df['id_video'].nunique()\n",
    "\n",
    "#HC \n",
    "zv_analyzed_all_HC_df = pd.concat([zv_analyzed_pws_HC_df, zv_analyzed_fw_HC_df])\n",
    "zv_analyzed_HC_participants = zv_analyzed_all_HC_df['id_video'].nunique()\n",
    "\n",
    "# Home --------------------------------------------------\n",
    "# After running the pose estimation through the final version of the linear walking identification algorithm, \n",
    "# at least one linear walking segment was identified in XX right turning and XX left turning videos from XX participants \n",
    "\n",
    "# right vs left \n",
    "\n",
    "hv_analysed_r_df = hv_merged_bw_path_df.loc[hv_merged_bw_path_df['task_pose_hv'].str.contains('gait_vertical_right')]\n",
    "hv_analysed_r_count = hv_analysed_r_df['task_pose_hv'].count()\n",
    "\n",
    "hv_analysed_l_df = hv_merged_bw_path_df.loc[hv_merged_bw_path_df['task_pose_hv'].str.contains('gait_vertical_left')]\n",
    "hv_analysed_l_count = hv_analysed_l_df['task_pose_hv'].count()\n",
    "\n",
    "# unique paricipants with any included videos \n",
    "hv_analyzed_all_participants = hv_merged_bw_path_df['id_video'].nunique() \n",
    "\n",
    "# participants with right turn \n",
    "hv_analyzed_r_participants = hv_analysed_r_df['id_video'].nunique()\n",
    "\n",
    "# participants with left turn \n",
    "hv_analyzed_l_participants = hv_analysed_l_df['id_video'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fef6e118-96a2-4660-8584-f451888e63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append values to zeno_video_summary --> .csv file \n",
    "\n",
    "zeno_video_summary = []\n",
    "zeno_video_summary.append({'num_total_zeno_videos' : zv_total_videos,\n",
    "                           'num_total_pws_zeno_videos' : zv_total_pws_videos,\n",
    "                           'num_total_fw_zeno_videos' : zv_total_fw_videos, \n",
    "                           'num_total_zeno_videos_lostInMerge' : vids_missing_w_bw_merge,\n",
    "                           'num_total_zeno_vids_w_bw' : zv_bw_total_videos,\n",
    "                           'num_total_zeno_particpants_wMS' : zv_all_videos_MS_participant_count,\n",
    "                           'num_total_zeno_pwMS_pws_vids' : zv_all_videos_MS_pws_count, \n",
    "                           'num_total_zeno_pwMS_fw_vids' : zv_all_videos_MS_fw_count,\n",
    "                           'num_total_zeno_particpants_HC' : zv_all_videos_HC_participant_count, \n",
    "                           'num_total_zeno_HC_pws_vids' : zv_all_videos_HC_pws_count, \n",
    "                           'num_total_zeno_HC_fw_vids' : zv_all_videos_HC_fw_count,\n",
    "                           'first_total_zeno_vid_date': zv_all_videos_first_date,\n",
    "                           'last_total_zeno_vid_date': zv_all_videos_last_date, \n",
    "                           'total_zeno_vid_visits' : zv_all_unique_visits,\n",
    "                           'num_total_zeno_ms_multiple_visits' : zv_multiple_visits_ms_count, \n",
    "                           'num_total_zeno_ms_single_visits': zv_single_visits_ms_count,\n",
    "                           'num_total_zeno_hc_multiple_visits' : zv_multiple_visits_hc_count,\n",
    "                           'num_total_zeno_hc_single_visits' : zv_single_visits_hc_count,\n",
    "                           'num_included_zeno_vids' : zv_included_vids_count,\n",
    "                           'num_included_zeno_pws_vids': zv_included_pws_count,\n",
    "                           'num_included_zeno_fw_vids': zv_included_fw_count,\n",
    "                           'num_included_zeno_otherTask_vids' : zv_included_otherTask_count,\n",
    "                           'num_analyzed_zeno_pws_vids' : zv_analyzed_pws_count,\n",
    "                           'num_analyzed_zeno_fw_vids' : zv_analyzed_fw_count,\n",
    "                           'num_zv_vids_incl_lostInMerge' : zv_included_missing_after_merge,\n",
    "                           'num_analyzed_zeno_MS_participants' : zv_analyzed_MS_participants,\n",
    "                           'num_analyzed_zeno_HC_participants' : zv_analyzed_HC_participants,\n",
    "                           'num_analyzed_zeno_MS_pws_participants' : zv_analyzed_pws_MS_participants,\n",
    "                           'num_analyzed_zeno_MS_pws_vids' : zv_analyzed_pws_MS_count,\n",
    "                           'num_analyzed_zeno_HC_pws_participants' : zv_analyzed_pws_HC_participants, \n",
    "                           'num_analyzed_zeno_HC_pws_vids' : zv_analyzed_pws_HC_count,\n",
    "                           'num_analyzed_zeno_MS_fw_participants' : zv_analyzed_fw_MS_participants, \n",
    "                           'num_analyzed_zeno_MS_fw_vids' : zv_analyzed_fw_MS_count,\n",
    "                           'num_analyzed_zeno_HC_fw_participants' : zv_analyzed_fw_HC_participants,\n",
    "                           'num_analyzed_zeno_HC_fw_vids' : zv_analyzed_fw_HC_count                       \n",
    "                          })\n",
    "\n",
    "\n",
    "zeno_video_summary_df = pd.DataFrame(zeno_video_summary)\n",
    "zeno_video_summary_df.to_csv(os.path.join(output_path, 'zeno_video_summary_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f379b6-39ab-40ce-ba5f-7bff7d629cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append values to home_video_summary --> .csv file \n",
    "\n",
    "home_video_summary = []\n",
    "home_video_summary.append({'num_total_home_videos' : hv_total_videos,\n",
    "                           'num_total_right_home_videos' : hv_total_r_videos,\n",
    "                           'num_total_left_home_videos' : hv_total_l_videos,\n",
    "                           'num_total_home_particpants' : hv_all_videos_participant_count,\n",
    "                           'first_total_home_vid_date': hv_all_videos_first_date,\n",
    "                           'last_total_home_vid_date': hv_all_videos_last_date, \n",
    "                           'total_home_vid_visits' : hv_all_unique_visits,\n",
    "                           'num_total_home_multiple_visits' : hv_multiple_visits_count, \n",
    "                           'num_total_home_single_visits': hv_single_visits_count,\n",
    "                           'num_included_home_vids' : hv_included_vids_count,\n",
    "                           'num_included_home_right_vids' : hv_included_r_count,\n",
    "                           'num_included_home_left_vids' : hv_included_l_count,\n",
    "                           'num_analyzed_home_vids' : hv_analyzed_count,\n",
    "                           'num_hv_vids_incl_lostInMerge' : hv_included_missing_after_merge, \n",
    "                           'num_analyzed_home_participants' : hv_analyzed_all_participants,\n",
    "                           'num_analyzed_home_right_participants' : hv_analyzed_r_participants, \n",
    "                           'num_analyzed_home_right_vids' : hv_analysed_r_count,\n",
    "                           'num_analyzed_home_left_participants' : hv_analyzed_l_participants,\n",
    "                           'num_analyzed_home_left_vids' : hv_analysed_l_count}\n",
    "                         )  \n",
    "\n",
    "home_video_summary_df = pd.DataFrame(home_video_summary)\n",
    "home_video_summary_df.to_csv(os.path.join(output_path, 'home_video_summary_counts.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
