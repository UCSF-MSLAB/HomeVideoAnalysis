{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c52760-b03c-42c5-afce-791fe54b7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884bd13-f08a-43c0-8e61-0fa2c9d493c8",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20cfd49-c89e-4cdd-bdd4-2a79e266c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_race_ethnicity(df): \n",
    "    df_2 = df\n",
    "    df_2['race_ethnicity_clean'] = ''\n",
    "    df_2 = df_2.copy()\n",
    "    # White race and not hispanic or latino ethnicity = White Not Hispanic \n",
    "    df_2.loc[(df_2['clean_race'] == 'White') & (df_2['clean_ethnicity'] == 'Not Hispanic Or Latino'),\n",
    "            'race_ethnicity_clean'] = 'White Not Hispanic' \n",
    "\n",
    "    # Exclude White Not Hispanic and ethnicity is Hispanic or Latino = 'Hispanic or Latino'\n",
    "    df_2.loc[(df_2['race_ethnicity_clean'] != 'White Not Hispanic') & (df_2['clean_ethnicity'] == 'Hispanic Or Latino'),\n",
    "            'race_ethnicity_clean'] = 'Hispanic or Latino'\n",
    "\n",
    "    # Of individuals that haven't been assignd race_ethnicity_clean, go off clean_race column \n",
    "    # asian \n",
    "    df_2.loc[(df_2['race_ethnicity_clean'] == '') & (df_2['clean_race'] == 'Asian'),\n",
    "            'race_ethnicity_clean'] = 'Asian' \n",
    "\n",
    "    # American Indian Or Alaska Native\n",
    "    df_2.loc[(df_2['race_ethnicity_clean'] == '') & (df_2['clean_race'] == 'American Indian Or Alaska Native'),\n",
    "            'race_ethnicity_clean'] = 'American Indian Or Alaska Native'\n",
    "    \n",
    "   # Black Or African American \n",
    "    df_2.loc[(df_2['race_ethnicity_clean'] == '') & (df_2['clean_race'] == 'Black Or African American'),\n",
    "            'race_ethnicity_clean'] = 'Black Or African American'\n",
    "\n",
    "    # Other Pacific Islander\n",
    "    df_2.loc[(df_2['race_ethnicity_clean'] == '') & (df_2['clean_race'] == 'Other Pacific Islander'),\n",
    "            'race_ethnicity_clean'] = 'Other Pacific Islander'\n",
    "\n",
    "    # if not yet assigned -> other, unknown, Declined \n",
    "    df_2.loc[df_2['race_ethnicity_clean'] == '',\n",
    "            'race_ethnicity_clean'] = 'Other/Unknown/Declined'\n",
    "    return df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2348d25d-e059-4222-91a4-4f7df178c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into healthy controls and participant swith MS \n",
    "# then select first visit date - maybe not baseline, but first visit with data in that dataset \n",
    "\n",
    "def split_MS_HC_first_visit(df): \n",
    "    df = df.copy()\n",
    "    df['visit_date'] = pd.to_datetime(df['visit_date'])\n",
    "    df['bw_id'] = df['bw_id'].str.strip()\n",
    "\n",
    "    print('total unique bw_ids in df')\n",
    "    print(df['bw_id'].nunique())\n",
    "    print('--------------') \n",
    "\n",
    "    # drop full duplicate rows \n",
    "    df = df.drop_duplicates(keep='first')\n",
    "\n",
    "    # drop dupllicated bw_id and visit_date - ex: same fw and pws \n",
    "    df = df.drop_duplicates(subset=['bw_id', 'visit_date'], keep='first')\n",
    "\n",
    "    # first visit - keep the earliest date for each ID \n",
    "    df_first_visit = (\n",
    "        df.sort_values(by=['bw_id', 'visit_date'])\n",
    "        .groupby('bw_id')\n",
    "        .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "\n",
    "    # check if any duplicates \n",
    "    duplicates = df_first_visit['bw_id'].duplicated().sum()\n",
    "    \n",
    "    print('any duplicate bw_ids in first visit df?') \n",
    "    print(duplicates)\n",
    "    print('--------------')\n",
    "\n",
    "    print('df_first_visit demographic diagnosis counts') \n",
    "    print(df_first_visit['demographic_diagnosis'].value_counts())\n",
    "    print('--------------') \n",
    "    \n",
    "    MS_1_df = df_first_visit.loc[df_first_visit['demographic_diagnosis'] == 'MS']\n",
    "    HC_1_df = df_first_visit.loc[df_first_visit['demographic_diagnosis'] == 'HC'] \n",
    "\n",
    "    print('MS and HC rows should match from table above') \n",
    "    print('rows in final MS df')\n",
    "    print(len(MS_1_df))\n",
    "    print('MS df count bw_id rows with data') \n",
    "    print(MS_1_df['bw_id'].count()) \n",
    "\n",
    "    print('rows in final HC df')\n",
    "    print(len(HC_1_df))\n",
    "    print('HC df count bw_id rows with data') \n",
    "    print(HC_1_df['bw_id'].count()) \n",
    "\n",
    "    return MS_1_df, HC_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c976b94-b8d3-41af-b76d-f689f02422b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_summary(df): \n",
    "    # summary statistics for  cohort \n",
    "    if len(df) > 0: \n",
    "        # age \n",
    "        age_count = df['demoEHR_Age'].count()\n",
    "        age_mean = df['demoEHR_Age'].mean()\n",
    "        age_sd = df['demoEHR_Age'].std()\n",
    "        \n",
    "        # sex \n",
    "        sex_count = df['clean_sex'].count()\n",
    "        sex_n = df['clean_sex'].value_counts()\n",
    "        sex_n_female = sex_n['Female']\n",
    "        sex_freqs = df['clean_sex'].value_counts(normalize=True) * 100\n",
    "        sex_freq_female = sex_freqs['Female'] \n",
    "        \n",
    "        # edss \n",
    "        edss_count = df['bingoEHR_EDSS_measure_value'].count()\n",
    "        edss_median = df['bingoEHR_EDSS_measure_value'].median()\n",
    "        edss_iqr = df['bingoEHR_EDSS_measure_value'].quantile(0.75) - df['bingoEHR_EDSS_measure_value'].quantile(0.25)\n",
    "\n",
    "        # t25fw \n",
    "        t25fw_count = df['msfcEHR_T25FW SPEED AVG'].count()\n",
    "        t25fw_mean= df['msfcEHR_T25FW SPEED AVG'].mean()\n",
    "        t25fw_sd = df['msfcEHR_T25FW SPEED AVG'].std()\n",
    "\n",
    "        #race \n",
    "        race_count = df['race_ethnicity_clean'].count()\n",
    "        race_n = df['race_ethnicity_clean'].value_counts()\n",
    "        print(race_n)\n",
    "        race_freq = df['race_ethnicity_clean'].value_counts(normalize = True) * 100\n",
    "\n",
    "        try:\n",
    "            white_n = race_n['White Not Hispanic']\n",
    "            white_freq = race_freq['White Not Hispanic']\n",
    "        except KeyError:\n",
    "            white_n = 0\n",
    "            white_freq = 0\n",
    "\n",
    "        try: \n",
    "            black_n = race_n['Black Or African American']\n",
    "            black_freq = race_freq['Black Or African American']\n",
    "        except KeyError:\n",
    "            black_n = 0\n",
    "            black_freq = 0\n",
    "        \n",
    "        try: \n",
    "            asian_n = race_n['Asian']\n",
    "            asian_freq = race_freq['Asian']\n",
    "        except KeyError:\n",
    "            asian_n = 0\n",
    "            asian_freq = 0\n",
    "\n",
    "        try: \n",
    "            ai_an_n = race_n['American Indian Or Alaska Native']\n",
    "            ai_an_freq = race_freq['American Indian Or Alaska Native']\n",
    "        except KeyError:\n",
    "            ai_an_n = 0\n",
    "            ai_an_freq = 0\n",
    "\n",
    "        try: \n",
    "            opi_n = race_n['Other Pacific Islander']\n",
    "            opi_freq = race_freq['Other Pacific Islander']\n",
    "        except KeyError:\n",
    "            opi_n = 0\n",
    "            opi_freq = 0\n",
    "             \n",
    "        try: \n",
    "            hispanic_n = race_n['Hispanic or Latino']\n",
    "            hispanic_freq = race_freq['Hispanic or Latino']\n",
    "        except KeyError: \n",
    "            hispanic_n = 0\n",
    "            hispanic_freq = 0\n",
    "\n",
    "        try: \n",
    "            decl_n = race_n['Other/Unknown/Declined']\n",
    "            decl_freq = race_freq['Other/Unknown/Declined']\n",
    "        except KeyError: \n",
    "            decl_n = 0\n",
    "            decl_freq = 0\n",
    "\n",
    "        # disease duration \n",
    "        duration_count = df['demoEHR_DiseaseDuration'].count()\n",
    "        duration_mean = df['demoEHR_DiseaseDuration'].mean()\n",
    "        duration_sd = df['demoEHR_DiseaseDuration'].std()\n",
    "\n",
    "        # MS subtype \n",
    "        #'bingoEHR_DX_MS DX'\n",
    "        ms_dx_count = df['bingoEHR_DX_MS DX'].count()\n",
    "        ms_dx_n = df['bingoEHR_DX_MS DX'].value_counts()\n",
    "        ms_dx_freq = df['bingoEHR_DX_MS DX'].value_counts(normalize = True) * 100\n",
    "\n",
    "        try:\n",
    "            rrms_n = ms_dx_n['RRMS (Relapsing-remitting Multiple Sclerosis)']\n",
    "            rrms_freq = ms_dx_freq['RRMS (Relapsing-remitting Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            rrms_n = 0\n",
    "            rrms_freq = 0\n",
    "\n",
    "        try: \n",
    "            spms_n = ms_dx_n['SPMS (Secondary-progressive Multiple Sclerosis)']\n",
    "            spms_freq = ms_dx_freq['SPMS (Secondary-progressive Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            spms_n = 0\n",
    "            spms_freq = 0\n",
    "\n",
    "        try: \n",
    "            ppms_n = ms_dx_n['PPMS (Primary-progressive Multiple Sclerosis)']\n",
    "            ppms_freq = ms_dx_freq['PPMS (Primary-progressive Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            ppms_n = 0\n",
    "            ppms_freq = 0\n",
    "\n",
    "        try: \n",
    "            prms_n = ms_dx_n['PRMS (Progressive-relapsing Multiple Sclerosis)']\n",
    "            prms_freq = ms_dx_freq['PRMS (Progressive-relapsing Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            prms_n = 0\n",
    "            prms_freq = 0 \n",
    "\n",
    "        try: \n",
    "            sns_n = ms_dx_n['MS, Subtype Not Specified']\n",
    "            sns_freq = ms_dx_freq['MS, Subtype Not Specified']\n",
    "        except KeyError:\n",
    "            sns_n = 0\n",
    "            sns_freq = 0\n",
    "\n",
    "        try: \n",
    "            pend_n = ms_dx_n['pending']\n",
    "            pend_freq = ms_dx_freq['pending']\n",
    "        except KeyError:\n",
    "            pend_n = 0\n",
    "            pend_freq = 0\n",
    "\n",
    "        try: \n",
    "            abn_n = ms_dx_n['abnormal MRI']\n",
    "            abn_freq = ms_dx_freq['abnormal MRI']\n",
    "        except KeyError:\n",
    "            abn_n = 0\n",
    "            abn_freq = 0\n",
    "\n",
    "\n",
    "        \n",
    "        # summary data \n",
    "        summary_data = {'Metric': ['N', \n",
    "                                      'Age (Years, Mean (SD))',\n",
    "                                      'Sex (Female, n (%))',\n",
    "                                      'EDSS (Median (IQR))', \n",
    "                                      'T25FW (Seconds, Mean (SD))',\n",
    "                                      'Race (n, %)',\n",
    "                                      'White Not Hispanic',\n",
    "                                      'Hispanic or Latino',\n",
    "                                      'Asian',\n",
    "                                      'Black Or African American',\n",
    "                                      'American Indian Or Alaska Native',\n",
    "                                      'Other Pacific Islander',\n",
    "                                      'Other/Unknown/Declined',\n",
    "                                      'Disease Duration (Years, Mean (SD))',\n",
    "                                      'MS Subtype (n, %)',\n",
    "                                      'RRMS (Relapsing-remitting Multiple Sclerosis)',\n",
    "                                      'SPMS (Secondary-progressive Multiple Sclerosis)',\n",
    "                                      'PPMS (Primary-progressive Multiple Sclerosis)',\n",
    "                                      'PRMS (Progressive-relapsing Multiple Sclerosis)',\n",
    "                                      'MS, Subtype Not Specified',\n",
    "                                      'pending',\n",
    "                                      'abnormal MRI'],\n",
    "                         'Statistic': [df['bw_id'].nunique(),\n",
    "                                       f\"{age_mean:.2f} ({age_sd:.2f})\",  # Mean (SD)\n",
    "                                       f\"{sex_n_female} ({sex_freq_female:.0f}%)\",\n",
    "                                       f\"{edss_median:.1f} ({edss_iqr:.1f})\", \n",
    "                                       f\"{t25fw_mean:.2f} ({t25fw_sd:.2f})\",\n",
    "                                       np.nan, \n",
    "                                       f\"{white_n} ({white_freq:.0f}%)\",\n",
    "                                       f\"{hispanic_n} ({hispanic_freq:.0f}%)\",\n",
    "                                       f\"{asian_n} ({asian_freq:.0f}%)\",\n",
    "                                       f\"{black_n} ({black_freq:.0f}%)\",\n",
    "                                       f\"{ai_an_n} ({ai_an_freq:.0f}%)\",\n",
    "                                       f\"{opi_n} ({opi_freq:.0f}%)\",\n",
    "                                       f\"{decl_n} ({decl_freq:.0f}%)\",\n",
    "                                       f\"{duration_mean:.2f} ({duration_sd:.2f})\",  # Mean (SD)\n",
    "                                       np.nan,\n",
    "                                       f\"{rrms_n} ({rrms_freq:.0f}%)\",\n",
    "                                       f\"{spms_n} ({spms_freq:.0f}%)\",\n",
    "                                       f\"{ppms_n} ({ppms_freq:.0f}%)\",\n",
    "                                       f\"{prms_n} ({prms_freq:.0f}%)\",\n",
    "                                       f\"{sns_n} ({sns_freq:.0f}%)\",\n",
    "                                       f\"{pend_n} ({pend_freq:.0f}%)\",\n",
    "                                       f\"{abn_n} ({abn_freq:.0f}%)\"]\n",
    "                       }\n",
    "\n",
    "        demographics_summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "        # counts of participants with demographic data \n",
    "        n_data = {'Metric': ['N', \n",
    "                             'n with age data',\n",
    "                             'n with sex data',\n",
    "                             'n with edss data',\n",
    "                             'n with t25fw data',\n",
    "                             'n with demoEHR_REC_2 data',\n",
    "                             'n with duration data',\n",
    "                             'n with ms subtype data'],\n",
    "                         'Statistic': [df['bw_id'].nunique(),\n",
    "                                       age_count, \n",
    "                                       sex_count, \n",
    "                                       edss_count,\n",
    "                                       t25fw_count, \n",
    "                                       race_count,\n",
    "                                       duration_count,\n",
    "                                       ms_dx_count\n",
    "                                       ]}\n",
    "\n",
    "        n_data_df = pd.DataFrame(n_data) \n",
    "\n",
    "    else: \n",
    "        print('no participants') \n",
    "        demographics_summary_df = pd.DataFrame()\n",
    "        n_data_df = pd.DataFrame()\n",
    "\n",
    "    return demographics_summary_df, n_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd2426-14a5-4f90-a4ab-daed275e01b2",
   "metadata": {},
   "source": [
    "# file paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40890f60-e304-4dab-a05e-7ccfea122583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs \n",
    "version = '004'\n",
    "output_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis',\n",
    "                           version,\n",
    "                           'demographics')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aaa3544-807f-44fa-86d5-2cca8e81a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mmccu\\\\Box\\\\MM_Personal\\\\5_Projects\\\\BoveLab\\\\3_Data_and_Code\\\\gait_bw_zeno_home_analysis\\\\004'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input folder \n",
    "input_parent_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                                 version) \n",
    "input_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6accd6b3-ab66-43f3-8698-03b4eebe76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeno videos \n",
    "all_zv_w_bw_path = os.path.join(input_parent_path, \n",
    "                                'video_visit_participant_counts',\n",
    "                                'all_zv_videos_merged_w_bw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88b722d-ad0d-4f17-a6b9-59c7ccb4ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeno included PWS \n",
    "zv_pws_inclu_w_bw_path = os.path.join(input_parent_path, \n",
    "                                      'zv_bw_merged_gait_vertical_PWS_1.csv') \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75919d1-befb-4b96-9ba0-9dde550716b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeno included FW \n",
    "zv_fw_inclu_w_bw_path = os.path.join(input_parent_path, \n",
    "                                      'zv_bw_merged_gait_vertical_FW_1.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db511a8a-7e8c-4b9c-a168-826ee6135155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all bw participants with ms - maybe not using?? \n",
    "# tbd if not all partiicpants approached for home videos \n",
    "bw_path = r'C:\\Users\\mmccu\\AppData\\Local\\Temp\\ccsecure\\2025_01_24_BrainWalk_AllData_Long_MM.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2742d0-f941-4da9-9e2f-0384dd487ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all participants who sent home videos \n",
    "all_hv_path = os.path.join(input_parent_path, \n",
    "                           'home_feasibility_reliability\\home_vids_all_w_bw.csv') \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c932990-33b9-4a30-9c66-d15c24c46f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos included in analysis \n",
    "included_hv_w_bw_path = os.path.join(input_parent_path, 'hv_bw_merged.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0743bbf2-794d-49b4-a6b1-19a0aadb7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants consented to home vids\n",
    "    # need to save (either feas or counting step) - pick which one aligns col names the best \n",
    "redcap_reports_path = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\home_video_feasibility\\2025_01_08 RedCap Reports'\n",
    "consent_base_v1_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_baseline_consent_v1.csv') \n",
    "consent_base_v2_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_baseline_consent_v2.csv') \n",
    "consent_y2_v1_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_year2_consent_v1.csv') \n",
    "consent_y2_v2_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_year2_consent_v2.csv') \n",
    "consent_y3_v1_path = os.path.join(redcap_reports_path,\n",
    "                                  'homevid_year3_consent_v1.csv') \n",
    "consent_y3_v2_path = os.path.join(redcap_reports_path,\n",
    "                                  'homevid_year3_consent_v2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd3d5410-3fed-4d26-b152-28ee654c0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants consented to home vids - format and merge dataframes \n",
    "consent_base_v1_df = pd.read_csv(consent_base_v1_path) \n",
    "consent_base_v2_df = pd.read_csv(consent_base_v2_path)\n",
    "consent_y2_v1_df = pd.read_csv(consent_y2_v1_path)\n",
    "consent_y2_v2_df = pd.read_csv(consent_y2_v2_path)\n",
    "consent_y3_v1_df = pd.read_csv(consent_y3_v1_path)\n",
    "consent_y3_v2_df = pd.read_csv(consent_y3_v2_path) \n",
    "\n",
    "# add consent version column \n",
    "consent_base_v1_df['consent_version'] = 1\n",
    "consent_y2_v1_df['consent_version'] = 1\n",
    "consent_y3_v1_df['consent_version'] = 1\n",
    "\n",
    "consent_base_v2_df['consent_version'] = 2\n",
    "consent_y2_v2_df['consent_version'] = 2\n",
    "consent_y3_v2_df['consent_version']= 2\n",
    "\n",
    "# rename all columns to v1 col names \n",
    "#record_id\tredcap_event_name\tbw_id\tfalls_visit_date\twalking_consent_date\twalking_consent_sig\n",
    "consent_base_v1_df = consent_base_v1_df.rename(columns = {'falls_visit_date' : 'visit_date'}) \n",
    "consent_y2_v1_df = consent_y2_v1_df.rename(columns = {'falls_visit_date' : 'visit_date'})\n",
    "consent_y3_v1_df = consent_y3_v1_df.rename(columns = {'falls_visit_date' : 'visit_date'})\n",
    "\n",
    "\n",
    "consent_base_v2_df = consent_base_v2_df.rename(columns = {'falls_visit_date' : 'visit_date',\n",
    "                                                          'walking_consent_date_v2' : 'walking_consent_date',\n",
    "                                                          'walking_consent_sig_v2' : 'walking_consent_sig'}) \n",
    "consent_y2_v2_df = consent_y2_v2_df.rename(columns = {'falls_visit_date' : 'visit_date',\n",
    "                                                      'walking_consent_date_v2' : 'walking_consent_date',\n",
    "                                                      'walking_consent_sig_v2' : 'walking_consent_sig'}) \n",
    "consent_y3_v2_df = consent_y3_v2_df.rename(columns = {'falls_visit_date' : 'visit_date',\n",
    "                                                      'walking_consent_date_v2' : 'walking_consent_date',\n",
    "                                                      'walking_consent_sig_v2' : 'walking_consent_sig'})\n",
    "\n",
    "# convert to date time \n",
    "consent_base_v1_df['visit_date'] = pd.to_datetime(consent_base_v1_df['visit_date'], errors = 'coerce')\n",
    "consent_y2_v1_df['visit_date'] = pd.to_datetime(consent_y2_v1_df['visit_date'], errors = 'coerce')\n",
    "consent_y3_v1_df['visit_date'] = pd.to_datetime(consent_y3_v1_df['visit_date'], errors = 'coerce')\n",
    "consent_base_v2_df['visit_date'] = pd.to_datetime(consent_base_v2_df['visit_date'], errors = 'coerce')\n",
    "consent_y2_v2_df['visit_date'] = pd.to_datetime(consent_y2_v2_df['visit_date'], errors = 'coerce')\n",
    "consent_y3_v2_df['visit_date'] = pd.to_datetime(consent_y3_v2_df['visit_date'], errors = 'coerce')\n",
    "\n",
    "# concatenate \n",
    "consent_all_df = pd.concat([consent_base_v1_df,\n",
    "                            consent_base_v2_df,\n",
    "                            consent_y2_v1_df,\n",
    "                            consent_y2_v2_df,\n",
    "                            consent_y3_v1_df,\n",
    "                            consent_y3_v2_df])\n",
    "\n",
    "#consent_all_df['visit_date'] = pd.to_datetime(consent_all_df['visit_date'], errors = 'coerce')\n",
    "consent_all_df.to_csv(os.path.join(redcap_reports_path, 'all_home_vid_consent.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f88db-4f77-47db-af67-d7903a45c1b3",
   "metadata": {},
   "source": [
    "# run function on datasets below \n",
    "\n",
    "Save sumamry table - pulling demographic data from first brainwalk visit if participant has multiple visits\n",
    "\n",
    "Zeno \n",
    "1. All participants with videos: MS + HC\n",
    "2. All participants with included videos: MS + HC\n",
    "3. Participants with included PWS videos: MS + HC – is there a diff between groups?\n",
    "4. Participants with included FW videos: MS + HC – is there a diff between groups?\n",
    "\n",
    "Home Videos \n",
    "1. all BW participants with MS (TBD, maybe not all approached) \n",
    "2. All BW participants consented to home vids\n",
    "3. All BW participants who sent home vids\n",
    "4. All BW participants who sent usable/included home vids  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccbab2-2f71-4379-bc33-df86fbc10bae",
   "metadata": {},
   "source": [
    "### Zeno videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740215db-0b09-4260-ad44-ce5604234e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "215\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    174\n",
      "HC     41\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "174\n",
      "MS df count bw_id rows with data\n",
      "174\n",
      "rows in final HC df\n",
      "41\n",
      "HC df count bw_id rows with data\n",
      "41\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  116\n",
      "Hispanic or Latino                   17\n",
      "Asian                                14\n",
      "Black Or African American            12\n",
      "Other/Unknown/Declined               12\n",
      "American Indian Or Alaska Native      2\n",
      "Other Pacific Islander                1\n",
      "Name: count, dtype: int64\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic        22\n",
      "Asian                     10\n",
      "Other/Unknown/Declined     6\n",
      "Hispanic or Latino         3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# all zeno videos \n",
    "all_zv_w_bw_df = pd.read_csv(all_zv_w_bw_path, index_col = 0) \n",
    "all_zv_w_bw_df = merge_race_ethnicity(all_zv_w_bw_df)\n",
    "\n",
    "all_zv_ms_df, all_zv_hc_df = split_MS_HC_first_visit(all_zv_w_bw_df)\n",
    "\n",
    "all_zv_ms_dem, all_zv_ms_n = demographic_summary(all_zv_ms_df)\n",
    "all_zv_hc_dem, all_zv_hc_n = demographic_summary(all_zv_hc_df)\n",
    "\n",
    "# save outputs \n",
    "all_zv_ms_dem.to_csv(os.path.join(output_path, 'zeno_all_vids_ms_demographics.csv')) \n",
    "all_zv_hc_dem.to_csv(os.path.join(output_path, 'zeno_all_vids_hc_demographics.csv')) \n",
    "\n",
    "all_zv_ms_n.to_csv(os.path.join(output_path, 'zeno_all_vids_ms_counts.csv')) \n",
    "all_zv_hc_n.to_csv(os.path.join(output_path, 'zeno_all_vids_hc_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a4a0801-f8de-48c2-acf2-f4e9b302fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "179\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    146\n",
      "HC     33\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "146\n",
      "MS df count bw_id rows with data\n",
      "146\n",
      "rows in final HC df\n",
      "33\n",
      "HC df count bw_id rows with data\n",
      "33\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  99\n",
      "Hispanic or Latino                  14\n",
      "Asian                               11\n",
      "Black Or African American           10\n",
      "Other/Unknown/Declined               9\n",
      "American Indian Or Alaska Native     2\n",
      "Other Pacific Islander               1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_ethnicity_clean\n",
      "White Not Hispanic        18\n",
      "Asian                      9\n",
      "Other/Unknown/Declined     5\n",
      "Hispanic or Latino         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# all zeno included PWS \n",
    "zv_pws_inclu_w_bw_df = pd.read_csv(zv_pws_inclu_w_bw_path, index_col = 0)\n",
    "zv_pws_inclu_w_bw_df = merge_race_ethnicity(zv_pws_inclu_w_bw_df) \n",
    "\n",
    "# rename columns to align with functions above \n",
    "zv_pws_inclu_w_bw_df = zv_pws_inclu_w_bw_df.rename(columns = {'visit_date_video' : 'video_date'}) \n",
    "\n",
    "# demographics summary \n",
    "zv_pws_inclu_ms_df, zv_pws_inclu_hc_df = split_MS_HC_first_visit(zv_pws_inclu_w_bw_df)\n",
    "\n",
    "zv_pws_inclu_ms_dem, zv_pws_inclu_ms_n = demographic_summary(zv_pws_inclu_ms_df)\n",
    "zv_pws_inclu_hc_dem,  zv_pws_inclu_hc_n = demographic_summary(zv_pws_inclu_hc_df)\n",
    "\n",
    "# save outputs \n",
    "zv_pws_inclu_ms_dem.to_csv(os.path.join(output_path, 'zeno_pws_inclu_ms_demographics.csv')) \n",
    "zv_pws_inclu_hc_dem.to_csv(os.path.join(output_path, 'zeno_pws_inclu_hc_demographics.csv')) \n",
    "\n",
    "zv_pws_inclu_ms_n.to_csv(os.path.join(output_path, 'zeno_pws_inclu_ms_counts.csv')) \n",
    "zv_pws_inclu_hc_n.to_csv(os.path.join(output_path, 'zeno_pws_inclu_hc_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d381ae-b7c6-4cc5-ad76-4fc2b469e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "177\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    142\n",
      "HC     35\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "142\n",
      "MS df count bw_id rows with data\n",
      "142\n",
      "rows in final HC df\n",
      "35\n",
      "HC df count bw_id rows with data\n",
      "35\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  94\n",
      "Hispanic or Latino                  13\n",
      "Asian                               12\n",
      "Black Or African American           10\n",
      "Other/Unknown/Declined              10\n",
      "American Indian Or Alaska Native     2\n",
      "Other Pacific Islander               1\n",
      "Name: count, dtype: int64\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic        20\n",
      "Asian                      9\n",
      "Other/Unknown/Declined     5\n",
      "Hispanic or Latino         1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# all Zeno included FW \n",
    "zv_fw_inclu_w_bw_df = pd.read_csv(zv_fw_inclu_w_bw_path, index_col = 0)\n",
    "zv_fw_inclu_w_bw_df = merge_race_ethnicity(zv_fw_inclu_w_bw_df) \n",
    "\n",
    "# rename columns to align with functions above \n",
    "zv_fw_inclu_w_bw_df = zv_fw_inclu_w_bw_df.rename(columns = {'visit_date_video' : 'video_date'}) \n",
    "\n",
    "# demographics summary \n",
    "zv_fw_inclu_ms_df, zv_fw_inclu_hc_df = split_MS_HC_first_visit(zv_fw_inclu_w_bw_df)\n",
    "\n",
    "zv_fw_inclu_ms_dem, zv_fw_inclu_ms_n = demographic_summary(zv_fw_inclu_ms_df)\n",
    "zv_fw_inclu_hc_dem, zv_fw_inclu_hc_n = demographic_summary(zv_fw_inclu_hc_df)\n",
    "\n",
    "# save outputs\n",
    "zv_fw_inclu_ms_dem.to_csv(os.path.join(output_path, 'zeno_fw_inclu_ms_demographics.csv')) \n",
    "zv_fw_inclu_hc_dem.to_csv(os.path.join(output_path, 'zeno_fw_inclu_hc_demographics.csv'))\n",
    "\n",
    "zv_fw_inclu_ms_n.to_csv(os.path.join(output_path, 'zeno_fw_inclu_ms_counts.csv')) \n",
    "zv_fw_inclu_hc_n.to_csv(os.path.join(output_path, 'zeno_fw_inclu_hc_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82a12b1-25e7-4481-94a5-ea368fa653d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "193\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    156\n",
      "HC     37\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "156\n",
      "MS df count bw_id rows with data\n",
      "156\n",
      "rows in final HC df\n",
      "37\n",
      "HC df count bw_id rows with data\n",
      "37\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  106\n",
      "Hispanic or Latino                   14\n",
      "Asian                                13\n",
      "Black Or African American            10\n",
      "Other/Unknown/Declined               10\n",
      "American Indian Or Alaska Native      2\n",
      "Other Pacific Islander                1\n",
      "Name: count, dtype: int64\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic        21\n",
      "Asian                     10\n",
      "Other/Unknown/Declined     5\n",
      "Hispanic or Latino         1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# All participant's included Zeno - merge Zeno FW and PWs \n",
    "zv_all_includ_w_bw_df = pd.concat([zv_pws_inclu_w_bw_df, zv_fw_inclu_w_bw_df])\n",
    "zv_all_includ_w_bw_df = zv_all_includ_w_bw_df.drop_duplicates(keep = 'first')\n",
    "zv_all_includ_w_bw_df = merge_race_ethnicity(zv_all_includ_w_bw_df) \n",
    "                                                                 \n",
    "# demographics summary \n",
    "zv_all_inclu_ms_df, zv_all_inclu_hc_df = split_MS_HC_first_visit(zv_all_includ_w_bw_df)\n",
    "\n",
    "# demographics\n",
    "zv_all_inclu_ms_dem, zv_all_inclu_ms_n = demographic_summary(zv_all_inclu_ms_df)\n",
    "zv_all_inclu_hc_dem, zv_all_inclu_hc_n = demographic_summary(zv_all_inclu_hc_df)\n",
    "\n",
    "# save outputs \n",
    "zv_all_inclu_ms_dem.to_csv(os.path.join(output_path, 'zeno_all_inclu_ms_demographics.csv')) \n",
    "zv_all_inclu_hc_dem.to_csv(os.path.join(output_path, 'zeno_all_inclu_hc_demographics.csv'))\n",
    "\n",
    "zv_all_inclu_ms_n.to_csv(os.path.join(output_path, 'zeno_all_inclu_ms_counts.csv')) \n",
    "zv_all_inclu_hc_n.to_csv(os.path.join(output_path, 'zeno_all_inclu_hc_counts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd479a2-8d18-4195-b582-267ba7140f90",
   "metadata": {},
   "source": [
    "### Home Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b996ac54-b12c-4d0f-9b5e-d834fbc3013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_24244\\2588094127.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['race_ethnicity_clean'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "184\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    184\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "184\n",
      "MS df count bw_id rows with data\n",
      "184\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  122\n",
      "Hispanic or Latino                   19\n",
      "Asian                                14\n",
      "Other/Unknown/Declined               14\n",
      "Black Or African American            12\n",
      "American Indian Or Alaska Native      2\n",
      "Other Pacific Islander                1\n",
      "Name: count, dtype: int64\n",
      "no participants\n"
     ]
    }
   ],
   "source": [
    "# all bw participants with ms - maybe not using?? \n",
    "# tbd if not all partiicpants approached for home videos \n",
    "bw_df = pd.read_excel(bw_path, \n",
    "                     index_col = None, \n",
    "                     usecols = ['bw_id', 'record_id', 'trialdate', 'visit_date', 'demoEHR_DiseaseDuration',\n",
    "                                'clean_sex', 'demoEHR_Age', 'demographic_diagnosis', 'bingoEHR_DX_MS DX', 'clean_race',\t\n",
    "                                'clean_ethnicity', 'bingoEHR_EDSS_measure_value', 'msfcEHR_T25FW SPEED AVG']) \n",
    "\n",
    "# only ms participants have sent back videos \n",
    "bw_ms_df = bw_df.loc[bw_df['demographic_diagnosis'] == 'MS']\n",
    "bw_ms_df = merge_race_ethnicity(bw_ms_df) \n",
    "\n",
    "# demographics summary \n",
    "all_bw_ms_df, all_bw_hc_df = split_MS_HC_first_visit(bw_ms_df)\n",
    "\n",
    "all_bw_ms_dem, all_bw_ms_n = demographic_summary(all_bw_ms_df)\n",
    "all_bw_hc_dem, all_bw_hc_n = demographic_summary(all_bw_hc_df)\n",
    "\n",
    "all_bw_ms_dem.to_csv(os.path.join(output_path, 'home_all_bw_ms_demographics.csv')) \n",
    "all_bw_ms_n.to_csv(os.path.join(output_path, 'home_all_bw_ms_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d455004-a033-4970-8bc1-f5c6199bc032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "66\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    66\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "66\n",
      "MS df count bw_id rows with data\n",
      "66\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  42\n",
      "Other/Unknown/Declined               8\n",
      "Asian                                6\n",
      "Hispanic or Latino                   5\n",
      "Black Or African American            3\n",
      "Other Pacific Islander               1\n",
      "American Indian Or Alaska Native     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# participants consented to home videos \n",
    "# merge w bw data \n",
    "consent_all_w_bw_df = consent_all_df.merge(right = bw_df, how = 'left', on = ['bw_id', 'visit_date'])\n",
    "# one mild TBI? \n",
    "consent_all_w_bw_df = consent_all_w_bw_df.loc[consent_all_w_bw_df['demographic_diagnosis'] == 'MS']\n",
    "# two with signed home walking, but no BW ID or demographics \n",
    "consent_all_w_bw_df.dropna(subset=['bw_id'], inplace=True)\n",
    "consent_all_w_bw_df = consent_all_w_bw_df.sort_values(by='bw_id')\n",
    "consent_all_w_bw_df.to_csv(os.path.join(redcap_reports_path, 'all_home_vid_ms_consent_w_bw.csv'))\n",
    "\n",
    "consent_all_w_bw_df = merge_race_ethnicity(consent_all_w_bw_df)\n",
    "# demographics summary \n",
    "consent_all_ms_df, consent_all_hc_df = split_MS_HC_first_visit(consent_all_w_bw_df)\n",
    "consent_all_ms_dem, consent_all_ms_n = demographic_summary(consent_all_ms_df)\n",
    "\n",
    "consent_all_ms_dem.to_csv(os.path.join(output_path, 'home_consented_ms_demographics.csv'))\n",
    "consent_all_ms_n.to_csv(os.path.join(output_path, 'home_consented_ms_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a45735e-57db-4a3b-bcb1-9c6624ac47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_24244\\2588094127.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['race_ethnicity_clean'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "118\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    118\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "118\n",
      "MS df count bw_id rows with data\n",
      "118\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  80\n",
      "Hispanic or Latino                  14\n",
      "Black Or African American            9\n",
      "Asian                                8\n",
      "Other/Unknown/Declined               6\n",
      "American Indian Or Alaska Native     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# participants that did not consent to home videos \n",
    "hv_no_consent_w_bw_df = bw_ms_df.loc[~bw_ms_df['bw_id'].isin(consent_all_w_bw_df['bw_id'])]\n",
    "hv_no_consent_w_bw_df = merge_race_ethnicity(hv_no_consent_w_bw_df)\n",
    "\n",
    "hv_no_consent_ms_df, hv_no_consent_hc_df = split_MS_HC_first_visit(hv_no_consent_w_bw_df)\n",
    "hv_no_consent_ms_dem, hv_no_consent_ms_n = demographic_summary(hv_no_consent_ms_df)\n",
    "\n",
    "hv_no_consent_ms_dem.to_csv(os.path.join(output_path, 'home_no_consent_ms_demographics.csv'))\n",
    "hv_no_consent_ms_n.to_csv(os.path.join(output_path, 'home_no_consent_ms_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ced32ee-64c6-42d0-8492-e412e5bc24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "35\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    35\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "35\n",
      "MS df count bw_id rows with data\n",
      "35\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic           26\n",
      "Other/Unknown/Declined        3\n",
      "Asian                         3\n",
      "Other Pacific Islander        1\n",
      "Hispanic or Latino            1\n",
      "Black Or African American     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# all participants who sent home videos \n",
    "hv_all_vids_df = pd.read_csv(all_hv_path, index_col = 0) \n",
    "hv_all_vids_df = merge_race_ethnicity(hv_all_vids_df)\n",
    "\n",
    "# demographics summary \n",
    "hv_all_vids_ms_df, hv_all_vids_hc_df = split_MS_HC_first_visit(hv_all_vids_df)\n",
    "hv_all_vids_ms_dem, hv_all_vids_ms_n  = demographic_summary(hv_all_vids_ms_df)\n",
    "\n",
    "hv_all_vids_ms_dem.to_csv(os.path.join(output_path, 'home_all_vids_ms_demographics.csv')) \n",
    "hv_all_vids_ms_n.to_csv(os.path.join(output_path, 'home_all_vids_ms_counts.csv')) \n",
    "\n",
    "## ISSUE - some participants who sent videos are not included on RedCap consent reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0d0b00f-3a33-4ff6-869e-b0e97bab61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_24244\\2588094127.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['race_ethnicity_clean'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "35\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    35\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "35\n",
      "MS df count bw_id rows with data\n",
      "35\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic                  20\n",
      "Other/Unknown/Declined               5\n",
      "Hispanic or Latino                   4\n",
      "Asian                                3\n",
      "Black Or African American            2\n",
      "American Indian Or Alaska Native     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# participants that consented but did not send videos \n",
    "#ids in consent_all not in  hv_all_vids_df\n",
    "hv_no_vids_sent_df = consent_all_ms_df.loc[~consent_all_ms_df['bw_id'].isin(hv_all_vids_df['bw_id'])]\n",
    "hv_no_vids_sent_df = merge_race_ethnicity(hv_no_vids_sent_df)\n",
    "\n",
    "# demographics summary \n",
    "hv_no_vids_sent_ms_df, hv_no_vids_sent_hc_df = split_MS_HC_first_visit(hv_no_vids_sent_df)\n",
    "hv_no_vids_sent_ms_dem, hv_no_vids_sent_ms_n  = demographic_summary(hv_no_vids_sent_ms_df)\n",
    "\n",
    "hv_no_vids_sent_ms_dem.to_csv(os.path.join(output_path, 'home_no_vids_ms_demographics.csv')) \n",
    "hv_no_vids_sent_ms_n.to_csv(os.path.join(output_path, 'home_no_vids_ms_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "716639b3-743b-4725-b3f0-e622fccff048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "27\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    27\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "27\n",
      "MS df count bw_id rows with data\n",
      "27\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic        20\n",
      "Other/Unknown/Declined     3\n",
      "Asian                      2\n",
      "Other Pacific Islander     1\n",
      "Hispanic or Latino         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# videos included in analysis \n",
    "hv_all_inclu_w_bw_df = pd.read_csv(included_hv_w_bw_path, index_col = 0) \n",
    "hv_all_inclu_w_bw_df = merge_race_ethnicity(hv_all_inclu_w_bw_df)\n",
    "\n",
    "# demographics summary \n",
    "hv_all_inclu_ms_df, hv_all_inclu_hc_df = split_MS_HC_first_visit(hv_all_inclu_w_bw_df)\n",
    "hv_all_inclu_ms_dem, hv_all_inclu_ms_n = demographic_summary(hv_all_inclu_ms_df)\n",
    "\n",
    "hv_all_inclu_ms_dem.to_csv(os.path.join(output_path, 'home_all_inclu_ms_demographics.csv')) \n",
    "hv_all_inclu_ms_n.to_csv(os.path.join(output_path, 'home_all_inclu_ms_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8dc9e49-736a-4b5e-a4dc-5d585085e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\AppData\\Local\\Temp\\ipykernel_24244\\2588094127.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['race_ethnicity_clean'] = ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "8\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    8\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "8\n",
      "MS df count bw_id rows with data\n",
      "8\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "race_ethnicity_clean\n",
      "White Not Hispanic           6\n",
      "Asian                        1\n",
      "Black Or African American    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# participants that sent videos but none were included in analysis \n",
    "#ids in hv_all_vids_df not in  hv_all_inclu_w_bw_df\n",
    "hv_excluded_vids_df = hv_all_vids_df.loc[~hv_all_vids_df['bw_id'].isin(hv_all_inclu_w_bw_df['bw_id'])]\n",
    "hv_excluded_vids_df = merge_race_ethnicity(hv_excluded_vids_df)\n",
    "\n",
    "# demographics summary \n",
    "hv_excluded_vids_ms_df, hv_excluded_vids_hc_df = split_MS_HC_first_visit(hv_excluded_vids_df)\n",
    "hv_excluded_vids_ms_dem, hv_excluded_vids_ms_n = demographic_summary(hv_excluded_vids_ms_df)\n",
    "\n",
    "hv_excluded_vids_ms_dem.to_csv(os.path.join(output_path, 'home_all_exclu_ms_demographics.csv')) \n",
    "hv_excluded_vids_ms_n.to_csv(os.path.join(output_path, 'home_all_exclu_ms_counts.csv')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
