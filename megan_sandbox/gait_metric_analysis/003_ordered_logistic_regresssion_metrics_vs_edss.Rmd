---
title: "Ordered Logistic Regression"
author: "Megan"
date: "2025-03-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# to do and questions 
- Fix OR confidence interval 


- EDSS + T25FW: sensitivity analysis - dateDiff from video walking +- 90 days, +- 30 days 

- Improve metric - re-run delta pixel eye to foot?

- EDSS Ordinal regression
  - used EDSS severity for consistency- same cutoff groups for all models and bigger n per group
  - not sure if edss score better 
  
-Take out progressive MS as predictor? assumed progressive higher EDSS?

- cleanre way to do faceted plot with multiple predictors? - messy when I tried earlier 
  
- standardize y limits for probability plots 

```{r}

library(readxl)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(foreign)
library(MASS)
library(Hmisc)
library(reshape2)
```





# Set directories and load data 
## output directory 
```{r}
# analysis folder 
analysis_version <- '005'

```

```{r}
output_dir <- file.path("C:/Users/mmccu/Box/MM_Personal/5_Projects/BoveLab/3_Data_and_Code/gait_bw_zeno_home_analysis",
                        analysis_version, 
                        "003_ordered_logistic_regression_edss")

# create output folder if it doesn't already exist 
if (file.exists(output_dir) == FALSE){
  dir.create(output_dir)
}
```

## Load and format PWS data   
All videos included in analysis. 

Each row = 1 video 

```{r}
# Preferred Walking Speed 
zeno_pws_path <- file.path("C:/Users/mmccu/Box/MM_Personal/5_Projects/BoveLab/3_Data_and_Code/gait_bw_zeno_home_analysis", 
                           analysis_version, 
                           "000_merged_cleaned_data",
                           "zv_bw_merged_gait_vertical_PWS_1_clean.csv")
zeno_pws_df <- read.csv(zeno_pws_path)
table(zeno_pws_df$task_pose)
```

### Factor categorical vars 
```{r}
str(zeno_pws_df)
zeno_pws_df <- zeno_pws_df %>% 
  mutate_at(c("video_id_date_name_pose_zv", "id_date_pose_zv", "task_pose_zv", 
              "id_video", "bw_id", "clean_sex", "bingoEHR_DX_MS.DX", 
              "demographic_diagnosis", "race_ethnicity_clean", 
              "race_ethnicity_clean", "ms_dx_condensed",
              "redcap_event_name", "bingoEHR_EDSS_measure_value"), 
            as.factor)
str(zeno_pws_df)


# assign levels to categorical variables 
table(zeno_pws_df$race_ethnicity_clean)
zeno_pws_df$race_ethnicity_clean <- factor(zeno_pws_df$race_ethnicity_clean, 
                                           levels = c('White Not Hispanic', 
                                                      'Asian', 
                                                      'Black Or African American',
                                                      'Hispanic or Latino',
                                                      'Other/Unknown/Declined'), 
                                           ordered = FALSE)
print(levels(zeno_pws_df$race_ethnicity_clean))

table(zeno_pws_df$ms_dx_condensed)
zeno_pws_df$ms_dx_condensed <- factor(zeno_pws_df$ms_dx_condensed, 
                                      levels = c('RRMS', 
                                                 'Progressive MS',
                                                 'MS, Subtype Not Specified'), 
                                      ordered = FALSE)
print(levels(zeno_pws_df$ms_dx_condensed))

table(zeno_pws_df$clean_sex)
zeno_pws_df$clean_sex <- factor(zeno_pws_df$clean_sex, 
                                levels = c('Female', 
                                           'Male',
                                           'Non-Binary'), 
                                ordered = FALSE)
print(levels(zeno_pws_df$clean_sex))

table(zeno_pws_df$edss_severity_cat)
zeno_pws_df$edss_severity_cat <- factor(zeno_pws_df$edss_severity_cat, 
                                        levels = c('mild', 
                                                   'moderate',
                                                   'severe'), 
                                        ordered = TRUE)
print(levels(zeno_pws_df$edss_severity_cat))
print(table(zeno_pws_df$edss_severity_cat))
```

### Merge small categorical groups 

```{r}
#MS DX 
print(levels(zeno_pws_df$ms_dx_condensed))
zeno_pws_df <- zeno_pws_df %>% 
  mutate(ms_dx_condensed_2 = if_else(ms_dx_condensed == "Progressive MS", 
                                     "Progressive MS", 
                                     "RRMS or Not Specified"))

zeno_pws_df$ms_dx_condensed_2 <- factor(zeno_pws_df$ms_dx_condensed_2, 
                                        levels = c("RRMS or Not Specified", 
                                                   "Progressive MS"), 
                                        ordered = FALSE)


table(zeno_pws_df$ms_dx_condensed_2)
print(str(zeno_pws_df$ms_dx_condensed_2))

# race_ethnicity 
print(table(zeno_pws_df$race_ethnicity_clean))
zeno_pws_df <- zeno_pws_df %>% 
  mutate(race_ethnicity_clean_2 = if_else(zeno_pws_df$race_ethnicity_clean %in% c("Asian", "Black Or African American"), 
                                          "Asian or Black or African American",
                                          zeno_pws_df$race_ethnicity_clean))

print(table(zeno_pws_df$race_ethnicity_clean_2))
zeno_pws_df$race_ethnicity_clean_2 <- factor(zeno_pws_df$race_ethnicity_clean_2, 
                                           levels = c('White Not Hispanic', 
                                                      'Asian or Black or African American', 
                                                      'Hispanic or Latino',
                                                      'Other/Unknown/Declined'), 
                                           ordered = FALSE)
print(levels(zeno_pws_df$race_ethnicity_clean_2))

table(zeno_pws_df$race_ethnicity_clean_2)

# clean_sex 
print(table(zeno_pws_df$clean_sex))
zeno_pws_df <- zeno_pws_df %>% 
  mutate(clean_sex_2 = if_else(clean_sex == "Female", 
                                     "Female", 
                                     "Male or Non-Binary"))

zeno_pws_df$clean_sex_2 <- factor(zeno_pws_df$clean_sex_2, 
                                        levels = c("Female", 
                                                   "Male or Non-Binary"), 
                                        ordered = FALSE)


table(zeno_pws_df$clean_sex_2)
print(str(zeno_pws_df$clean_sex_2))
```

### missing variables in each column 
```{r}
colSums(is.na(zeno_pws_df))
```

### Visit types 
```{r}
table(zeno_pws_df$redcap_event_name)
```
## Load and format FW data   
All videos included in analysis. 

Each row = 1 video 
```{r}
zeno_fw_path <- file.path("C:/Users/mmccu/Box/MM_Personal/5_Projects/BoveLab/3_Data_and_Code/gait_bw_zeno_home_analysis", 
                          analysis_version, 
                          "000_merged_cleaned_data", 
                          "zv_bw_merged_gait_vertical_FW_1_clean.csv")
zeno_fw_df <- read.csv(zeno_fw_path)
table(zeno_fw_df$task_pose)
```

### Factor categorical vars 
```{r}
str(zeno_fw_df)
zeno_fw_df <- zeno_fw_df %>% 
  mutate_at(c("video_id_date_name_pose_zv", "id_date_pose_zv", "task_pose_zv", 
              "id_video", "bw_id", "clean_sex", "bingoEHR_DX_MS.DX", 
              "demographic_diagnosis", "race_ethnicity_clean", 
              "race_ethnicity_clean", "ms_dx_condensed",
              "redcap_event_name", "bingoEHR_EDSS_measure_value"), 
            as.factor)
str(zeno_fw_df)


# assign levels to categorical variables 
table(zeno_fw_df$race_ethnicity_clean)

zeno_fw_df$race_ethnicity_clean <- factor(zeno_fw_df$race_ethnicity_clean, 
                                          levels = c('White Not Hispanic', 
                                                     'Asian', 
                                                     'Black Or African American',
                                                     'Hispanic or Latino',
                                                     'Other/Unknown/Declined'), 
                                          ordered = FALSE)
print(levels(zeno_fw_df$race_ethnicity_clean))

table(zeno_fw_df$ms_dx_condensed)
zeno_fw_df$ms_dx_condensed <- factor(zeno_fw_df$ms_dx_condensed, 
                                     levels = c('RRMS', 
                                                'Progressive MS',
                                                'MS, Subtype Not Specified'), 
                                     ordered = FALSE)
print(levels(zeno_fw_df$ms_dx_condensed))

table(zeno_fw_df$clean_sex)
zeno_fw_df$clean_sex <- factor(zeno_fw_df$clean_sex, 
                               levels = c('Female', 
                                          'Male',
                                          'Non-Binary'), 
                               ordered = FALSE)
print(levels(zeno_fw_df$clean_sex))

table(zeno_fw_df$edss_severity_cat)
zeno_fw_df$edss_severity_cat <- factor(zeno_fw_df$edss_severity_cat, 
                                levels = c('mild', 
                                           'moderate',
                                           'severe'), 
                                ordered = TRUE)
print(levels(zeno_fw_df$edss_severity_cat))
```

### Merge small categorical groups 

```{r}
#MS DX 
print(levels(zeno_fw_df$ms_dx_condensed))
zeno_fw_df <- zeno_fw_df %>% 
  mutate(ms_dx_condensed_2 = if_else(ms_dx_condensed == "Progressive MS", 
                                     "Progressive MS", 
                                     "RRMS or Not Specified"))

zeno_fw_df$ms_dx_condensed_2 <- factor(zeno_fw_df$ms_dx_condensed_2, 
                                        levels = c("RRMS or Not Specified", 
                                                   "Progressive MS"), 
                                        ordered = FALSE)


table(zeno_fw_df$ms_dx_condensed_2)
print(str(zeno_fw_df$ms_dx_condensed_2))

# race_ethnicity 
print(table(zeno_fw_df$race_ethnicity_clean))
zeno_fw_df <- zeno_fw_df %>% 
  mutate(race_ethnicity_clean_2 = if_else(zeno_fw_df$race_ethnicity_clean %in% c("Asian", "Black Or African American"), 
                                          "Asian or Black or African American",
                                          zeno_fw_df$race_ethnicity_clean))
print(table(zeno_fw_df$race_ethnicity_clean_2))
zeno_fw_df$race_ethnicity_clean_2 <- factor(zeno_fw_df$race_ethnicity_clean_2, 
                                           levels = c('White Not Hispanic', 
                                                      'Asian or Black or African American', 
                                                      'Hispanic or Latino',
                                                      'Other/Unknown/Declined'), 
                                           ordered = FALSE)
print(levels(zeno_fw_df$race_ethnicity_clean_2))
table(zeno_fw_df$race_ethnicity_clean_2)

# clean_sex 
print(table(zeno_fw_df$clean_sex))
zeno_fw_df <- zeno_fw_df %>% 
  mutate(clean_sex_2 = if_else(clean_sex == "Female", 
                                     "Female", 
                                     "Male or Non-Binary"))

zeno_fw_df$clean_sex_2 <- factor(zeno_fw_df$clean_sex_2, 
                                        levels = c("Female", 
                                                   "Male or Non-Binary"), 
                                        ordered = FALSE)


table(zeno_fw_df$clean_sex_2)
print(str(zeno_fw_df$clean_sex_2))

```


### Missing variables per column
```{r}
colSums(is.na(zeno_fw_df))
```

### Visit types 
```{r}
table(zeno_fw_df$redcap_event_name)
```

## Load and format Home video data 
```{r}
home_path <- file.path("C:/Users/mmccu/Box/MM_Personal/5_Projects/BoveLab/3_Data_and_Code/gait_bw_zeno_home_analysis",
                       analysis_version, 
                       "000_merged_cleaned_data", 
                       "hv_bw_merged_clean.csv")
home_df <- read.csv(home_path)
nrow(home_df)
table(home_df$demographic_diagnosis)
table(home_df$task_pose_hv)
```

### Factor categorical vars 
```{r}
str(home_df)
home_df <- home_df %>% 
  mutate_at(c("video_id_date_name_pose_hv", "id_date_pose_hv", "task_pose_hv", 
              "id_video", "bw_id", "clean_sex", "bingoEHR_DX_MS.DX", 
              "demographic_diagnosis", "race_ethnicity_clean", 
              "race_ethnicity_clean", "ms_dx_condensed",
              "redcap_event_name", "bingoEHR_EDSS_measure_value"), 
            as.factor)
str(home_df)


# assign levels to categorical variables 
table(home_df$race_ethnicity_clean)

home_df$race_ethnicity_clean <- factor(home_df$race_ethnicity_clean, 
                                       levels = c('White Not Hispanic', 
                                                  'Asian', 
                                                  'Black Or African American',
                                                  'Hispanic or Latino',
                                                  'Other/Unknown/Declined'), 
                                       ordered = FALSE)
print(levels(home_df$race_ethnicity_clean))

table(home_df$ms_dx_condensed)
home_df$ms_dx_condensed <- factor(home_df$ms_dx_condensed, 
                                  levels = c('RRMS', 
                                             'Progressive MS',
                                             'MS, Subtype Not Specified'), 
                                  ordered = FALSE)
print(levels(zeno_fw_df$ms_dx_condensed))

table(zeno_fw_df$clean_sex)
zeno_fw_df$clean_sex <- factor(zeno_fw_df$clean_sex, 
                               levels = c('Female', 
                                          'Male',
                                          'Non-Binary'), 
                               ordered = FALSE)
print(levels(home_df$clean_sex))

table(home_df$edss_severity_cat)
home_df$edss_severity_cat <- factor(home_df$edss_severity_cat, 
                                levels = c('mild', 
                                           'moderate',
                                           'severe'), 
                                ordered = TRUE)
print(levels(home_df$edss_severity_cat))
```

### Missing variables per column
```{r}
colSums(is.na(home_df))
```

### Visit types 
```{r}
# of right turning videos and left turning videos 
table(home_df$task_pose_hv)

# videos per timepoint - most people sent two videos per timepoint 
# some sent first videos at year 2 or year 3 visit, not necessarily a true follow up 
table(home_df$redcap_event_name)
```

### Date diff histograms 
```{r}
ggplot(data = home_df, aes(bw_hv_date_diff_days)) + 
  geom_histogram()
```

# Functions 
## Summarize and save polr results 
```{r}
summary_calc_p_and_odds <- function(polr_object, file_name) {
  
  print(summary(polr_object))
  
  # calculate p-value by comparing t-value vs standard normal distribution 
  ctable1 <- coef(summary(polr_object))
  ## calculate and store p values
  p <- pnorm(abs(ctable1[, "t value"]), lower.tail = FALSE) * 2
  
  ## combined table
  print('Add p-value')
  print((ctable1 <- cbind(ctable1, "p.value" = p)))
  write.csv(ctable1, file.path(output_dir, paste(file_name, "estimates.csv", sep = "_"))) 
  
  # confidence intervals 
  ci <- confint(polr_object)
  print(ci[1])
  
  ## OR and CI
  print('Odds Ratio and CI')
  OR <- exp(cbind("OR" = coef(polr_object), "ci_2.5%" = ci[1], "ci_97.5%"= ci[2]))
  print(OR)
  write.csv(OR, file.path(output_dir, paste(file_name, "odds_ratio.csv", sep = "_"))) 
  
}

```

## Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
sf <- function(y) {
  c('Y>=1' = qlogis(mean(y >= 1)),
    'Y>=2' = qlogis(mean(y >= 2)),
    'Y>=3' = qlogis(mean(y >= 3)))
}
```

```{r}
plot_check_assumption <- function(s_var) {
  # we normalized all the first set of coefficients to be zero so there is a common reference point. 
  # for each variable - is horizontal distance between variables similar? 
  # if so, proportional odds assumption likeley holds 
  # if not, proportional odss assumption may not hold 

  s[, 4] <- s[, 4] - s[, 3]
  s[, 3] <- s[, 3] - s[, 3]
  print(s) # print

  p <- plot(s, which=1:3, pch=1:3, xlab='logit', main=' ', xlim=range(s[,3:4]))
  return(p) 
  }
```


# Transform Velocity Proxy 
log transform to improve linearity and replace inf values with NA 
```{r}
zeno_pws_df$log_delta_pix_h_rel_median_pose_zv <- log(zeno_pws_df$delta_pix_h_rel_median_pose_zv)
zeno_fw_df$log_delta_pix_h_rel_median_pose_zv <- log(zeno_fw_df$delta_pix_h_rel_median_pose_zv)
home_df$log_delta_pix_h_rel_median_pose_hv <- log(home_df$delta_pix_h_rel_median_pose_hv)

# convert inf to NaN 
zeno_pws_df[] <- lapply(zeno_pws_df, function(x) {
  if (is.numeric(x)) replace(x, is.infinite(x), NA) else x
})

zeno_fw_df[] <- lapply(zeno_fw_df, function(x) {
  if (is.numeric(x)) replace(x, is.infinite(x), NA) else x
})

home_df[] <- lapply(home_df, function(x) {
  if (is.numeric(x)) replace(x, is.infinite(x), NA) else x
})
```

# EDSS Ordinal Regresssion 
Following steps from - https://stats.oarc.ucla.edu/r/dae/ordinal-logistic-regression/ 

## Filter Videos 
- EDSS within 90 days of Brainwalk Visit 
- First video from each participant - not sure how to do (or if possible) to add participant ID as random effect in ordinal regression

### PWS 
```{r}
# PWS 
print("# of videos in original df")
print(nrow(zeno_pws_df))

p1 <- ggplot(data = zeno_pws_df, aes(demoEHR_EDSS_dateDiff)) + 
  geom_histogram() + 
  labs(title = "PWS All")
p1

# filter within 90 days 
zeno_pws_edss_df <- zeno_pws_df %>% 
  filter(demoEHR_EDSS_dateDiff > -90 & demoEHR_EDSS_dateDiff < 90)

p2 <- ggplot(data = zeno_pws_edss_df, aes(demoEHR_EDSS_dateDiff)) + 
  geom_histogram() + 
  labs(title = "PWS: EDSS within 90 days")
p2

# Number of videos 
print("# OF videos after dropping EDSS")
print(nrow(zeno_pws_edss_df))

# select unique ID 
zeno_pws_edss_df <- zeno_pws_edss_df %>%
  arrange(visit_date_video) %>%   # Sort by date
  distinct(bw_id, .keep_all = TRUE) %>%  # Keep the first occurrence of each ID
  drop_na(c("stride_time_median_sec_pose_zv", # drop missing video metrics 
            "log_delta_pix_h_rel_median_pose_zv",
            "mean_cadence_step_per_min_pose_zv",
            "stride_width_median_cm_pose_zv"))
# Number of videos 
print("# OF videos after dropping EDSS + only unique ID")
print(nrow(zeno_pws_edss_df))

# Histogram of EDSS: only unique ID 
p3 <- ggplot(data = zeno_pws_edss_df, aes(bingoEHR_EDSS_measure_value)) + 
  geom_bar() + 
  labs(title = "PWS: unique ID and EDSS w/in 90 days ")
p3

```

### FW 
```{r}
print("# of videos in original df")
print(nrow(zeno_fw_df))

p1 <- ggplot(data = zeno_fw_df, aes(demoEHR_EDSS_dateDiff)) + 
  geom_histogram() + 
  labs(title = "FW All")
p1

# filter within 90 days 
zeno_fw_edss_df <- zeno_fw_df %>% 
  filter(demoEHR_EDSS_dateDiff > -90 & demoEHR_EDSS_dateDiff < 90)

p2 <- ggplot(data = zeno_fw_edss_df, aes(demoEHR_EDSS_dateDiff)) + 
  geom_histogram() + 
  labs(title = "FW: EDSS within 90 days")
p2

# Number of videos 
print("# OF videos after dropping EDSS")
print(nrow(zeno_fw_edss_df))

# select unique ID 
zeno_fw_edss_df <- zeno_fw_edss_df %>%
  arrange(visit_date_video) %>%   # Sort by date
  distinct(bw_id, .keep_all = TRUE)  %>%  # Keep the first occurrence of each ID
  drop_na(c("stride_time_median_sec_pose_zv", # drop missing video metrics 
            "log_delta_pix_h_rel_median_pose_zv",
            "mean_cadence_step_per_min_pose_zv",
            "stride_width_median_cm_pose_zv"))

# Number of videos 
print("# OF videos after dropping EDSS + only unique ID")
print(nrow(zeno_fw_edss_df))

# Histogram of EDSS: only unique ID 
p3 <- ggplot(data = zeno_fw_edss_df, aes(bingoEHR_EDSS_measure_value)) + 
  geom_bar() + 
  labs(title = "FW: unique ID and EDSS w/in 90 days ")
p3

```

### Home  
```{r}
print("# of videos in original df")
print(nrow(home_df))

p1 <- ggplot(data = home_df, aes(demoEHR_EDSS_dateDiff)) + 
  geom_histogram() + 
  labs(title = "Home All")
p1

# filter within 90 days 
home_edss_df <- home_df %>% 
  filter(demoEHR_EDSS_dateDiff > -90 & demoEHR_EDSS_dateDiff < 90)

p2 <- ggplot(data = home_edss_df, aes(demoEHR_EDSS_dateDiff)) + 
  geom_histogram() + 
  labs(title = "Home: EDSS within 90 days")
p2

# Number of videos 
print("# OF videos after dropping EDSS")
print(nrow(home_edss_df))

# select unique ID 
home_edss_df <- home_edss_df %>%
  arrange(visit_date_video) %>%   # Sort by date
  distinct(bw_id, .keep_all = TRUE)  %>%  # Keep the first occurrence of each ID
  drop_na(c("stride_time_median_sec_pose_hv", # drop missing video metrics 
            "log_delta_pix_h_rel_median_pose_hv",
            "mean_cadence_step_per_min_pose_hv",
            "stride_width_median_cm_pose_hv"))

# Number of videos 
print("# OF home_edss_df after dropping EDSS + only unique ID")
print(nrow(home_edss_df))

# Histogram of EDSS: only unique ID 
p3 <- ggplot(data = home_edss_df, aes(bingoEHR_EDSS_measure_value)) + 
  geom_bar() + 
  labs(title = "Home: unique ID and EDSS w/in 90 days ")
p3

```

## Check EDSS factor and levels 
```{r}
print(str(zeno_pws_edss_df$edss_severity_cat))
print(table(zeno_pws_edss_df$edss_severity_cat))
print(levels(zeno_pws_edss_df$edss_severity_cat))

print(str(zeno_fw_edss_df$edss_severity_cat))
print(table(zeno_fw_edss_df$edss_severity_cat))
print(levels(zeno_fw_edss_df$edss_severity_cat))

print(str(home_df$edss_severity_cat))
print(table(home_edss_df$edss_severity_cat))
print(levels(home_edss_df$edss_severity_cat))
```
## Preferred Walking Speed Videos 

### Univariate - log pixel proxy 
```{r}
# file name 
filename = "PWS_univariate_log_delta_pix"
# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, y = log_delta_pix_h_rel_median_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)

ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ log_delta_pix_h_rel_median_pose_zv, 
             data = zeno_pws_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ log_delta_pix_h_rel_median_pose_zv, fun=sf))
p <- plot_check_assumption(s_var = s)

```

Obtain and plot predicted probabilities 

example 
newdat <- data.frame(
 pared = rep(0:1, 200),
 public = rep(0:1, each = 200), 
 gpa = rep(seq(from = 1.9, to = 4, length.out = 100), 4)) 
  
Categorical vars (pared, public) -  0 and 1 levels for factor, repeat 01 200x = 400 rows 
Continuous vars (gpa_ - from = upper left square of s; to = lower right square of s 
  length.out = 100 rows, * 4 = total 400 rows 
  

```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  log_delta_pix_h_rel_median_pose_zv = rep(seq(from = -2.813, to = -0.462, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("log_delta_pix_h_rel_median_pose_zv"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = log_delta_pix_h_rel_median_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```

### Univariate - stride_time_median_sec_pose
```{r}
filename = "PWS_univariate_stride_time_median"
# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, y = stride_time_median_sec_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ stride_time_median_sec_pose_zv, 
             data = zeno_pws_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```
Stride time not significantly associated --> didn't test assumptions etc 

### Univariate - mean_cadence_step_per_min_pose
```{r}
filename = "PWS_univariate_mean_cadence"
# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, y = mean_cadence_step_per_min_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ mean_cadence_step_per_min_pose_zv, 
             data = zeno_pws_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```
Cadence not significantly associated --> didn't test assumptions etc 

### Univariate - stride_width_median_cm_pose
```{r}
filename = "PWS_univariate_stride_width_median"
# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, y = stride_width_median_cm_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ stride_width_median_cm_pose_zv, 
             data = zeno_pws_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)
```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ stride_width_median_cm_pose_zv, fun=sf))
plot_check_assumption(s_var = s)
```
```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  stride_width_median_cm_pose_zv = rep(seq(from = 3.38, to = 26.9, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("stride_width_median_cm_pose_zv"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

ggplot(lnewdat, aes(x = stride_width_median_cm_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```
### Univariate - demoEHR_Age
```{r}
filename = "PWS_univariate_age"
# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, y = demoEHR_Age)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ demoEHR_Age, 
             data = zeno_pws_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)
```
If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_Age, fun=sf))
plot_check_assumption(s)
```
```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(demoEHR_Age = rep(seq(from = 25, to = 75, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("demoEHR_Age"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

ggplot(lnewdat, aes(x = demoEHR_Age, y = Probability, colour = Level)) +
  geom_line()  + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'probabilities.png', sep = "_")))
```

### Univariate - demoEHR_DiseaseDuration
```{r}
filename = "PWS_univariate_disease_duration"
# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, y = demoEHR_DiseaseDuration)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ demoEHR_DiseaseDuration, 
             data = zeno_pws_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)
```
If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_DiseaseDuration, fun=sf))
plot_check_assumption(s)
```
```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(demoEHR_DiseaseDuration = rep(seq(from =0, to = 38, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("demoEHR_DiseaseDuration"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

ggplot(lnewdat, aes(x = demoEHR_DiseaseDuration, y = Probability, colour = Level)) +
  geom_line()  + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'probabilities.png', sep = "_")))
```

### Univariate - ms_dx_condensed 

Using two groups: RRMS and not specified, or progressive 
```{r}
filename = "PWS_univariate_ms_dx_condensed_2"

# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, fill = ms_dx_condensed_2)) +
  geom_bar(position = "dodge") + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ ms_dx_condensed_2, 
             data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)


```
If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ ms_dx_condensed_2, fun=sf))
plot_check_assumption(s)
```

### Univariate - race_ethnicity_clean

```{r}
filename = "PWS_univariate_clean_race_ethnicity_2"

# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, fill = race_ethnicity_clean_2)) +
  geom_bar(position = "dodge") + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ race_ethnicity_clean_2, 
             data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)


```
If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ race_ethnicity_clean_2, fun=sf))
plot_check_assumption(s)
```

### Univariate - clean_sex
```{r}
filename = "PWS_univariate_clean_sex_2"

# plot 
ggplot(zeno_pws_edss_df, aes(x = edss_severity_cat, fill = clean_sex_2)) +
  geom_bar(position = "dodge") + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ clean_sex_2, 
             data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)


```

### Multivariate - Demographics and MS Info
```{r}
filename = "PWS_multivar_dem_ms_info"

# model 
pws_multivar_dem_ms <- polr(edss_severity_cat ~ demoEHR_Age + 
                              demoEHR_DiseaseDuration + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2 + 
                              clean_sex_2,
                            data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = pws_multivar_dem_ms,
                        file_name = filename)
```

If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_Age + 
                                      demoEHR_DiseaseDuration + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2 + 
                                      clean_sex_2, 
                                    fun=sf))
plot_check_assumption(s)
```

### Multivariate - Unadj Video Metrics 
```{r}
filename = "PWS_multivar_video_unadj"

# model 
pws_multivar_video_unadj <- polr(edss_severity_cat ~ log_delta_pix_h_rel_median_pose_zv + 
                              stride_time_median_sec_pose_zv + 
                              mean_cadence_step_per_min_pose_zv + 
                              stride_width_median_cm_pose_zv, 
                            data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = pws_multivar_video_unadj,
                        file_name = filename)
```

If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ log_delta_pix_h_rel_median_pose_zv + 
                                      stride_time_median_sec_pose_zv + 
                                      mean_cadence_step_per_min_pose_zv + 
                                      stride_width_median_cm_pose_zv, 
                                    fun=sf))
plot_check_assumption(s)
```

### Multivariate - Adj Video Metrics 
```{r}
filename = "PWS_multivar_video_adj"

# model 
pws_multivar_video_adj <- polr(edss_severity_cat ~ demoEHR_Age + 
                                   demoEHR_DiseaseDuration + 
                                   ms_dx_condensed_2 + 
                                   race_ethnicity_clean_2 + 
                                   clean_sex_2 + 
                                   log_delta_pix_h_rel_median_pose_zv + 
                                   stride_time_median_sec_pose_zv + 
                                   mean_cadence_step_per_min_pose_zv + 
                                   stride_width_median_cm_pose_zv, 
                                 data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = pws_multivar_video_adj,
                        file_name = filename)
```


### Plot multivariate models 
For now, just using combinations of three predictors, two categorical and one continuous 
Can try to edit to make continous vars categorical just for plots? 

Plot 1 - Demographics only 
Left out sex - not sig effect in univariate 
Left out age - similar effect to duration, but expect disease duration to be more impactful on EDSS 

```{r}
filename = "PWS_multivar_dur_dx_race"

# model 
pws_multivar_dur_dx_race <- polr(edss_severity_cat ~ demoEHR_DiseaseDuration + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2,
                            data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = pws_multivar_dur_dx_race,
                        file_name = filename)


# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_DiseaseDuration + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2, 
                                    fun=sf))
plot_check_assumption(s)

# save original levels to create df  
ms_dx_levels <- levels(pws_multivar_dur_dx_race$model$ms_dx_condensed_2)
ms_dx_levels

race_levels <- levels(pws_multivar_dur_dx_race$model$race_ethnicity_clean_2)
race_levels

# Define continuous variable ranges
disease_duration_values <- seq(from = 0, to = 38, length.out = 100)

# Generate all combinations of categorical variables
cat_combinations <- expand.grid(
  ms_dx_condensed_2 = ms_dx_levels,
  race_ethnicity_clean_2 = race_levels,
  stringsAsFactors = TRUE  # Ensures they are factors
)

head(cat_combinations)

# Expand dataset to include all continuous variable values for each categorical combination
newdat <- expand.grid(
  demoEHR_DiseaseDuration = disease_duration_values,
  stringsAsFactors = FALSE  # Keep continuous variables numeric
)

# Use `merge()` to properly combine categorical and continuous variables
newdat <- merge(cat_combinations, newdat, by = NULL)

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(pws_multivar_dur_dx_race, newdat, type = "probs"))
head(newdat)

head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("demoEHR_DiseaseDuration",
                                    "ms_dx_condensed_2",
                                    "race_ethnicity_clean_2"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)


# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = demoEHR_DiseaseDuration, y = Probability, colour = Level)) +
  geom_line() + 
  facet_grid(ms_dx_condensed_2 ~ race_ethnicity_clean_2) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))

```

Plot 2 - Sig predictors in adjusted model 
Race, MS DX, and Log Pixel Proxy 
```{r}
filename = "PWS_multivar_logPix_dx_race"

# model 
pws_multivar_logPixdx_race <- polr(edss_severity_cat ~ log_delta_pix_h_rel_median_pose_zv + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2,
                            data = zeno_pws_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = pws_multivar_logPixdx_race,
                        file_name = filename)


# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_pws_edss_df, summary(as.numeric(edss_severity_cat) ~ log_delta_pix_h_rel_median_pose_zv + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2, 
                                    fun=sf))
plot_check_assumption(s)

# save original levels to create df  
ms_dx_levels <- levels(pws_multivar_logPixdx_race$model$ms_dx_condensed_2)
ms_dx_levels

race_levels <- levels(pws_multivar_logPixdx_race$model$race_ethnicity_clean_2)
race_levels

# Define continuous variable ranges
log_pix_values <- seq(from = -2.813, to = -0.462, length.out = 100)

# Generate all combinations of categorical variables
cat_combinations <- expand.grid(
  ms_dx_condensed_2 = ms_dx_levels,
  race_ethnicity_clean_2 = race_levels,
  stringsAsFactors = TRUE  # Ensures they are factors
)

head(cat_combinations)

# Expand dataset to include all continuous variable values for each categorical combination
newdat <- expand.grid(
  log_delta_pix_h_rel_median_pose_zv = log_pix_values,
  stringsAsFactors = FALSE  # Keep continuous variables numeric
)

# Use `merge()` to properly combine categorical and continuous variables
newdat <- merge(cat_combinations, newdat, by = NULL)

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(pws_multivar_logPixdx_race, newdat, type = "probs"))
head(newdat)

head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("log_delta_pix_h_rel_median_pose_zv",
                                    "ms_dx_condensed_2",
                                    "race_ethnicity_clean_2"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)


# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = log_delta_pix_h_rel_median_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  facet_grid(ms_dx_condensed_2 ~ race_ethnicity_clean_2) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))

```

# Fast Walking Speed Videos 
### Univariate - log pixel proxy 
```{r}
# file name 
filename = "FW_univariate_log_delta_pix"
# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, y = log_delta_pix_h_rel_median_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ log_delta_pix_h_rel_median_pose_zv, 
             data = zeno_fw_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ log_delta_pix_h_rel_median_pose_zv, fun=sf))
p <- plot_check_assumption(s_var = s)

```

```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  log_delta_pix_h_rel_median_pose_zv = rep(seq(from = -3.219, to = -0.139, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("log_delta_pix_h_rel_median_pose_zv"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = log_delta_pix_h_rel_median_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```
### Univariate - stride_time_median_sec_pose
```{r}
filename = "FW_univariate_stride_time_median"
# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, y = stride_time_median_sec_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ stride_time_median_sec_pose_zv, 
             data = zeno_fw_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ stride_time_median_sec_pose_zv, fun=sf))
p <- plot_check_assumption(s_var = s)

```

```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  stride_time_median_sec_pose_zv = rep(seq(from = 0.650, to = 2.017, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("stride_time_median_sec_pose_zv"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = stride_time_median_sec_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```

### Univariate - mean_cadence_step_per_min_pose
```{r}
filename = "FW_univariate_mean_cadence"
# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, y = mean_cadence_step_per_min_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))

# model 
uni1 <- polr(edss_severity_cat ~ mean_cadence_step_per_min_pose_zv, 
             data = zeno_fw_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```

If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ mean_cadence_step_per_min_pose_zv, fun=sf))
p <- plot_check_assumption(s_var = s)

```

```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  mean_cadence_step_per_min_pose_zv = rep(seq(from = 56.4, to = 170, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("mean_cadence_step_per_min_pose_zv"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = mean_cadence_step_per_min_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```

### Univariate - stride_width_median_cm_pose
```{r}
filename = "FW_univariate_stride_width_median"
# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, y = stride_width_median_cm_pose_zv)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ stride_width_median_cm_pose_zv, 
             data = zeno_fw_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)
```

If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ stride_width_median_cm_pose_zv, fun=sf))
p <- plot_check_assumption(s_var = s)
```
```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  stride_width_median_cm_pose_zv = rep(seq(from = 5.72, to = 23.7, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("stride_width_median_cm_pose_zv"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = stride_width_median_cm_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```
### Univariate - demoEHR_Age
```{r}
filename = "FW_univariate_age"
# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, y = demoEHR_Age)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ demoEHR_Age, 
             data = zeno_fw_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)
```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_Age, fun=sf))
p <- plot_check_assumption(s_var = s)
```
```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  demoEHR_Age = rep(seq(from = 24, to = 80, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("demoEHR_Age"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = demoEHR_Age, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```
### Univariate - demoEHR_DiseaseDuration
```{r}
filename = "FW_univariate_disease_duration"
# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, y = demoEHR_DiseaseDuration)) +
  geom_boxplot(size = .75) +
  geom_jitter(alpha = .5) + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ demoEHR_DiseaseDuration, 
             data = zeno_fw_edss_df, Hess=TRUE)

summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)
```

If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_DiseaseDuration, fun=sf))
p <- plot_check_assumption(s_var = s)
```

```{r}
# Create new dataset of all values to use for prediction 
newdat <- data.frame(
  demoEHR_DiseaseDuration = rep(seq(from = 0, to = 38, length.out = 100), 4)) 

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(uni1, newdat, type = "probs"))
head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("demoEHR_DiseaseDuration"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)

# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = demoEHR_DiseaseDuration, y = Probability, colour = Level)) +
  geom_line() + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))
```

### Univariate - ms_dx_condensed 

Using two groups: RRMS and not specified, or progressive 
```{r}
filename = "FW_univariate_ms_dx_condensed_2"

# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, fill = ms_dx_condensed_2)) +
  geom_bar(position = "dodge")  + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ ms_dx_condensed_2, 
             data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)


```

If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ ms_dx_condensed_2, fun=sf))
p <- plot_check_assumption(s_var = s)
```
### Univariate - race_ethnicity_clean

```{r}
filename = "FW_univariate_clean_race_ethnicity_2"

# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, fill = race_ethnicity_clean_2)) +
  geom_bar(position = "dodge") + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ race_ethnicity_clean_2, 
             data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)

```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ race_ethnicity_clean_2, fun=sf))
p <- plot_check_assumption(s_var = s)
```
### Univariate - clean_sex
```{r}
filename = "FW_univariate_clean_sex_2"

# plot 
ggplot(zeno_fw_edss_df, aes(x = edss_severity_cat, fill = clean_sex_2)) +
  geom_bar(position = "dodge") + 
  labs(title = filename)
ggsave(file.path(output_dir, paste(filename, 'vs_edss.png', sep = "_")))


# model 
uni1 <- polr(edss_severity_cat ~ clean_sex_2, 
             data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = uni1, 
                        file_name = filename)


```
If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ clean_sex_2, fun=sf))
p <- plot_check_assumption(s_var = s)
```


### Multivariate - Demographics and MS Info
```{r}
filename = "FW_multivar_dem_ms_info"

# model 
fw_multivar_dem_ms <- polr(edss_severity_cat ~ demoEHR_Age + 
                              demoEHR_DiseaseDuration + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2 + 
                              clean_sex_2,
                            data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = fw_multivar_dem_ms,
                        file_name = filename)
```

If significant effect: 
Test proportional odds assumption
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ demoEHR_Age + 
                                     demoEHR_DiseaseDuration + 
                                     ms_dx_condensed_2 + 
                                     race_ethnicity_clean_2 + 
                                     clean_sex_2,
                                   fun=sf))
p <- plot_check_assumption(s_var = s)
```

### Multivariate - Unadj Video Metrics 
```{r}
filename = "FW_multivar_video_unadj"

# model 
fw_multivar_video_unadj <- polr(edss_severity_cat ~ log_delta_pix_h_rel_median_pose_zv + 
                              stride_time_median_sec_pose_zv + 
                              mean_cadence_step_per_min_pose_zv + 
                              stride_width_median_cm_pose_zv, 
                            data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = fw_multivar_video_unadj,
                        file_name = filename)
```

If significant effect: 
Test proportional odds assumption - don't think meets assumption?
```{r}
# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ log_delta_pix_h_rel_median_pose_zv + 
                                      stride_time_median_sec_pose_zv + 
                                      mean_cadence_step_per_min_pose_zv + 
                                      stride_width_median_cm_pose_zv, 
                                    fun=sf))
plot_check_assumption(s)
```

### Multivariate - Adj Video Metrics 
```{r}
filename = "FW_multivar_video_adj"

# model 
fw_multivar_video_adj <- polr(edss_severity_cat ~ demoEHR_Age + 
                                   demoEHR_DiseaseDuration + 
                                   ms_dx_condensed_2 + 
                                   race_ethnicity_clean_2 + 
                                   clean_sex_2 + 
                                   log_delta_pix_h_rel_median_pose_zv + 
                                   stride_time_median_sec_pose_zv + 
                                   mean_cadence_step_per_min_pose_zv + 
                                   stride_width_median_cm_pose_zv, 
                                 data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = fw_multivar_video_adj,
                        file_name = filename)
```


### Plot multivariate models 
Each video metric that was sig in univariate model with race and dx 
Race, MS DX, and Log Pixel Proxy 
```{r}
filename = "FW_multivar_logPix_dx_race"

# model 
FW_multivar_logPixdx_race <- polr(edss_severity_cat ~ log_delta_pix_h_rel_median_pose_zv + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2,
                            data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = FW_multivar_logPixdx_race,
                        file_name = filename)


# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ log_delta_pix_h_rel_median_pose_zv + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2, 
                                    fun=sf))
plot_check_assumption(s)

# save original levels to create df  
ms_dx_levels <- levels(FW_multivar_logPixdx_race$model$ms_dx_condensed_2)
ms_dx_levels

race_levels <- levels(FW_multivar_logPixdx_race$model$race_ethnicity_clean_2)
race_levels

# Define continuous variable ranges
log_pix_values <- seq(from = -3.219, to = -0.139, length.out = 100)

# Generate all combinations of categorical variables
cat_combinations <- expand.grid(
  ms_dx_condensed_2 = ms_dx_levels,
  race_ethnicity_clean_2 = race_levels,
  stringsAsFactors = TRUE  # Ensures they are factors
)

head(cat_combinations)

# Expand dataset to include all continuous variable values for each categorical combination
newdat <- expand.grid(
  log_delta_pix_h_rel_median_pose_zv = log_pix_values,
  stringsAsFactors = FALSE  # Keep continuous variables numeric
)

# Use `merge()` to properly combine categorical and continuous variables
newdat <- merge(cat_combinations, newdat, by = NULL)

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(FW_multivar_logPixdx_race, newdat, type = "probs"))
head(newdat)

head(newdat)

# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("log_delta_pix_h_rel_median_pose_zv",
                                    "ms_dx_condensed_2",
                                    "race_ethnicity_clean_2"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)


# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = log_delta_pix_h_rel_median_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  facet_grid(ms_dx_condensed_2 ~ race_ethnicity_clean_2) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))

```

Race, MS DX, and Stride Time 
```{r}
filename = "FW_multivar_strideTime_dx_race"

# model 
FW_multivar_strideTime_dx_race <- polr(edss_severity_cat ~ stride_time_median_sec_pose_zv + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2,
                            data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = FW_multivar_strideTime_dx_race,
                        file_name = filename)


# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ stride_time_median_sec_pose_zv + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2, 
                                    fun=sf))
plot_check_assumption(s)

# save original levels to create df  
ms_dx_levels <- levels(FW_multivar_strideTime_dx_race$model$ms_dx_condensed_2)
ms_dx_levels

race_levels <- levels(FW_multivar_logPixdx_race$model$race_ethnicity_clean_2)
race_levels

# Define continuous variable ranges
stride_time_values <- seq(from = 0.650, to = 2.017, length.out = 100)

# Generate all combinations of categorical variables
cat_combinations <- expand.grid(
  ms_dx_condensed_2 = ms_dx_levels,
  race_ethnicity_clean_2 = race_levels,
  stringsAsFactors = TRUE  # Ensures they are factors
)

head(cat_combinations)

# Expand dataset to include all continuous variable values for each categorical combination
newdat <- expand.grid(
  stride_time_median_sec_pose_zv = stride_time_values,
  stringsAsFactors = FALSE  # Keep continuous variables numeric
)

# Use `merge()` to properly combine categorical and continuous variables
newdat <- merge(cat_combinations, newdat, by = NULL)

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(FW_multivar_strideTime_dx_race, newdat, type = "probs"))
head(newdat)


# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("stride_time_median_sec_pose_zv",
                                    "ms_dx_condensed_2",
                                    "race_ethnicity_clean_2"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)


# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = stride_time_median_sec_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  facet_grid(ms_dx_condensed_2 ~ race_ethnicity_clean_2) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))

```

Race, MS DX, and Cadence
```{r}
filename = "FW_multivar_cadence_dx_race"

# model 
FW_multivar_cadence_dx_race <- polr(edss_severity_cat ~ mean_cadence_step_per_min_pose_zv + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2,
                            data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = FW_multivar_cadence_dx_race,
                        file_name = filename)


# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ mean_cadence_step_per_min_pose_zv + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2, 
                                    fun=sf))
plot_check_assumption(s)

# save original levels to create df  
ms_dx_levels <- levels(FW_multivar_cadence_dx_race$model$ms_dx_condensed_2)
ms_dx_levels

race_levels <- levels(FW_multivar_logPixdx_race$model$race_ethnicity_clean_2)
race_levels

# Define continuous variable ranges
cadence_values <- seq(from = 56.4, to = 170, length.out = 100)

# Generate all combinations of categorical variables
cat_combinations <- expand.grid(
  ms_dx_condensed_2 = ms_dx_levels,
  race_ethnicity_clean_2 = race_levels,
  stringsAsFactors = TRUE  # Ensures they are factors
)

head(cat_combinations)

# Expand dataset to include all continuous variable values for each categorical combination
newdat <- expand.grid(
  mean_cadence_step_per_min_pose_zv = cadence_values,
  stringsAsFactors = FALSE  # Keep continuous variables numeric
)

# Use `merge()` to properly combine categorical and continuous variables
newdat <- merge(cat_combinations, newdat, by = NULL)

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(FW_multivar_cadence_dx_race, newdat, type = "probs"))
head(newdat)


# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("mean_cadence_step_per_min_pose_zv",
                                    "ms_dx_condensed_2",
                                    "race_ethnicity_clean_2"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)


# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = mean_cadence_step_per_min_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  facet_grid(ms_dx_condensed_2 ~ race_ethnicity_clean_2) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))

```

Race, MS DX, and StrideWidth
```{r}
filename = "FW_multivar_strideWidth_dx_race"

# model 
FW_multivar_strideWidth_dx_race <- polr(edss_severity_cat ~ stride_width_median_cm_pose_zv + 
                              ms_dx_condensed_2 + 
                              race_ethnicity_clean_2,
                            data = zeno_fw_edss_df, Hess=TRUE)


summary_calc_p_and_odds(polr_object = FW_multivar_strideWidth_dx_race,
                        file_name = filename)


# calculate the log odds of being greater than or equal to each value of the target variable
s <- with(zeno_fw_edss_df, summary(as.numeric(edss_severity_cat) ~ stride_width_median_cm_pose_zv + 
                                      ms_dx_condensed_2 + 
                                      race_ethnicity_clean_2, 
                                    fun=sf))
plot_check_assumption(s)

# save original levels to create df  
ms_dx_levels <- levels(FW_multivar_strideWidth_dx_race$model$ms_dx_condensed_2)
ms_dx_levels

race_levels <- levels(FW_multivar_logPixdx_race$model$race_ethnicity_clean_2)
race_levels

# Define continuous variable ranges
stride_width_values <- seq(from = 5.72, to = 23.7, length.out = 100)

# Generate all combinations of categorical variables
cat_combinations <- expand.grid(
  ms_dx_condensed_2 = ms_dx_levels,
  race_ethnicity_clean_2 = race_levels,
  stringsAsFactors = TRUE  # Ensures they are factors
)

head(cat_combinations)

# Expand dataset to include all continuous variable values for each categorical combination
newdat <- expand.grid(
  stride_width_median_cm_pose_zv = stride_width_values,
  stringsAsFactors = FALSE  # Keep continuous variables numeric
)

# Use `merge()` to properly combine categorical and continuous variables
newdat <- merge(cat_combinations, newdat, by = NULL)

# predict for each row of new dat using model 
newdat <- cbind(newdat, predict(FW_multivar_strideWidth_dx_race, newdat, type = "probs"))
head(newdat)


# reshape for plotting 
lnewdat <- melt(newdat, id.vars = c("stride_width_median_cm_pose_zv",
                                    "ms_dx_condensed_2",
                                    "race_ethnicity_clean_2"),
                variable.name = "Level", value.name="Probability")
head(lnewdat)


# plot all of the predicted probabilities for the different conditions. 
# example 
#ggplot(lnewdat, aes(x = gpa, y = Probability, colour = Level)) +
  #geom_line() + facet_grid(pared ~ public, labeller="label_both")

p <- ggplot(lnewdat, aes(x = stride_width_median_cm_pose_zv, y = Probability, colour = Level)) +
  geom_line() + 
  facet_grid(ms_dx_condensed_2 ~ race_ethnicity_clean_2) + 
  labs(title = filename)
p
ggsave(file.path(output_dir, paste(filename, "probabilities.png", sep = "_")))

```