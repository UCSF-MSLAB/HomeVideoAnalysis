{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c52760-b03c-42c5-afce-791fe54b7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884bd13-f08a-43c0-8e61-0fa2c9d493c8",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2348d25d-e059-4222-91a4-4f7df178c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into healthy controls and participant swith MS \n",
    "# then select first visit date - maybe not baseline, but first visit with data in that dataset \n",
    "\n",
    "def split_MS_HC_first_visit(df): \n",
    "    df = df.copy()\n",
    "    df['visit_date'] = pd.to_datetime(df['visit_date'])\n",
    "    df['bw_id'] = df['bw_id'].str.strip()\n",
    "\n",
    "    print('total unique bw_ids in df')\n",
    "    print(df['bw_id'].nunique())\n",
    "    print('--------------') \n",
    "\n",
    "    # drop full duplicate rows \n",
    "    df = df.drop_duplicates(keep='first')\n",
    "\n",
    "    # drop dupllicated bw_id and visit_date - ex: same fw and pws \n",
    "    df = df.drop_duplicates(subset=['bw_id', 'visit_date'], keep='first')\n",
    "\n",
    "    # first visit - keep the earliest date for each ID \n",
    "    df_first_visit = (\n",
    "        df.sort_values(by=['bw_id', 'visit_date'])\n",
    "        .groupby('bw_id')\n",
    "        .first()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # if multiple tasks for one participant on one day, drop duplicate id date combos \n",
    "    # df_one_task_per_id - 1 row (task) per each id an dvisit data combination\n",
    "#    df = df.sort_values(by=['bw_id', 'visit_date'])\n",
    "#    df = df.drop_duplicates(subset=['bw_id', 'visit_date'], keep='first')\n",
    "\n",
    "    # Group by 'ID' and select the row with the minimum date (first visit) \n",
    "#    df_first_visit = df.loc[df.groupby('bw_id')['visit_date'].idxmin()]\n",
    "\n",
    "    # check if any duplicates \n",
    "    duplicates = df_first_visit['bw_id'].duplicated().sum()\n",
    "    \n",
    "    print('any duplicate bw_ids in first visit df?') \n",
    "    print(duplicates)\n",
    "    print('--------------')\n",
    "\n",
    "    print('df_first_visit demographic diagnosis counts') \n",
    "    print(df_first_visit['demographic_diagnosis'].value_counts())\n",
    "    print('--------------') \n",
    "    \n",
    "    MS_1_df = df_first_visit.loc[df_first_visit['demographic_diagnosis'] == 'MS']\n",
    "    HC_1_df = df_first_visit.loc[df_first_visit['demographic_diagnosis'] == 'HC'] \n",
    "\n",
    "    print('MS and HC rows should match from table above') \n",
    "    print('rows in final MS df')\n",
    "    print(len(MS_1_df))\n",
    "    print('MS df count bw_id rows with data') \n",
    "    print(MS_1_df['bw_id'].count()) \n",
    "\n",
    "    print('rows in final HC df')\n",
    "    print(len(HC_1_df))\n",
    "    print('HC df count bw_id rows with data') \n",
    "    print(HC_1_df['bw_id'].count()) \n",
    "\n",
    "    return MS_1_df, HC_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c976b94-b8d3-41af-b76d-f689f02422b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_summary(df): \n",
    "    # summary statistics for  cohort \n",
    "    if len(df) > 0: \n",
    "        # age \n",
    "        age_count = df['demoEHR_Age'].count()\n",
    "        age_mean = df['demoEHR_Age'].mean()\n",
    "        age_sd = df['demoEHR_Age'].std()\n",
    "        \n",
    "        # sex \n",
    "        sex_count = df['demoEHR_GENDER'].count()\n",
    "        sex_n = df['demoEHR_GENDER'].value_counts()\n",
    "        sex_n_female = sex_n['Female']\n",
    "        sex_freqs = df['demoEHR_GENDER'].value_counts(normalize=True) * 100\n",
    "        sex_freq_female = sex_freqs['Female'] \n",
    "        \n",
    "        # edss \n",
    "        edss_count = df['bingoEHR_EDSS_measure_value'].count()\n",
    "        edss_median = df['bingoEHR_EDSS_measure_value'].median()\n",
    "        edss_iqr = df['bingoEHR_EDSS_measure_value'].quantile(0.75) - df['bingoEHR_EDSS_measure_value'].quantile(0.25)\n",
    "\n",
    "        # t25fw \n",
    "        t25fw_count = df['msfcEHR_T25FW SPEED AVG'].count()\n",
    "        t25fw_mean= df['msfcEHR_T25FW SPEED AVG'].mean()\n",
    "        t25fw_sd = df['msfcEHR_T25FW SPEED AVG'].std()\n",
    "\n",
    "        #race \n",
    "        rec_2_count = df['demoEHR_REC_2'].count()\n",
    "        rec_2_n = df['demoEHR_REC_2'].value_counts()\n",
    "        rec_2_freq = df['demoEHR_REC_2'].value_counts(normalize = True) * 100\n",
    "        \n",
    "        try:\n",
    "            white_n = rec_2_n['WhiteNonHispanic']\n",
    "            white_freq = rec_2_freq['WhiteNonHispanic']\n",
    "        except KeyError:\n",
    "            white_n = 0\n",
    "            white_freq = 0\n",
    "\n",
    "        try: \n",
    "            hispanic_n = rec_2_n['Hispanic']\n",
    "            hispanic_freq = rec_2_freq['Hispanic']\n",
    "        except KeyError: \n",
    "            hispanic_n = 0\n",
    "            hispanic_freq = 0\n",
    "\n",
    "        try: \n",
    "            black_n = rec_2_n['Black']\n",
    "            black_freq = rec_2_freq['Black']\n",
    "        except KeyError:\n",
    "            black_n = 0\n",
    "            black_freq = 0\n",
    "        \n",
    "        try: \n",
    "            asian_n = rec_2_n['Asian/PacificIslander/NativeAmerican']\n",
    "            asian_freq = rec_2_freq['Asian/PacificIslander/NativeAmerican']\n",
    "        except KeyError:\n",
    "            asian_n = 0\n",
    "            asian_freq = 0\n",
    "             \n",
    "        try: \n",
    "            other_n = rec_2_n['Other/Decline/Unknown']\n",
    "            other_freq = rec_2_freq['Other/Decline/Unknown']\n",
    "        except KeyError: \n",
    "            other_n = 0\n",
    "            other_freq = 0\n",
    "\n",
    "        # disease duration \n",
    "        duration_count = df['demoEHR_DiseaseDuration'].count()\n",
    "        duration_mean = df['demoEHR_DiseaseDuration'].mean()\n",
    "        duration_sd = df['demoEHR_DiseaseDuration'].std()\n",
    "\n",
    "        # MS subtype \n",
    "        #'bingoEHR_DX_MS DX'\n",
    "        ms_dx_count = df['bingoEHR_DX_MS DX'].count()\n",
    "        ms_dx_n = df['bingoEHR_DX_MS DX'].value_counts()\n",
    "        ms_dx_freq = df['bingoEHR_DX_MS DX'].value_counts(normalize = True) * 100\n",
    "\n",
    "        try:\n",
    "            rrms_n = ms_dx_n['RRMS (Relapsing-remitting Multiple Sclerosis)']\n",
    "            rrms_freq = ms_dx_freq['RRMS (Relapsing-remitting Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            rrms_n = 0\n",
    "            rrms_freq = 0\n",
    "\n",
    "        try: \n",
    "            spms_n = ms_dx_n['SPMS (Secondary-progressive Multiple Sclerosis)']\n",
    "            spms_freq = ms_dx_freq['RRMS (Relapsing-remitting Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            spms_n = 0\n",
    "            spms_freq = 0\n",
    "\n",
    "        try: \n",
    "            ppms_n = ms_dx_n['PPMS (Primary-progressive Multiple Sclerosis)']\n",
    "            ppms_freq = ms_dx_freq['PPMS (Primary-progressive Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            ppms_n = 0\n",
    "            ppms_freq = 0\n",
    "\n",
    "        try: \n",
    "            prms_n = ms_dx_n['PRMS (Progressive-relapsing Multiple Sclerosis)']\n",
    "            prms_freq = ms_dx_freq['PRMS (Progressive-relapsing Multiple Sclerosis)']\n",
    "        except KeyError:\n",
    "            prms_n = 0\n",
    "            prms_freq = 0 \n",
    "\n",
    "        try: \n",
    "            sns_n = ms_dx_n['MS, Subtype Not Specified']\n",
    "            sns_freq = ms_dx_freq['MS, Subtype Not Specified']\n",
    "        except KeyError:\n",
    "            sns_n = 0\n",
    "            sns_freq = 0\n",
    "\n",
    "        try: \n",
    "            pend_n = ms_dx_n['pending']\n",
    "            pend_freq = ms_dx_freq['pending']\n",
    "        except KeyError:\n",
    "            pend_n = 0\n",
    "            pend_freq = 0\n",
    "\n",
    "        try: \n",
    "            abn_n = ms_dx_n['abnormal MRI']\n",
    "            abn_freq = ms_dx_freq['abnormal MRI']\n",
    "        except KeyError:\n",
    "            abn_n = 0\n",
    "            abn_freq = 0\n",
    "\n",
    "\n",
    "        \n",
    "        # summary data \n",
    "        summary_data = {'Metric': ['N', \n",
    "                                      'Age (Years, Mean (SD))',\n",
    "                                      'Sex (Female, n (%))',\n",
    "                                      'EDSS (Median (IQR))', \n",
    "                                      'T25FW (Seconds, Mean (SD))',\n",
    "                                      'Race (n, %)',\n",
    "                                      'White NonHispanic',\n",
    "                                      'Hispanic',\n",
    "                                      'Black',\n",
    "                                      'Asian/PacificIslander/NativeAmerican',\n",
    "                                      'Other/Decline/Unknown',\n",
    "                                      'Disease Duration (Years, Mean (SD))',\n",
    "                                      'MS Subtype (n, %)',\n",
    "                                      'RRMS (Relapsing-remitting Multiple Sclerosis)',\n",
    "                                      'SPMS (Secondary-progressive Multiple Sclerosis)',\n",
    "                                      'PPMS (Primary-progressive Multiple Sclerosis)',\n",
    "                                      'PRMS (Progressive-relapsing Multiple Sclerosis)',\n",
    "                                      'MS, Subtype Not Specified',\n",
    "                                      'pending',\n",
    "                                      'abnormal MRI'],\n",
    "                         'Statistic': [df['bw_id'].nunique(),\n",
    "                                       f\"{age_mean:.2f} ({age_sd:.2f})\",  # Mean (SD)\n",
    "                                       f\"{sex_n_female} ({sex_freq_female:.0f}%)\",\n",
    "                                       f\"{edss_median:.1f} ({edss_iqr:.1f})\", \n",
    "                                       f\"{t25fw_mean:.2f} ({t25fw_sd:.2f})\",\n",
    "                                       np.nan, \n",
    "                                       f\"{white_n} ({white_freq:.0f}%)\",\n",
    "                                       f\"{hispanic_n} ({hispanic_freq:.0f}%)\",\n",
    "                                       f\"{black_n} ({black_freq:.0f}%)\",\n",
    "                                       f\"{asian_n} ({asian_freq:.0f}%)\",\n",
    "                                       f\"{other_n} ({other_freq:.0f}%)\",\n",
    "                                       f\"{duration_mean:.2f} ({duration_sd:.2f})\",  # Mean (SD)\n",
    "                                       np.nan,\n",
    "                                       f\"{rrms_n} ({rrms_freq:.0f}%)\",\n",
    "                                       f\"{spms_n} ({spms_freq:.0f}%)\",\n",
    "                                       f\"{ppms_n} ({ppms_freq:.0f}%)\",\n",
    "                                       f\"{prms_n} ({prms_freq:.0f}%)\",\n",
    "                                       f\"{sns_n} ({sns_freq:.0f}%)\",\n",
    "                                       f\"{pend_n} ({pend_freq:.0f}%)\",\n",
    "                                       f\"{abn_n} ({abn_freq:.0f}%)\"]\n",
    "                       }\n",
    "\n",
    "        demographics_summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "\n",
    "        # counts of participants with demographic data \n",
    "        n_data = {'Metric': ['N', \n",
    "                             'n with age data',\n",
    "                             'n with sex data',\n",
    "                             'n with edss data',\n",
    "                             'n with t25fw data',\n",
    "                             'n with demoEHR_REC_2 data',\n",
    "                             'n with duration data',\n",
    "                             'n with ms subtype data'],\n",
    "                         'Statistic': [df['bw_id'].nunique(),\n",
    "                                       age_count, \n",
    "                                       sex_count, \n",
    "                                       edss_count,\n",
    "                                       t25fw_count, \n",
    "                                       rec_2_count,\n",
    "                                       duration_count,\n",
    "                                       ms_dx_count\n",
    "                                       ]}\n",
    "\n",
    "        n_data_df = pd.DataFrame(n_data) \n",
    "\n",
    "    else: \n",
    "        print('no participants') \n",
    "        demographics_summary_df = pd.DataFrame()\n",
    "        n_data_df = pd.DataFrame()\n",
    "\n",
    "    return demographics_summary_df, n_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd2426-14a5-4f90-a4ab-daed275e01b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# file paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40890f60-e304-4dab-a05e-7ccfea122583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs \n",
    "version = '004'\n",
    "output_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis',\n",
    "                           version,\n",
    "                           'demographics')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaa3544-807f-44fa-86d5-2cca8e81a2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mmccu\\\\Box\\\\MM_Personal\\\\5_Projects\\\\BoveLab\\\\3_Data_and_Code\\\\gait_bw_zeno_home_analysis\\\\004'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input folder \n",
    "input_parent_path = os.path.join(r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_bw_zeno_home_analysis', \n",
    "                                 version) \n",
    "input_parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6accd6b3-ab66-43f3-8698-03b4eebe76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeno videos \n",
    "all_zv_w_bw_path = os.path.join(input_parent_path, \n",
    "                                'video_visit_participant_counts',\n",
    "                                'all_zv_videos_merged_w_bw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a88b722d-ad0d-4f17-a6b9-59c7ccb4ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeno included PWS \n",
    "zv_pws_inclu_w_bw_path = os.path.join(input_parent_path, \n",
    "                                      'zv_bw_merged_gait_vertical_PWS_1.csv') \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75919d1-befb-4b96-9ba0-9dde550716b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all zeno included FW \n",
    "zv_fw_inclu_w_bw_path = os.path.join(input_parent_path, \n",
    "                                      'zv_bw_merged_gait_vertical_FW_1.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db511a8a-7e8c-4b9c-a168-826ee6135155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all bw participants with ms - maybe not using?? \n",
    "# tbd if not all partiicpants approached for home videos \n",
    "bw_path = r'C:\\Users\\mmccu\\AppData\\Local\\Temp\\ccsecure\\2024_10_15_BrainWalk_AllData_Long_MM.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f2742d0-f941-4da9-9e2f-0384dd487ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all participants who sent home videos \n",
    "all_hv_path = os.path.join(input_parent_path, \n",
    "                           'home_feasibility_reliability\\home_vids_all_w_bw.csv') \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c932990-33b9-4a30-9c66-d15c24c46f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home videos included in analysis \n",
    "included_hv_w_bw_path = os.path.join(input_parent_path, 'hv_bw_merged.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0743bbf2-794d-49b4-a6b1-19a0aadb7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants consented to home vids\n",
    "    # need to save (either feas or counting step) - pick which one aligns col names the best \n",
    "redcap_reports_path = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\home_video_feasibility\\2025_01_08 RedCap Reports'\n",
    "consent_base_v1_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_baseline_consent_v1.csv') \n",
    "consent_base_v2_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_baseline_consent_v2.csv') \n",
    "consent_y2_v1_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_year2_consent_v1.csv') \n",
    "consent_y2_v2_path = os.path.join(redcap_reports_path,\n",
    "                                    'homevid_year2_consent_v2.csv') \n",
    "consent_y3_v1_path = os.path.join(redcap_reports_path,\n",
    "                                  'homevid_year3_consent_v1.csv') \n",
    "consent_y3_v2_path = os.path.join(redcap_reports_path,\n",
    "                                  'homevid_year3_consent_v2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3d5410-3fed-4d26-b152-28ee654c0856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participants consented to home vids - format and merge dataframes \n",
    "consent_base_v1_df = pd.read_csv(consent_base_v1_path) \n",
    "consent_base_v2_df = pd.read_csv(consent_base_v2_path)\n",
    "consent_y2_v1_df = pd.read_csv(consent_y2_v1_path)\n",
    "consent_y2_v2_df = pd.read_csv(consent_y2_v2_path)\n",
    "consent_y3_v1_df = pd.read_csv(consent_y3_v1_path)\n",
    "consent_y3_v2_df = pd.read_csv(consent_y3_v2_path) \n",
    "\n",
    "# add consent version column \n",
    "consent_base_v1_df['consent_version'] = 1\n",
    "consent_y2_v1_df['consent_version'] = 1\n",
    "consent_y3_v1_df['consent_version'] = 1\n",
    "\n",
    "consent_base_v2_df['consent_version'] = 2\n",
    "consent_y2_v2_df['consent_version'] = 2\n",
    "consent_y3_v2_df['consent_version']= 2\n",
    "\n",
    "# rename all columns to v1 col names \n",
    "#record_id\tredcap_event_name\tbw_id\tfalls_visit_date\twalking_consent_date\twalking_consent_sig\n",
    "consent_base_v1_df = consent_base_v1_df.rename(columns = {'falls_visit_date' : 'visit_date'}) \n",
    "consent_y2_v1_df = consent_y2_v1_df.rename(columns = {'falls_visit_date' : 'visit_date'})\n",
    "consent_y3_v1_df = consent_y3_v1_df.rename(columns = {'falls_visit_date' : 'visit_date'})\n",
    "\n",
    "\n",
    "consent_base_v2_df = consent_base_v2_df.rename(columns = {'falls_visit_date' : 'visit_date',\n",
    "                                                          'walking_consent_date_v2' : 'walking_consent_date',\n",
    "                                                          'walking_consent_sig_v2' : 'walking_consent_sig'}) \n",
    "consent_y2_v2_df = consent_y2_v2_df.rename(columns = {'falls_visit_date' : 'visit_date',\n",
    "                                                      'walking_consent_date_v2' : 'walking_consent_date',\n",
    "                                                      'walking_consent_sig_v2' : 'walking_consent_sig'}) \n",
    "consent_y3_v2_df = consent_y3_v2_df.rename(columns = {'falls_visit_date' : 'visit_date',\n",
    "                                                      'walking_consent_date_v2' : 'walking_consent_date',\n",
    "                                                      'walking_consent_sig_v2' : 'walking_consent_sig'})\n",
    "\n",
    "# convert to date time \n",
    "consent_base_v1_df['visit_date'] = pd.to_datetime(consent_base_v1_df['visit_date'], errors = 'coerce')\n",
    "consent_y2_v1_df['visit_date'] = pd.to_datetime(consent_y2_v1_df['visit_date'], errors = 'coerce')\n",
    "consent_y3_v1_df['visit_date'] = pd.to_datetime(consent_y3_v1_df['visit_date'], errors = 'coerce')\n",
    "consent_base_v2_df['visit_date'] = pd.to_datetime(consent_base_v2_df['visit_date'], errors = 'coerce')\n",
    "consent_y2_v2_df['visit_date'] = pd.to_datetime(consent_y2_v2_df['visit_date'], errors = 'coerce')\n",
    "consent_y3_v2_df['visit_date'] = pd.to_datetime(consent_y3_v2_df['visit_date'], errors = 'coerce')\n",
    "\n",
    "# concatenate \n",
    "consent_all_df = pd.concat([consent_base_v1_df,\n",
    "                            consent_base_v2_df,\n",
    "                            consent_y2_v1_df,\n",
    "                            consent_y2_v2_df,\n",
    "                            consent_y3_v1_df,\n",
    "                            consent_y3_v2_df])\n",
    "\n",
    "#consent_all_df['visit_date'] = pd.to_datetime(consent_all_df['visit_date'], errors = 'coerce')\n",
    "consent_all_df.to_csv(os.path.join(redcap_reports_path, 'all_home_vid_consent.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f88db-4f77-47db-af67-d7903a45c1b3",
   "metadata": {},
   "source": [
    "# run function on datasets below \n",
    "\n",
    "Save sumamry table - pulling demographic data from first brainwalk visit if participant has multiple visits\n",
    "\n",
    "Zeno \n",
    "1. All participants with videos: MS + HC\n",
    "2. All participants with included videos: MS + HC\n",
    "3. Participants with included PWS videos: MS + HC – is there a diff between groups?\n",
    "4. Participants with included FW videos: MS + HC – is there a diff between groups?\n",
    "\n",
    "Home Videos \n",
    "1. all BW participants with MS (TBD, maybe not all approached) \n",
    "2. All BW participants consented to home vids\n",
    "3. All BW participants who sent home vids\n",
    "4. All BW participants who sent usable/included home vids  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccbab2-2f71-4379-bc33-df86fbc10bae",
   "metadata": {},
   "source": [
    "### Zeno videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740215db-0b09-4260-ad44-ce5604234e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "214\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    173\n",
      "HC     41\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "173\n",
      "MS df count bw_id rows with data\n",
      "173\n",
      "rows in final HC df\n",
      "41\n",
      "HC df count bw_id rows with data\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# all zeno videos \n",
    "all_zv_w_bw_df = pd.read_csv(all_zv_w_bw_path, index_col = 0) \n",
    "\n",
    "all_zv_ms_df, all_zv_hc_df = split_MS_HC_first_visit(all_zv_w_bw_df)\n",
    "\n",
    "all_zv_ms_dem, all_zv_ms_n = demographic_summary(all_zv_ms_df)\n",
    "all_zv_hc_dem, all_zv_hc_n = demographic_summary(all_zv_hc_df)\n",
    "\n",
    "# save outputs \n",
    "all_zv_ms_dem.to_csv(os.path.join(output_path, 'zeno_all_vids_ms_demographics.csv')) \n",
    "all_zv_hc_dem.to_csv(os.path.join(output_path, 'zeno_all_vids_hc_demographics.csv')) \n",
    "\n",
    "all_zv_ms_n.to_csv(os.path.join(output_path, 'zeno_all_vids_ms_counts.csv')) \n",
    "all_zv_hc_n.to_csv(os.path.join(output_path, 'zeno_all_vids_hc_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a4a0801-f8de-48c2-acf2-f4e9b302fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "177\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    144\n",
      "HC     33\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "144\n",
      "MS df count bw_id rows with data\n",
      "144\n",
      "rows in final HC df\n",
      "33\n",
      "HC df count bw_id rows with data\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# all zeno included PWS \n",
    "zv_pws_inclu_w_bw_df = pd.read_csv(zv_pws_inclu_w_bw_path, index_col = 0)\n",
    "\n",
    "# rename columns to align with functions above \n",
    "zv_pws_inclu_w_bw_df = zv_pws_inclu_w_bw_df.rename(columns = {'visit_date_video' : 'video_date'}) \n",
    "\n",
    "# demographics summary \n",
    "zv_pws_inclu_ms_df, zv_pws_inclu_hc_df = split_MS_HC_first_visit(zv_pws_inclu_w_bw_df)\n",
    "\n",
    "zv_pws_inclu_ms_dem, zv_pws_inclu_ms_n = demographic_summary(zv_pws_inclu_ms_df)\n",
    "zv_pws_inclu_hc_dem,  zv_pws_inclu_hc_n = demographic_summary(zv_pws_inclu_hc_df)\n",
    "\n",
    "# save outputs \n",
    "zv_pws_inclu_ms_dem.to_csv(os.path.join(output_path, 'zeno_pws_inclu_ms_demographics.csv')) \n",
    "zv_pws_inclu_hc_dem.to_csv(os.path.join(output_path, 'zeno_pws_inclu_hc_demographics.csv')) \n",
    "\n",
    "zv_pws_inclu_ms_n.to_csv(os.path.join(output_path, 'zeno_pws_inclu_ms_counts.csv')) \n",
    "zv_pws_inclu_hc_n.to_csv(os.path.join(output_path, 'zeno_pws_inclu_hc_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d381ae-b7c6-4cc5-ad76-4fc2b469e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    141\n",
      "HC     35\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "141\n",
      "MS df count bw_id rows with data\n",
      "141\n",
      "rows in final HC df\n",
      "35\n",
      "HC df count bw_id rows with data\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# all Zeno included FW \n",
    "zv_fw_inclu_w_bw_df = pd.read_csv(zv_fw_inclu_w_bw_path, index_col = 0)\n",
    "\n",
    "# rename columns to align with functions above \n",
    "zv_fw_inclu_w_bw_df = zv_fw_inclu_w_bw_df.rename(columns = {'visit_date_video' : 'video_date'}) \n",
    "\n",
    "# demographics summary \n",
    "zv_fw_inclu_ms_df, zv_fw_inclu_hc_df = split_MS_HC_first_visit(zv_fw_inclu_w_bw_df)\n",
    "\n",
    "zv_fw_inclu_ms_dem, zv_fw_inclu_ms_n = demographic_summary(zv_fw_inclu_ms_df)\n",
    "zv_fw_inclu_hc_dem, zv_fw_inclu_hc_n = demographic_summary(zv_fw_inclu_hc_df)\n",
    "\n",
    "# save outputs\n",
    "zv_fw_inclu_ms_dem.to_csv(os.path.join(output_path, 'zeno_fw_inclu_ms_demographics.csv')) \n",
    "zv_fw_inclu_hc_dem.to_csv(os.path.join(output_path, 'zeno_fw_inclu_hc_demographics.csv'))\n",
    "\n",
    "zv_fw_inclu_ms_n.to_csv(os.path.join(output_path, 'zeno_fw_inclu_ms_counts.csv')) \n",
    "zv_fw_inclu_hc_n.to_csv(os.path.join(output_path, 'zeno_fw_inclu_hc_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82a12b1-25e7-4481-94a5-ea368fa653d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "191\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    154\n",
      "HC     37\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "154\n",
      "MS df count bw_id rows with data\n",
      "154\n",
      "rows in final HC df\n",
      "37\n",
      "HC df count bw_id rows with data\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\venv_home_video_analysis_2\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# All participant's included Zeno - merge Zeno FW and PWs \n",
    "zv_all_includ_w_bw_df = pd.concat([zv_pws_inclu_w_bw_df, zv_fw_inclu_w_bw_df])\n",
    "zv_all_includ_w_bw_df = zv_all_includ_w_bw_df.drop_duplicates(keep = 'first')\n",
    "                                                                 \n",
    "# demographics summary \n",
    "zv_all_inclu_ms_df, zv_all_inclu_hc_df = split_MS_HC_first_visit(zv_all_includ_w_bw_df)\n",
    "\n",
    "# demographics\n",
    "zv_all_inclu_ms_dem, zv_all_inclu_ms_n = demographic_summary(zv_all_inclu_ms_df)\n",
    "zv_all_inclu_hc_dem, zv_all_inclu_hc_n = demographic_summary(zv_all_inclu_hc_df)\n",
    "\n",
    "# save outputs \n",
    "zv_all_inclu_ms_dem.to_csv(os.path.join(output_path, 'zeno_all_inclu_ms_demographics.csv')) \n",
    "zv_all_inclu_hc_dem.to_csv(os.path.join(output_path, 'zeno_all_inclu_hc_demographics.csv'))\n",
    "\n",
    "zv_all_inclu_ms_n.to_csv(os.path.join(output_path, 'zeno_all_inclu_ms_counts.csv')) \n",
    "zv_all_inclu_hc_n.to_csv(os.path.join(output_path, 'zeno_all_inclu_hc_counts.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd479a2-8d18-4195-b582-267ba7140f90",
   "metadata": {},
   "source": [
    "### Home Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b996ac54-b12c-4d0f-9b5e-d834fbc3013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "187\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    187\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "187\n",
      "MS df count bw_id rows with data\n",
      "187\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n",
      "no participants\n"
     ]
    }
   ],
   "source": [
    "# all bw participants with ms - maybe not using?? \n",
    "# tbd if not all partiicpants approached for home videos \n",
    "bw_df = pd.read_excel(bw_path, \n",
    "                     index_col = None, \n",
    "                     usecols = ['bw_id', 'record_id', 'visit_date', 'demoEHR_DiseaseDuration',\n",
    "                                'demoEHR_GENDER', 'demoEHR_Age', 'demographic_diagnosis', 'bingoEHR_DX_MS DX', 'demoEHR_REC_1',\t\n",
    "                                'demoEHR_REC_2', 'bingoEHR_EDSS_measure_value', 'msfcEHR_T25FW SPEED AVG']) \n",
    "\n",
    "# only ms participants have sent back videos \n",
    "bw_ms_df = bw_df.loc[bw_df['demographic_diagnosis'] == 'MS']\n",
    "\n",
    "# demographics summary \n",
    "all_bw_ms_df, all_bw_hc_df = split_MS_HC_first_visit(bw_ms_df)\n",
    "\n",
    "all_bw_ms_dem, all_bw_ms_n = demographic_summary(all_bw_ms_df)\n",
    "all_bw_hc_dem, all_bw_hc_n = demographic_summary(all_bw_hc_df)\n",
    "\n",
    "all_bw_ms_dem.to_csv(os.path.join(output_path, 'home_all_bw_ms_demographics.csv')) \n",
    "all_bw_ms_n.to_csv(os.path.join(output_path, 'home_all_bw_ms_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d455004-a033-4970-8bc1-f5c6199bc032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "67\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    67\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "67\n",
      "MS df count bw_id rows with data\n",
      "67\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# participants consented to home videos \n",
    "# merge w bw data \n",
    "consent_all_w_bw_df = consent_all_df.merge(right = bw_df, how = 'left', on = ['bw_id', 'visit_date'])\n",
    "# one mild TBI? \n",
    "consent_all_w_bw_df = consent_all_w_bw_df.loc[consent_all_w_bw_df['demographic_diagnosis'] == 'MS']\n",
    "# two with signed home walking, but no BW ID or demographics \n",
    "consent_all_w_bw_df.dropna(subset=['bw_id'], inplace=True)\n",
    "consent_all_w_bw_df = consent_all_w_bw_df.sort_values(by='bw_id')\n",
    "consent_all_w_bw_df.to_csv(os.path.join(redcap_reports_path, 'all_home_vid_ms_consent_w_bw.csv'))\n",
    "\n",
    "# demographics summary \n",
    "consent_all_ms_df, consent_all_hc_df = split_MS_HC_first_visit(consent_all_w_bw_df)\n",
    "consent_all_ms_dem, consent_all_ms_n = demographic_summary(consent_all_ms_df)\n",
    "\n",
    "consent_all_ms_dem.to_csv(os.path.join(output_path, 'home_consented_ms_demographics.csv'))\n",
    "consent_all_ms_n.to_csv(os.path.join(output_path, 'home_consented_ms_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a45735e-57db-4a3b-bcb1-9c6624ac47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "120\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    120\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "120\n",
      "MS df count bw_id rows with data\n",
      "120\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# participants that did not consent to home videos \n",
    "hv_no_consent_w_bw_df = bw_ms_df.loc[~bw_ms_df['bw_id'].isin(consent_all_w_bw_df['bw_id'])]\n",
    "\n",
    "hv_no_consent_ms_df, hv_no_consent_hc_df = split_MS_HC_first_visit(hv_no_consent_w_bw_df)\n",
    "hv_no_consent_ms_dem, hv_no_consent_ms_n = demographic_summary(hv_no_consent_ms_df)\n",
    "\n",
    "hv_no_consent_ms_dem.to_csv(os.path.join(output_path, 'home_no_consent_ms_demographics.csv'))\n",
    "hv_no_consent_ms_n.to_csv(os.path.join(output_path, 'home_no_consent_ms_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ced32ee-64c6-42d0-8492-e412e5bc24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "35\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    35\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "35\n",
      "MS df count bw_id rows with data\n",
      "35\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# all participants who sent home videos \n",
    "hv_all_vids_df = pd.read_csv(all_hv_path, index_col = 0) \n",
    "\n",
    "# demographics summary \n",
    "hv_all_vids_ms_df, hv_all_vids_hc_df = split_MS_HC_first_visit(hv_all_vids_df)\n",
    "hv_all_vids_ms_dem, hv_all_vids_ms_n  = demographic_summary(hv_all_vids_ms_df)\n",
    "\n",
    "hv_all_vids_ms_dem.to_csv(os.path.join(output_path, 'home_all_vids_ms_demographics.csv')) \n",
    "hv_all_vids_ms_n.to_csv(os.path.join(output_path, 'home_all_vids_ms_counts.csv')) \n",
    "\n",
    "## ISSUE - some participants who sent videos are not included on RedCap consent reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0d0b00f-3a33-4ff6-869e-b0e97bab61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "35\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    35\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "35\n",
      "MS df count bw_id rows with data\n",
      "35\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# participants that consented but did not send videos \n",
    "#ids in consent_all not in  hv_all_vids_df\n",
    "hv_no_vids_sent_df = consent_all_ms_df.loc[~consent_all_ms_df['bw_id'].isin(hv_all_vids_df['bw_id'])]\n",
    "\n",
    "# demographics summary \n",
    "hv_no_vids_sent_ms_df, hv_no_vids_sent_hc_df = split_MS_HC_first_visit(hv_no_vids_sent_df)\n",
    "hv_no_vids_sent_ms_dem, hv_no_vids_sent_ms_n  = demographic_summary(hv_no_vids_sent_ms_df)\n",
    "\n",
    "hv_no_vids_sent_ms_dem.to_csv(os.path.join(output_path, 'home_no_vids_ms_demographics.csv')) \n",
    "hv_no_vids_sent_ms_n.to_csv(os.path.join(output_path, 'home_no_vids_ms_counts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "716639b3-743b-4725-b3f0-e622fccff048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "27\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    27\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "27\n",
      "MS df count bw_id rows with data\n",
      "27\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# videos included in analysis \n",
    "hv_all_inclu_w_bw_df = pd.read_csv(included_hv_w_bw_path, index_col = 0) \n",
    "\n",
    "# demographics summary \n",
    "hv_all_inclu_ms_df, hv_all_inclu_hc_df = split_MS_HC_first_visit(hv_all_inclu_w_bw_df)\n",
    "hv_all_inclu_ms_dem, hv_all_inclu_ms_n = demographic_summary(hv_all_inclu_ms_df)\n",
    "\n",
    "hv_all_inclu_ms_dem.to_csv(os.path.join(output_path, 'home_all_inclu_ms_demographics.csv')) \n",
    "hv_all_inclu_ms_n.to_csv(os.path.join(output_path, 'home_all_inclu_ms_counts.csv')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8dc9e49-736a-4b5e-a4dc-5d585085e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique bw_ids in df\n",
      "8\n",
      "--------------\n",
      "any duplicate bw_ids in first visit df?\n",
      "0\n",
      "--------------\n",
      "df_first_visit demographic diagnosis counts\n",
      "demographic_diagnosis\n",
      "MS    8\n",
      "Name: count, dtype: int64\n",
      "--------------\n",
      "MS and HC rows should match from table above\n",
      "rows in final MS df\n",
      "8\n",
      "MS df count bw_id rows with data\n",
      "8\n",
      "rows in final HC df\n",
      "0\n",
      "HC df count bw_id rows with data\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# participants that sent videos but none were included in analysis \n",
    "#ids in hv_all_vids_df not in  hv_all_inclu_w_bw_df\n",
    "hv_excluded_vids_df = hv_all_vids_df.loc[~hv_all_vids_df['bw_id'].isin(hv_all_inclu_w_bw_df['bw_id'])]\n",
    "\n",
    "# demographics summary \n",
    "hv_excluded_vids_ms_df, hv_excluded_vids_hc_df = split_MS_HC_first_visit(hv_excluded_vids_df)\n",
    "hv_excluded_vids_ms_dem, hv_excluded_vids_ms_n = demographic_summary(hv_excluded_vids_ms_df)\n",
    "\n",
    "hv_excluded_vids_ms_dem.to_csv(os.path.join(output_path, 'home_all_exclu_ms_demographics.csv')) \n",
    "hv_excluded_vids_ms_n.to_csv(os.path.join(output_path, 'home_all_exclu_ms_counts.csv')) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
