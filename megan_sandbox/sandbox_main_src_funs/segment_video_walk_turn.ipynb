{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1008ad-0a3c-46c9-84a5-a84fe766901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment video into times when person is walking away from the camera, toward the camera, and turning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0007de8c-240e-445a-8797-9f60011df0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.signal as sig \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edba6168-959c-4c00-bb0b-6274cf91b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from sandbox src \n",
    "#from frames_to_time import get_frames_per_second\n",
    "#from sandbox_main_src_funs.filtering_functions.filter_single_axis import filter_landmark_single_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d6ac00-662a-430a-91c7-70d7fd867022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually input below if running one video at a time \n",
    "# long term goal - incorporate into pipeline \n",
    "\n",
    "# video file path \n",
    "#vid_in_path = r'..\\..\\tests\\fixtures\\all_videos\\NW_HC_practice videos\\NW_HC_gait_vertical_left.MOV' # vid_in_path set during process_dir() of run.py\n",
    "\n",
    "# run.py outputs\n",
    "#mp_all_filepath = r'..\\..\\temp\\test_sandbox_pipeline_outputs\\002_frames_to_time\\NW_HC_gait_vertical_left_mediapipe_all_sec.csv'\n",
    "#yolo_filepath = r'..\\..\\temp\\test_sandbox_pipeline_outputs\\002_frames_to_time\\NW_HC_gait_vertical_left_yolo_sec.csv' \n",
    "\n",
    "#mp_all_df = pd.read_csv(mp_all_filepath, index_col = 0)\n",
    "#yolo_df = pd.read_csv(yolo_filepath, index_col = 0)\n",
    "\n",
    "# ground truth anotation of turn start and stop time \n",
    "# watch videos frame by frame: e on keyboard = move forward one frame \n",
    "#ground_truth_turn_frames_filepath = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\poseEstimation_practice\\data_example_videos\\visual_annotation_ground_truth\\vertical_turns_start_stop_frame.xlsx'\n",
    "#ground_truth_turn_frames_df = pd.read_excel(ground_truth_turn_frames_filepath, sheet_name = 'Sheet1', engine='openpyxl')\n",
    "\n",
    "#filter ground truth for this specific participant \n",
    "#ground_truth_turn_frames_df  = ground_truth_turn_frames_df.loc[ground_truth_turn_frames_df['filename'] == 'NW_HC_gait_vertical_left', :]\n",
    "#print(ground_truth_turn_frames_df.head())\n",
    "\n",
    "# outputs \n",
    "#output_parent_folder = r'..\\..\\temp\\test_sandbox_pipeline_outputs'\n",
    "\n",
    "# filtering vars \n",
    "#cutoff = 0.4  # Desired cutoff frequency of the filter in Hz\n",
    "#order = 1  # Order of the filter (higher means sharper cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b40750f-1b81-4349-9f5d-404992fef60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_landmark_single_axis(df, landmark, axis_to_filter, video_fps, cutoff_hz, filter_order): \n",
    "    df_landmark = df.loc[df['label'] == landmark]\n",
    "    df_landmark.index = df_landmark['frame'] # set index to frame\n",
    "\n",
    "    # data = series, one landmark and one axis (column) \n",
    "    data = df_landmark[axis_to_filter]\n",
    "       \n",
    "    # Normalized cutoff frequency (cutoff frequency divided by the Nyquist frequency)\n",
    "    nyquist = 0.5 * video_fps\n",
    "    normal_cutoff = cutoff_hz / nyquist\n",
    "\n",
    "    # Design a Butterworth low-pass filter\n",
    "    b, a = sig.butter(filter_order, normal_cutoff, btype='low', analog=False)\n",
    "\n",
    "    # filter data \n",
    "    filtered_data = sig.filtfilt(b, a, data)\n",
    "    filtered_data = pd.Series(filtered_data)\n",
    "    \n",
    "    return ([data, filtered_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c248406-21f0-44d4-82ec-6ba98174c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs \n",
    "def segment_video_walks_turn(mp_all_df, yolo_df, fps, vid_in_path, output_parent_folder, \n",
    "                             cutoff, order, find_peaks_distance, find_peaks_prominence, flattening_point_atol, \n",
    "                             dist_turn_mid_to_flattening): \n",
    "    # -----------------------------------------------------------------------------\n",
    "    # use hip z position to ID start, stop, and midpoint of turns in vertical videos \n",
    "\n",
    "    # filter right and left hip z pose data \n",
    "    [hip_r_mp_z, hip_r_mp_z_filt] = filter_landmark_single_axis(df = mp_all_df, \n",
    "                                                                landmark = 'right_hip',\n",
    "                                                                axis_to_filter = 'Z_pose', \n",
    "                                                                video_fps = fps,\n",
    "                                                                cutoff_hz = cutoff, \n",
    "                                                                filter_order = order)\n",
    "\n",
    "    [hip_l_mp_z, hip_l_mp_z_filt] = filter_landmark_single_axis(df = mp_all_df,\n",
    "                                                                landmark = 'left_hip', \n",
    "                                                                axis_to_filter = 'Z_pose', \n",
    "                                                                video_fps = fps, \n",
    "                                                                cutoff_hz = cutoff, \n",
    "                                                                filter_order = order)\n",
    "    # frames for hip vars \n",
    "    hip_l_mp_z_frames = hip_l_mp_z.index\n",
    "    hip_r_mp_z_frames = hip_r_mp_z.index\n",
    "\n",
    "    # distance between l and r z and smooth\n",
    "    hip_z_diff_mp_filt = hip_l_mp_z_filt - hip_r_mp_z_filt\n",
    "    hip_z_diff_mp_filt = pd.Series(hip_z_diff_mp_filt).rolling(window=15, min_periods=1).mean()\n",
    "    hip_z_diff_mp_filt.index = hip_l_mp_z_frames\n",
    "\n",
    "    # find max and min of hip distance filtered \n",
    "    # max and min = frame of midpoint of turn \n",
    "    hip_z_diff_mp_filt_peak_frames, _ = sig.find_peaks(hip_z_diff_mp_filt, distance = find_peaks_distance, prominence = (find_peaks_prominence, None))\n",
    "    hip_z_diff_mp_filt_peak_frames = hip_z_diff_mp_filt.index[hip_z_diff_mp_filt_peak_frames] # set to index, accounts for missing data where frame doesn't equal row index\n",
    "    hip_z_diff_mp_filt_valley_frames, _ = sig.find_peaks(-hip_z_diff_mp_filt, distance = find_peaks_distance, prominence = (find_peaks_prominence, None))\n",
    "    hip_z_diff_mp_filt_valley_frames = hip_z_diff_mp_filt.index[hip_z_diff_mp_filt_valley_frames]\n",
    "\n",
    "    # merge together peaks and valleys of hip z diff df -> frames of each turn, ordered \n",
    "    hip_z_diff_mp_filt_turn_midpoints = np.concatenate((hip_z_diff_mp_filt_peak_frames, hip_z_diff_mp_filt_valley_frames), axis = None)\n",
    "    hip_z_diff_mp_filt_turn_midpoints = np.sort(hip_z_diff_mp_filt_turn_midpoints)\n",
    "\n",
    "    # rate of change of z hip distance \n",
    "    hip_z_diff_mp_filt_gradient = np.gradient(hip_z_diff_mp_filt)\n",
    "    # make series and set index \n",
    "    hip_z_diff_mp_filt_gradient = pd.Series(hip_z_diff_mp_filt_gradient)\n",
    "    hip_z_diff_mp_filt_gradient.index = hip_l_mp_z_frames\n",
    "\n",
    "    # Identify where the slope is within absolute tolerance value (atol) away from zero \n",
    "    flattening_points = np.where(np.isclose(hip_z_diff_mp_filt_gradient, 0, atol=flattening_point_atol))[0]\n",
    "    flattening_points = hip_z_diff_mp_filt_gradient.index[flattening_points]\n",
    "\n",
    "\n",
    "    # Find first flattening point prior to turn midpoint\n",
    "    turn_start_frames = np.array([], dtype='int16')\n",
    "    for midpoint_i, current_midpoint in enumerate(hip_z_diff_mp_filt_turn_midpoints):\n",
    "        # flattening points that are before current midpoint and at least 10 frames away from midpoint (exclude midpoint itself)\n",
    "        before_peak_flattening_all = flattening_points[(flattening_points < current_midpoint) & (abs(current_midpoint - flattening_points) >= dist_turn_mid_to_flattening)]\n",
    "        # select last element (closest to turn midpoint)\n",
    "        before_peak_flattening_last = before_peak_flattening_all[-1]\n",
    "        # save \n",
    "        turn_start_frames = np.append(turn_start_frames, before_peak_flattening_last)\n",
    "\n",
    "    #Find first flattening point after hip midpoint \n",
    "    turn_stop_frames = np.array([], dtype='int16')\n",
    "    for midpoint_i, current_midpoint in enumerate(hip_z_diff_mp_filt_turn_midpoints):\n",
    "        # flattening points that are after current midpoint and at least 10 frames away from midpoint (exclude midpoint itself)\n",
    "        after_peak_flattening_all = flattening_points[(flattening_points > current_midpoint) & (abs(current_midpoint - flattening_points) >= dist_turn_mid_to_flattening)]\n",
    "        # select first element (closest to turn midpoint)\n",
    "        after_peak_flattening_first = after_peak_flattening_all[0]\n",
    "        # save \n",
    "        turn_stop_frames = np.append(turn_stop_frames, after_peak_flattening_first)\n",
    "\n",
    "    # save all turn info as one df \n",
    "    turn_data = {'turn_num' : np.arange(0, len(hip_z_diff_mp_filt_turn_midpoints), step = 1),\n",
    "                 'turn_start_frame' : turn_start_frames, \n",
    "                 'turn_midpoint' : hip_z_diff_mp_filt_turn_midpoints,\n",
    "                 'turn_stop_frame' : turn_stop_frames,\n",
    "                 'turn_time_frames' : turn_stop_frames - turn_start_frames, \n",
    "                 'turn_time_seconds' : (turn_stop_frames - turn_start_frames) / fps\n",
    "                } \n",
    "\n",
    "    turn_df = pd.DataFrame(turn_data)\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Use distance between shoulders in pixels (yolo) to determine direction subject is moving \n",
    "    # shoulder width increasing = walking toward camera  \n",
    "    #  shoulder width decreasing = walking away from camera\n",
    "    # use start and stop of turns from hip z distance to ID walking times\n",
    "\n",
    "    # create one df for r shoulder, one for l \n",
    "    shoulder_r_yolo_df = yolo_df.loc[(yolo_df['label'] == 'right_shoulder')]\n",
    "    shoulder_r_yolo_df.index = shoulder_r_yolo_df['frame']\n",
    "\n",
    "    shoulder_l_yolo_df = yolo_df.loc[(yolo_df['label'] == 'left_shoulder')]\n",
    "    shoulder_l_yolo_df.index = shoulder_l_yolo_df['frame']\n",
    "\n",
    "    # shoulder width \n",
    "    shoulder_width_yolo = abs(shoulder_r_yolo_df['X'] - shoulder_l_yolo_df['X'])\n",
    "    shoulder_width_yolo_smooth = pd.Series(shoulder_width_yolo).rolling(window=15, min_periods=1).mean()\n",
    "\n",
    "    # frames \n",
    "    frames = shoulder_r_yolo_df['frame']\n",
    "    # walk start - start one second in to account for time for model to fit to person\n",
    "        # start of entire video \n",
    "    first_walk_start_frame = frames[0] \n",
    "    # end of last walk \n",
    "    last_walk_end_frame = frames.iloc[-1]\n",
    "\n",
    "    # create walk_df with start and stop of eaach walk, time per walk, and direction \n",
    "    walks_df = pd.DataFrame(index=range(len(turn_df) + 1), \n",
    "                            columns = ['walk_num', \n",
    "                                       'walk_start_frame', \n",
    "                                       'walk_end_frame', \n",
    "                                       'walk_time_frames', \n",
    "                                       'walk_time_turns', \n",
    "                                       'walk_direction'])\n",
    "\n",
    "    number_of_walks = np.arange(0, len(walks_df), step = 1)\n",
    "\n",
    "    for current_walk_num in number_of_walks: \n",
    "        # walk_num\n",
    "        walks_df.iloc[current_walk_num, 0] = current_walk_num\n",
    "    \n",
    "        #walk_start_frame \n",
    "        # if walk 1 - start = first_walk_start_frame\n",
    "        # all other walks = walk start = end of previous turn \n",
    "        if current_walk_num == 0:\n",
    "            current_walk_start = first_walk_start_frame\n",
    "        else:   \n",
    "            turn_stop_frame = turn_df['turn_stop_frame'] \n",
    "            current_walk_start = turn_stop_frame[current_walk_num - 1]\n",
    "\n",
    "        walks_df.iloc[current_walk_num, 1] = current_walk_start\n",
    "\n",
    "        # walk end frame \n",
    "        # if current walk is the last walk, stop frame = last walk stop \n",
    "        if current_walk_num == max(number_of_walks): \n",
    "             current_walk_stop = last_walk_end_frame\n",
    "        else:\n",
    "            turn_start_frame = turn_df['turn_start_frame'] \n",
    "            current_walk_stop = turn_start_frame[current_walk_num]\n",
    "        \n",
    "        walks_df.iloc[current_walk_num, 2] = current_walk_stop\n",
    "\n",
    "        # walk_time_frames \n",
    "        walks_df.iloc[current_walk_num, 3] = current_walk_stop - current_walk_start\n",
    "\n",
    "        # walk_time_seconds \n",
    "        walks_df.iloc[current_walk_num, 4] = (current_walk_stop - current_walk_start) / fps\n",
    "\n",
    "        # walk direction \n",
    "        # if shoulder width is bigger at walk stop than walk start, person is moving toward camera \n",
    "        if (shoulder_width_yolo_smooth[current_walk_stop] - shoulder_width_yolo_smooth[current_walk_start]) > 0: \n",
    "            walks_df.iloc[current_walk_num, 5] = 'toward'\n",
    "        elif (shoulder_width_yolo_smooth[current_walk_stop] - shoulder_width_yolo_smooth[current_walk_start]) < 0:\n",
    "            walks_df.iloc[current_walk_num, 5] = 'away'\n",
    "\n",
    "    ## plots  -------------------------------------------\n",
    "    # plot #1 - hip and shoulder positions \n",
    "    fig1, (ax1, ax2) = plt.subplots(2)\n",
    "    fig1.suptitle(os.path.splitext(os.path.basename(vid_in_path))[0])\n",
    "\n",
    "    # subplot 1 - mp z for each hip \n",
    "    ax1.plot(hip_r_mp_z_frames, hip_r_mp_z_filt, label = 'r_hip_z_filt', color = 'blue')\n",
    "    ax1.plot(hip_l_mp_z_frames, hip_l_mp_z_filt, label = 'l_hip_z_filt', color = 'red')\n",
    "    ax1.set_ylabel('MP Pose')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # subplot 2 - yolo x for each shoulder \n",
    "    ax2.plot(shoulder_r_yolo_df['frame'], shoulder_r_yolo_df['X'], label = 'r_shoulder_x', color = 'orange')\n",
    "    ax2.plot(shoulder_r_yolo_df['frame'], shoulder_l_yolo_df['X'], label = 'l_shoulder_x', color = 'green')\n",
    "    ax2.set_ylabel('Yolo Pixels')\n",
    "    ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # plot 2 - hip and shoulder dist \n",
    "    # set plot with two subplots \n",
    "    fig2, (ax1, ax2) = plt.subplots(2)\n",
    "    fig2.suptitle(os.path.splitext(os.path.basename(vid_in_path))[0])\n",
    "\n",
    "    # subplot 1 - distance between right and left hip, use peaks and mins as turns \n",
    "    ax1.set_title('Turns')\n",
    "    ax1.plot(hip_z_diff_mp_filt, label = 'l_hip_z_filt - r_hip_z_filt', color = 'black')\n",
    "    ax1.vlines(x = turn_start_frames, ymin = -1, ymax = 1, color = 'green', alpha = 0.5, label = 'turn_start_calculated')\n",
    "    ax1.vlines(x=turn_df['turn_midpoint'], ymin = -1, ymax = 1, color = 'yellow',  alpha = 0.5, label = 'turn_midpoint calculated')\n",
    "    ax1.vlines(x = turn_stop_frames, ymin = -1, ymax = 1, color = 'red', alpha = 0.5,  label = 'turn_stop_calculated')\n",
    "    ax1.set_ylabel('MP Pose')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # sublot 2 - yolo shoulder width \n",
    "    ax2.set_title('Walks')\n",
    "    ax2.plot(shoulder_r_yolo_df['frame'], shoulder_width_yolo_smooth, label = \"shoulder_width, abs, smooth\", color = 'black') \n",
    "    ax2.vlines(x = walks_df['walk_start_frame'], ymin = 0, ymax = 1000, color = 'green', alpha = 0.5, label = 'walk_start_calculated')\n",
    "    ax2.vlines(x = walks_df['walk_end_frame'], ymin = 0, ymax = 1000, color = 'red', alpha = 0.5,  label = 'walk_stop_calculated')\n",
    "    ax2.vlines(x = first_walk_start_frame, ymin = 0, ymax = 1000,  color = 'green', linestyle = '--', label = 'first_walk_start_frame')\n",
    "    ax2.vlines(x = last_walk_end_frame, ymin = 0, ymax = 1000, color = 'red', linestyle = '--', label = 'last_walk_end_frame')\n",
    "    ax2.set_xlabel('Frames')\n",
    "    ax2.set_ylabel('Yolo Pixels')\n",
    "    ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # save outputs ------------  \n",
    "    output_folder = os.path.join(output_parent_folder, '004_segment_towards_away_turn')\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    vid_in_path_no_ext = os.path.splitext(os.path.basename(vid_in_path))[0]\n",
    "\n",
    "    # save plots \n",
    "    # plot 1 \n",
    "    output_plot_1 = os.path.normpath(os.path.join(output_folder, (vid_in_path_no_ext + '_hip_z_mp_shoulder_x_yolo.png')))\n",
    "    fig1.savefig(output_plot_1, bbox_inches = 'tight')\n",
    "\n",
    "    # plot 2 \n",
    "    output_plot_2 = os.path.normpath(os.path.join(output_folder, (vid_in_path_no_ext + '_turn_walk_start_stop.png')))\n",
    "    fig2.savefig(output_plot_2, bbox_inches = 'tight')\n",
    "\n",
    "    # save turn and walk data frames \n",
    "    turn_df_path = os.path.normpath(os.path.join(output_folder, (vid_in_path_no_ext + '_turn_start_stop_frames.csv')))\n",
    "    turn_df.to_csv(turn_df_path)\n",
    "\n",
    "    walk_df_path = os.path.normpath(os.path.join(output_folder, (vid_in_path_no_ext + '_walk_start_stop_frames.csv'))) \n",
    "    walks_df.to_csv(walk_df_path)\n",
    "\n",
    "    # update mp_all_df and yolo_df with turns and \n",
    "    \n",
    "    # outputs \n",
    "    return([turn_df, walks_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ed1c2d-d4f8-47a1-8142-977bbd22b0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook segment_video_walk_turn.ipynb to script\n",
      "[NbConvertApp] Writing 15503 bytes to segment_video_walk_turn.py\n"
     ]
    }
   ],
   "source": [
    "## convert to .py file so functions can be used in other scripts \n",
    "!jupyter nbconvert --to script segment_video_walk_turn.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
