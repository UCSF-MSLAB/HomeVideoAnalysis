{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a878794-1037-4cf6-8c29-3cabd32dd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze raw pose estimation from vertical videos only and get gait metrics\n",
    "\n",
    "# required folder structure of input folder (raw_pose_data_in_path, mirrors video folder structure)\n",
    "# raw_pose_data_in_path\n",
    "    # participant 1\n",
    "        # date \n",
    "            # 000_raw_pose_data (folder containing pose, world, and yolo raw pose data .csv files) \n",
    "    # BW-12 \n",
    "        # 2024-05-02  \n",
    "            # 000_raw_pose_data (folder containing pose, world, and yolo raw pose data .csv files)\n",
    "\n",
    "#  outputs from this analysis script will be saved in the same folder \n",
    "\n",
    "#raw_pose_data_in_path\n",
    "    # participant 1\n",
    "        # date \n",
    "            # 001 analysis results \n",
    "            # 002 analysis results \n",
    "\n",
    "# note! expects only 1 gait_vertical_right and only 1 gait_vertical_left per date folder \n",
    "    # If multiple vertical videos per date, make another date folder (example below)\n",
    "    #  BW-12 \n",
    "        # 2024-05-02-a\n",
    "        # 2024-05-02-b\n",
    "\n",
    "# try for no spaces in folder and file names, but should still work if there are spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceab7caf-76d8-4c08-888f-91ab68c7a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b0c2c0-a0d7-4124-b69d-6b05e0a7d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from sandbox src code files \n",
    "from raw_pose_analysis_funs.merge_mp_yolo_dfs import (merge_mp_pose_world, clean_mp_yolo_missing_data, add_orientation_and_turn_direction, save_merge_mp_yolo_df)\n",
    "\n",
    "from raw_pose_analysis_funs.frames_to_time import (add_time_column, save_df_w_time)\n",
    "\n",
    "from raw_pose_analysis_funs.landmark_visibility import (mp_vis_all_labels_boxplot, mp_vis_lineplot, mp_save_vis_stats_by_label, yolo_vis_lineplot)\n",
    "\n",
    "from raw_pose_analysis_funs.segment_video_walk_turn import (segment_video_interp_filter, segment_video_walks_turn)\n",
    "\n",
    "from raw_pose_analysis_funs.gait_metric_stride_time import(stride_time_interp, calculate_stride_time)\n",
    "\n",
    "from raw_pose_analysis_funs.gait_metric_cadence import (calculate_cadence)\n",
    "from raw_pose_analysis_funs.gait_metric_stride_width import (stride_width_interp, calculate_stride_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c572cbf1-ca14-4276-9694-12bef6455d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables in advance \n",
    "\n",
    "# Set input path to run all analysis \n",
    "# folder with all raw pose data (dir_in_path) \n",
    "raw_pose_data_in_path = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\gait\\gait_hc_outputs\\MM_HC_test_distance'\n",
    "\n",
    "# input variables for segment toward and away functions \n",
    "max_gap = 0.12 # max gap to interpolate over \n",
    "cutoff = 0.4\n",
    "order = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38fc76f-e30d-41ff-81da-726d61cf24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of all csv files in raw pose data folders \n",
    "\n",
    "raw_data_full_path_all = [] \n",
    "raw_data_file_names_all = []\n",
    "\n",
    "# loop through all files in input path \n",
    "for (dir_path, dir_names, file_names) in os.walk(raw_pose_data_in_path):\n",
    "    for file_name in file_names: \n",
    "        name, ext = os.path.splitext(file_name)\n",
    "        ext = ext.lower()[1:]\n",
    "        current_raw_data_in_path = os.path.join(dir_path, file_name) # full path to files \n",
    "        # save full path to file if it meets requirements to be raw pose data \n",
    "        if (ext == 'csv') & ('000_raw_pose_data' in current_raw_data_in_path): # from run.py, outputs all saved in 000_raw_pose_data_folder\n",
    "            raw_data_full_path_all = raw_data_full_path_all + [current_raw_data_in_path]\n",
    "            raw_data_file_names_all = raw_data_file_names_all + [file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162e5f85-a1f2-49f3-b395-8f7e83626308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all unique ID date combos (each unique folder with videos)\n",
    "id_date_all = []\n",
    "for file_i, raw_path in enumerate(raw_data_full_path_all): \n",
    "    parent_path_1, current_file_name = os.path.split(raw_path)\n",
    "    parent_path_2, current_raw_data_folder = os.path.split(parent_path_1)\n",
    "    parent_path_3, current_date = os.path.split(parent_path_2)\n",
    "    parent_path_4, current_id = os.path.split(parent_path_3)\n",
    "    current_id_date = os.path.join(current_id, current_date)\n",
    "    id_date_all = id_date_all + [current_id_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb859306-38f9-4da7-8080-0d57f3bd6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data from: MM_HC_test_distance\\09-12-2024\n",
      "dir_out_prefix: C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\gait\\gait_hc_outputs\\MM_HC_test_distance\\09-12-2024\n",
      "video_id_date_name: MM_HC_test_distance_09-12-2024_gait_vertical_left\n",
      "video_id_date_name: MM_HC_test_distance_09-12-2024_gait_vertical_right\n"
     ]
    }
   ],
   "source": [
    "# for each unique ID and date combo, \n",
    "#select either all gait_vertical_right .csv files or all gait_vertical_left files and run all analysis \n",
    "\n",
    "# all unique ID and date combos of .csv files in raw pose data folder \n",
    "unique_id_date = list(set(id_date_all))\n",
    "unique_id_date = sorted(unique_id_date) # run in same order every time\n",
    "tasks = ['gait_vertical_left', 'gait_vertical_right'] \n",
    "\n",
    "for id_date_i, id_date in enumerate(unique_id_date): \n",
    "    print('Analyzing data from: ' + id_date)\n",
    "    # select raw data paths that match id_date combo \n",
    "    current_id_date_csv_file_paths = [item for item in raw_data_full_path_all if id_date in item]\n",
    "\n",
    "    # set output folder prefix. Find relative paths relative from input folder to raw data .csv \n",
    "    raw_data_relpath = os.path.relpath(current_id_date_csv_file_paths[1], raw_pose_data_in_path)\n",
    "    rel_path_to_date_subfolder, raw_data_subfolder = os.path.split(os.path.dirname(raw_data_relpath))\n",
    "    dir_out_prefix = os.path.normpath(os.path.join(raw_pose_data_in_path, rel_path_to_date_subfolder))\n",
    "    print('dir_out_prefix: ' + dir_out_prefix)\n",
    "    \n",
    "    # select raw data paths that match right or left vertical task \n",
    "    for task_i, task, in enumerate(tasks):  \n",
    "        \n",
    "        # set video ID - ID_date_task (analogous to vid_in_path in run script, use for plot and file names)\n",
    "        video_id_date_name = (id_date + '_' + task).replace('\\\\', '_').replace(' ', '_')\n",
    "        print('video_id_date_name: ' + video_id_date_name)\n",
    "        \n",
    "        # select files matching current task \n",
    "        current_task_csv_paths = [item for item in current_id_date_csv_file_paths if task in item]\n",
    "        \n",
    "        # if files with raw data for this task is saved in subfolder, run analysis  \n",
    "        if len(current_task_csv_paths) == 0: \n",
    "            print('Skipped: no files matching ' + task)\n",
    "        elif len(current_task_csv_paths) > 0:   \n",
    "            \n",
    "            # after selecting for correct task, save each raw data path as own variable \n",
    "            current_yolo_data_path = [item for item in current_task_csv_paths if 'yolo.csv' in item]\n",
    "            current_mp_pose_data_path = [item for item in current_task_csv_paths if 'mediapipe.csv' in item]\n",
    "            current_mp_world_data_path = [item for item in current_task_csv_paths if 'mediapipe_world.csv' in item]\n",
    "            # save video frames per second (fps) file path\n",
    "            current_video_fps_path = [item for item in current_task_csv_paths if 'fps.csv' in item]\n",
    "            \n",
    "            # read in raw pose data, all three types \n",
    "            mp_pose_df = pd.read_csv(current_mp_pose_data_path[0])\n",
    "            mp_world_df = pd.read_csv(current_mp_world_data_path[0])\n",
    "            yolo_df = pd.read_csv(current_yolo_data_path[0])\n",
    "            \n",
    "            # read in frames per seconds and save as var for future code \n",
    "            fps_df = pd.read_csv(current_video_fps_path[0], index_col = 0)\n",
    "            fps = fps_df.iloc[0,0]\n",
    "        \n",
    "            # run analysis functions \n",
    "            # step 001 - save updated .csv files in 001 output folder \n",
    "            [mp_all_df, yolo_df] = merge_mp_pose_world(mp_pose_df, mp_world_df, yolo_df)\n",
    "            [mp_all_df, yolo_df] = clean_mp_yolo_missing_data(mp_all_df, yolo_df)\n",
    "            [mp_all_df, yolo_df] = add_orientation_and_turn_direction(video_id_date_name, mp_all_df, yolo_df) # check vid_in_path \n",
    "            save_merge_mp_yolo_df(mp_all_df, yolo_df, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # 002 frames to time: save .csv file with seconds in 003 output folder \n",
    "            [mp_all_df, yolo_df] = add_time_column(mp_all_df, yolo_df, fps)\n",
    "            save_df_w_time(mp_all_df, yolo_df, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # 003 - plot and save landmark visibility scores for yolo and mediapipe \n",
    "            # yolo \n",
    "            yolo_vis_lineplot(yolo_df, video_id_date_name, dir_out_prefix)\n",
    "            # mediapipe \n",
    "            mp_vis_all_labels_boxplot(mp_all_df, video_id_date_name, dir_out_prefix) \n",
    "            mp_vis_lineplot(mp_all_df, video_id_date_name, dir_out_prefix)\n",
    "            # calculate and save mean, standard deviation, and median visibility for each marker\n",
    "            vis_stats_df = mp_save_vis_stats_by_label(mp_all_df, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # 004 - segment walking toward camera, away from camera, or turning based on hip positions\n",
    "            # interpolate and filter mp hip Z position, L and R \n",
    "            # interpolate yolo hip X position, L and R \n",
    "            [mp_hip_z_filt, yolo_hip_x_interp] = segment_video_interp_filter(mp_all_df,\n",
    "                                                                             yolo_df, \n",
    "                                                                             video_id_date_name, \n",
    "                                                                             dir_out_prefix, \n",
    "                                                                             max_gap, \n",
    "                                                                             fps, \n",
    "                                                                             cutoff, \n",
    "                                                                             order)\n",
    "            # using interpolated and filtered data, ID toward, away, or turn\n",
    "            # save plots and .csv files \n",
    "            [turn_df, walks_df] = segment_video_walks_turn(mp_hip_z_filt, yolo_hip_x_interp, video_id_date_name, dir_out_prefix, fps,\n",
    "                                               find_peaks_distance = 200, # min distance between hip z distance peaks (frames) \n",
    "                                               find_peaks_prominence = 0.2, # hip Z peaks need to be greater than this value to count as a turn\n",
    "                                               flattening_point_atol = 0.0025, # Distance of hip z diff away from zero to be identified as \"flattening point\"\n",
    "                                               dist_turn_mid_to_flattening = 20) # flattening point has to be at least this many frames from turn midpoint\n",
    "\n",
    "            #005 calculate gait metrics \n",
    "            # stride time \n",
    "            mp_ankle_Y_interp = stride_time_interp(mp_all_df,video_id_date_name, dir_out_prefix, max_gap, fps)\n",
    "            [stride_time_stats_df, stride_times_peaks, stride_times_valleys] = calculate_stride_time(mp_ankle_Y_interp, fps, \n",
    "                                                                                                     video_id_date_name, dir_out_prefix,\n",
    "                                                                                                     find_peaks_distance = 5, # min distance between ankle y distance peaks (frames) \n",
    "                                                                                                     find_peaks_prominence = 0.01) # ankle y peaks need to be greater than this value to count as step\n",
    "\n",
    "            # cadence \n",
    "            [total_steps, video_length_sec, cadence] = calculate_cadence(stride_times_peaks, stride_times_valleys, \n",
    "                                                                         fps, mp_all_df, \n",
    "                                                                         video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # stride width \n",
    "            mp_stride_width_interp_dfs = stride_width_interp(mp_all_df, video_id_date_name, dir_out_prefix, max_gap, fps)\n",
    "            stride_width_stats_df = calculate_stride_width(mp_stride_width_interp_dfs, video_id_date_name, dir_out_prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
