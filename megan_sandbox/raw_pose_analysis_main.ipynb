{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a878794-1037-4cf6-8c29-3cabd32dd38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze raw pose estimation from vertical videos only and get gait metrics\n",
    "\n",
    "# required folder structure of input folder (raw_pose_data_in_path, mirrors video folder structure)\n",
    "# raw_pose_data_in_path\n",
    "    # participant 1\n",
    "        # date \n",
    "            # 000_raw_pose_data (folder containing pose, world, and yolo raw pose data .csv files) \n",
    "    # BW-12 \n",
    "        # 2024-05-02  \n",
    "            # 000_raw_pose_data (folder containing pose, world, and yolo raw pose data .csv files)\n",
    "\n",
    "#  outputs from this analysis per patient will be saved in the same folder \n",
    "\n",
    "#raw_pose_data_in_path\n",
    "    # participant 1\n",
    "        # date \n",
    "            # 001 analysis results \n",
    "            # 002 analysis results \n",
    "\n",
    "# .csv for all participants in raw_pose_data_in_path saved as all_participants_pose_metrics_df variable \n",
    "    # save pose metrics from all videos in raw_pose_data_in_path saved as  \n",
    "    # 'all_participants_pose_metrics_df.csv' in raw_pose_data_in_path folder \n",
    "\n",
    "# note! if more than three videos for each task, need to update 'task' variable below to include 'gait_vertical_left_3' etc \n",
    "\n",
    "# try for no spaces in folder and file names, but should still work if there are spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceab7caf-76d8-4c08-888f-91ab68c7a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b0c2c0-a0d7-4124-b69d-6b05e0a7d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from sandbox src code files \n",
    "from raw_pose_analysis_funs.merge_mp_yolo_dfs import (merge_mp_pose_world, clean_mp_yolo_missing_data, add_orientation_and_turn_direction, save_merge_mp_yolo_df)\n",
    "from raw_pose_analysis_funs.frames_to_time import (add_time_column, save_df_w_time)\n",
    "from raw_pose_analysis_funs.landmark_visibility import (mp_vis_all_labels_boxplot, mp_vis_lineplot, mp_save_vis_stats_by_label, yolo_vis_lineplot)\n",
    "from raw_pose_analysis_funs.segment_video_walk_turn import (segment_video_interp_filter, segment_video_walks_turn)\n",
    "from raw_pose_analysis_funs.gait_metric_stride_time import(stride_time_interp, calculate_stride_time)\n",
    "from raw_pose_analysis_funs.gait_metric_cadence import (calculate_cadence)\n",
    "from raw_pose_analysis_funs.gait_metric_stride_width import (stride_width_interp, calculate_stride_width)\n",
    "from raw_pose_analysis_funs.gait_metric_support import (support_interp, ankle_y_vel_accel_peak_min, id_toe_off_heel_strike, calculate_single_double_support)\n",
    "from raw_pose_analysis_funs.gait_metrics_compile_stats import save_all_pose_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c572cbf1-ca14-4276-9694-12bef6455d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables manually  \n",
    "\n",
    "# Set input path to run all analysis \n",
    "# folder with all raw pose data (dir_in_path) \n",
    "raw_pose_data_in_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_hc_outputs'\n",
    "\n",
    "# input variables for interpolation and filtering \n",
    "max_gap = 0.12 # max gap to interpolate over \n",
    "cutoff = 0.4\n",
    "order = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38fc76f-e30d-41ff-81da-726d61cf24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of all csv files in raw pose data folders \n",
    "\n",
    "raw_data_full_path_all = [] \n",
    "raw_data_file_names_all = []\n",
    "\n",
    "# loop through all files in input path \n",
    "for (dir_path, dir_names, file_names) in os.walk(raw_pose_data_in_path):\n",
    "    for file_name in file_names: \n",
    "        name, ext = os.path.splitext(file_name)\n",
    "        ext = ext.lower()[1:]\n",
    "        current_raw_data_in_path = os.path.join(dir_path, file_name) # full path to files \n",
    "        # save full path to file if it meets requirements to be raw pose data \n",
    "        if (ext == 'csv') & ('000_raw_pose_data' in current_raw_data_in_path): # from run.py, outputs all saved in 000_raw_pose_data_folder\n",
    "            raw_data_full_path_all = raw_data_full_path_all + [current_raw_data_in_path]\n",
    "            raw_data_file_names_all = raw_data_file_names_all + [file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162e5f85-a1f2-49f3-b395-8f7e83626308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all unique ID date combos (each unique folder with videos)\n",
    "\n",
    "id_date_all = []\n",
    "for file_i, raw_path in enumerate(raw_data_full_path_all): \n",
    "    parent_path_1, current_file_name = os.path.split(raw_path)\n",
    "    parent_path_2, current_raw_data_folder = os.path.split(parent_path_1)\n",
    "    parent_path_3, current_date = os.path.split(parent_path_2)\n",
    "    parent_path_4, current_id = os.path.split(parent_path_3)\n",
    "    parent_path_5, current_parent_folder = os.path.split(parent_path_4)\n",
    "    current_id_date = os.path.join(current_id, current_date)\n",
    "    id_date_all = id_date_all + [current_id_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5f5382-f155-46ec-9905-8cd5b2364b29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create blank data frame to populate in for loop below \n",
    "all_participants_pose_metrics_df = pd.DataFrame(\n",
    "    columns = ['id_date_pose',\n",
    "               'video_id_date_name_pose', \n",
    "               'task_pose',\n",
    "               'turn_time_mean_sec_pose',\n",
    "               'turn_time_median_sec_pose',\n",
    "               'turn_time_sd_pose', \n",
    "               'turn_time_cv_pose',\n",
    "               'cadence_pose',\n",
    "               'stride_time_leg_1_peaks_mean_sec_pose',\n",
    "               'stride_time_leg_1_peaks_median_sec_pose',\n",
    "               'stride_time_leg_1_peaks_std_pose', \n",
    "               'stride_time_leg_1_peaks_cv_pose',\n",
    "               'stride_time_leg_2_valleys_mean_sec_pose',\n",
    "               'stride_time_leg_2_valleys_median_sec_pose',\n",
    "               'stride_time_leg_2_valleys_std_pose',\n",
    "               'stride_time_leg_2_valleys_cv_pose',\n",
    "               'stride_time_all_strides_mean_sec_pose',\n",
    "               'stride_time_all_strides_median_sec_pose',\n",
    "               'stride_time_all_strides_std_pose',\n",
    "               'stride_time_all_strides_cv_pose',\n",
    "               'stride_width_mean_m_pose', \n",
    "               'stride_width_median_m_pose',\n",
    "               'stride_width_std_pose',\n",
    "               'stride_width_cv_pose',\n",
    "               'right_gait_cycle_time_pose',\n",
    "               'right_stance_time_pose',\n",
    "               'right_stance_per_pose', \n",
    "               'right_swing_time_pose',\n",
    "               'right_swing_per_pose', \n",
    "               'right_ini_double_support_time_pose',\n",
    "               'right_term_double_support_time_pose',\n",
    "               'right_tot_double_support_time_pose',\n",
    "               'right_double_support_per_pose',\n",
    "               'right_single_support_time_pose', \n",
    "               'right_single_support_per_pose',\n",
    "               'left_gait_cycle_time_pose', \n",
    "               'left_stance_time_pose',\n",
    "               'left_stance_per_pose', \n",
    "               'left_swing_time_pose', \n",
    "               'left_swing_per_pose',\n",
    "               'left_ini_double_support_time_pose',\n",
    "               'left_term_double_support_time_pose',\n",
    "               'left_tot_double_support_time_pose',\n",
    "               'left_double_support_per_pose',\n",
    "               'left_single_support_time_pose', \n",
    "               'left_single_support_per_pose'])\n",
    "\n",
    "all_participants_pose_metrics_df = all_participants_pose_metrics_df.dropna(how='all', axis=1)\n",
    "all_participants_pose_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb859306-38f9-4da7-8080-0d57f3bd6536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data from: DS_HC\\2024-05-02\n",
      "dir_out_prefix: C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_hc_outputs\\DS_HC\\2024-05-02\n",
      "video_id_date_name: gait_vertical_left_DS_HC_2024-05-02\n",
      "Skipped: no files matching gait_vertical_left_2\n",
      "Skipped: no files matching gait_vertical_left_3\n",
      "video_id_date_name: gait_vertical_right_DS_HC_2024-05-02\n",
      "Skipped: no files matching gait_vertical_right_2\n",
      "Skipped: no files matching gait_vertical_right_3\n",
      "Skipped: no files matching gait_vertical_PWS_1\n",
      "Skipped: no files matching gait_vertical_PWS_2\n",
      "Skipped: no files matching gait_vertical_FW_1\n",
      "Skipped: no files matching gait_vertical_FW_2\n",
      "Skipped: no files matching gait_vertical_TUG_1\n",
      "Skipped: no files matching gait_vertical_TUG_2\n",
      "Analyzing data from: MM_HC\\2024-07-30\n",
      "dir_out_prefix: C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_hc_outputs\\MM_HC\\2024-07-30\n",
      "Skipped: no files matching gait_vertical_left\n",
      "Skipped: no files matching gait_vertical_left_2\n",
      "Skipped: no files matching gait_vertical_left_3\n",
      "video_id_date_name: MM_HC_17ft_gait_vertical_right_MM_HC_2024-07-30\n",
      "Skipped: no files matching gait_vertical_right_2\n",
      "Skipped: no files matching gait_vertical_right_3\n",
      "Skipped: no files matching gait_vertical_PWS_1\n",
      "Skipped: no files matching gait_vertical_PWS_2\n",
      "Skipped: no files matching gait_vertical_FW_1\n",
      "Skipped: no files matching gait_vertical_FW_2\n",
      "Skipped: no files matching gait_vertical_TUG_1\n",
      "Skipped: no files matching gait_vertical_TUG_2\n",
      "Analyzing data from: NW_HC\\2024-05-02\n",
      "dir_out_prefix: C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_hc_outputs\\NW_HC\\2024-05-02\n",
      "video_id_date_name: gait_vertical_left_NW_HC_2024-05-02\n",
      "Skipped: no files matching gait_vertical_left_2\n",
      "Skipped: no files matching gait_vertical_left_3\n",
      "video_id_date_name: gait_vertical_right_NW_HC_2024-05-02\n",
      "Skipped: no files matching gait_vertical_right_2\n",
      "Skipped: no files matching gait_vertical_right_3\n",
      "Skipped: no files matching gait_vertical_PWS_1\n",
      "Skipped: no files matching gait_vertical_PWS_2\n",
      "Skipped: no files matching gait_vertical_FW_1\n",
      "Skipped: no files matching gait_vertical_FW_2\n",
      "Skipped: no files matching gait_vertical_TUG_1\n",
      "Skipped: no files matching gait_vertical_TUG_2\n",
      "Analyzing data from: RB_HC\\2024-05-02\n",
      "dir_out_prefix: C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\gait_hc_outputs\\RB_HC\\2024-05-02\n",
      "video_id_date_name: gait_vertical_left_RB_HC_2024-05-02\n",
      "Skipped: no files matching gait_vertical_left_2\n",
      "Skipped: no files matching gait_vertical_left_3\n",
      "video_id_date_name: gait_vertical_right_RB_HC_2024-05-02\n",
      "Skipped: no files matching gait_vertical_right_2\n",
      "Skipped: no files matching gait_vertical_right_3\n",
      "Skipped: no files matching gait_vertical_PWS_1\n",
      "Skipped: no files matching gait_vertical_PWS_2\n",
      "Skipped: no files matching gait_vertical_FW_1\n",
      "Skipped: no files matching gait_vertical_FW_2\n",
      "Skipped: no files matching gait_vertical_TUG_1\n",
      "Skipped: no files matching gait_vertical_TUG_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_date_pose</th>\n",
       "      <th>video_id_date_name_pose</th>\n",
       "      <th>task_pose</th>\n",
       "      <th>turn_time_mean_sec_pose</th>\n",
       "      <th>turn_time_median_sec_pose</th>\n",
       "      <th>turn_time_sd_pose</th>\n",
       "      <th>turn_time_cv_pose</th>\n",
       "      <th>cadence_step_per_min_pose</th>\n",
       "      <th>stride_time_leg_1_peaks_mean_sec_pose</th>\n",
       "      <th>stride_time_leg_1_peaks_median_sec_pose</th>\n",
       "      <th>...</th>\n",
       "      <th>left_stance_time_pose</th>\n",
       "      <th>left_stance_per_pose</th>\n",
       "      <th>left_swing_time_pose</th>\n",
       "      <th>left_swing_per_pose</th>\n",
       "      <th>left_ini_double_support_time_pose</th>\n",
       "      <th>left_term_double_support_time_pose</th>\n",
       "      <th>left_tot_double_support_time_pose</th>\n",
       "      <th>left_double_support_per_pose</th>\n",
       "      <th>left_single_support_time_pose</th>\n",
       "      <th>left_single_support_per_pose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DS_HC\\2024-05-02</td>\n",
       "      <td>gait_vertical_left_DS_HC_2024-05-02</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>1.320</td>\n",
       "      <td>1.183</td>\n",
       "      <td>0.435</td>\n",
       "      <td>32.966</td>\n",
       "      <td>107.436</td>\n",
       "      <td>1.111</td>\n",
       "      <td>1.083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>56.250</td>\n",
       "      <td>0.467</td>\n",
       "      <td>43.750</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.183</td>\n",
       "      <td>17.188</td>\n",
       "      <td>0.417</td>\n",
       "      <td>39.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DS_HC\\2024-05-02</td>\n",
       "      <td>gait_vertical_right_DS_HC_2024-05-02</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>1.290</td>\n",
       "      <td>1.367</td>\n",
       "      <td>0.279</td>\n",
       "      <td>21.631</td>\n",
       "      <td>100.155</td>\n",
       "      <td>1.160</td>\n",
       "      <td>1.067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650</td>\n",
       "      <td>61.905</td>\n",
       "      <td>0.400</td>\n",
       "      <td>38.095</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.233</td>\n",
       "      <td>22.222</td>\n",
       "      <td>0.417</td>\n",
       "      <td>39.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MM_HC\\2024-07-30</td>\n",
       "      <td>MM_HC_17ft_gait_vertical_right_MM_HC_2024-07-30</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>2.493</td>\n",
       "      <td>2.533</td>\n",
       "      <td>0.191</td>\n",
       "      <td>7.645</td>\n",
       "      <td>91.954</td>\n",
       "      <td>1.196</td>\n",
       "      <td>1.167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767</td>\n",
       "      <td>65.714</td>\n",
       "      <td>0.400</td>\n",
       "      <td>34.286</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.367</td>\n",
       "      <td>31.429</td>\n",
       "      <td>0.400</td>\n",
       "      <td>34.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NW_HC\\2024-05-02</td>\n",
       "      <td>gait_vertical_left_NW_HC_2024-05-02</td>\n",
       "      <td>gait_vertical_left</td>\n",
       "      <td>1.920</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.601</td>\n",
       "      <td>31.313</td>\n",
       "      <td>91.720</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>64.865</td>\n",
       "      <td>0.433</td>\n",
       "      <td>35.135</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.433</td>\n",
       "      <td>35.135</td>\n",
       "      <td>0.367</td>\n",
       "      <td>29.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NW_HC\\2024-05-02</td>\n",
       "      <td>gait_vertical_right_NW_HC_2024-05-02</td>\n",
       "      <td>gait_vertical_right</td>\n",
       "      <td>2.100</td>\n",
       "      <td>2.217</td>\n",
       "      <td>0.548</td>\n",
       "      <td>26.082</td>\n",
       "      <td>71.354</td>\n",
       "      <td>1.644</td>\n",
       "      <td>1.367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>69.767</td>\n",
       "      <td>0.433</td>\n",
       "      <td>30.233</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.533</td>\n",
       "      <td>37.209</td>\n",
       "      <td>0.467</td>\n",
       "      <td>32.558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_date_pose                          video_id_date_name_pose  \\\n",
       "0  DS_HC\\2024-05-02              gait_vertical_left_DS_HC_2024-05-02   \n",
       "0  DS_HC\\2024-05-02             gait_vertical_right_DS_HC_2024-05-02   \n",
       "0  MM_HC\\2024-07-30  MM_HC_17ft_gait_vertical_right_MM_HC_2024-07-30   \n",
       "0  NW_HC\\2024-05-02              gait_vertical_left_NW_HC_2024-05-02   \n",
       "0  NW_HC\\2024-05-02             gait_vertical_right_NW_HC_2024-05-02   \n",
       "\n",
       "             task_pose  turn_time_mean_sec_pose  turn_time_median_sec_pose  \\\n",
       "0   gait_vertical_left                    1.320                      1.183   \n",
       "0  gait_vertical_right                    1.290                      1.367   \n",
       "0  gait_vertical_right                    2.493                      2.533   \n",
       "0   gait_vertical_left                    1.920                      1.900   \n",
       "0  gait_vertical_right                    2.100                      2.217   \n",
       "\n",
       "   turn_time_sd_pose  turn_time_cv_pose  cadence_step_per_min_pose  \\\n",
       "0              0.435             32.966                    107.436   \n",
       "0              0.279             21.631                    100.155   \n",
       "0              0.191              7.645                     91.954   \n",
       "0              0.601             31.313                     91.720   \n",
       "0              0.548             26.082                     71.354   \n",
       "\n",
       "   stride_time_leg_1_peaks_mean_sec_pose  \\\n",
       "0                                  1.111   \n",
       "0                                  1.160   \n",
       "0                                  1.196   \n",
       "0                                  1.225   \n",
       "0                                  1.644   \n",
       "\n",
       "   stride_time_leg_1_peaks_median_sec_pose  ...  left_stance_time_pose  \\\n",
       "0                                    1.083  ...                  0.600   \n",
       "0                                    1.067  ...                  0.650   \n",
       "0                                    1.167  ...                  0.767   \n",
       "0                                    1.200  ...                  0.800   \n",
       "0                                    1.367  ...                  1.000   \n",
       "\n",
       "   left_stance_per_pose  left_swing_time_pose  left_swing_per_pose  \\\n",
       "0                56.250                 0.467               43.750   \n",
       "0                61.905                 0.400               38.095   \n",
       "0                65.714                 0.400               34.286   \n",
       "0                64.865                 0.433               35.135   \n",
       "0                69.767                 0.433               30.233   \n",
       "\n",
       "   left_ini_double_support_time_pose  left_term_double_support_time_pose  \\\n",
       "0                              0.100                               0.083   \n",
       "0                              0.150                               0.083   \n",
       "0                              0.167                               0.200   \n",
       "0                              0.233                               0.200   \n",
       "0                              0.233                               0.300   \n",
       "\n",
       "   left_tot_double_support_time_pose  left_double_support_per_pose  \\\n",
       "0                              0.183                        17.188   \n",
       "0                              0.233                        22.222   \n",
       "0                              0.367                        31.429   \n",
       "0                              0.433                        35.135   \n",
       "0                              0.533                        37.209   \n",
       "\n",
       "   left_single_support_time_pose  left_single_support_per_pose  \n",
       "0                          0.417                        39.062  \n",
       "0                          0.417                        39.683  \n",
       "0                          0.400                        34.286  \n",
       "0                          0.367                        29.730  \n",
       "0                          0.467                        32.558  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each unique ID and date combo, \n",
    "#select either all gait_vertical_right .csv files or all gait_vertical_left files and run all analysis \n",
    "\n",
    "# all unique ID and date combos of .csv files in raw pose data folder \n",
    "unique_id_date = list(set(id_date_all))\n",
    "unique_id_date = sorted(unique_id_date) # run in same order every time\n",
    "\n",
    "# gait_vertical_left and gait_vertical_right = home videos \n",
    "# PWS, FW, and TUG = in person BW zeno videos \n",
    "tasks = ['gait_vertical_left', \n",
    "         'gait_vertical_left_2', \n",
    "         'gait_vertical_left_3',\n",
    "         'gait_vertical_right', \n",
    "         'gait_vertical_right_2',\n",
    "         'gait_vertical_right_3',\n",
    "         'gait_vertical_PWS_1',\n",
    "         'gait_vertical_PWS_2',\n",
    "         'gait_vertical_FW_1', \n",
    "         'gait_vertical_FW_2',\n",
    "         'gait_vertical_TUG_1',\n",
    "         'gait_vertical_TUG_2'\n",
    "        ] \n",
    "\n",
    "for id_date_i, id_date in enumerate(unique_id_date): \n",
    "    print('Analyzing data from: ' + id_date)\n",
    "    # select raw data paths that match id_date combo \n",
    "    current_id_date_csv_file_paths = [item for item in raw_data_full_path_all if id_date in item]\n",
    "    \n",
    "    # set output folder prefix. Find relative paths relative from input folder to raw data .csv \n",
    "    raw_data_relpath = os.path.relpath(current_id_date_csv_file_paths[1], raw_pose_data_in_path)\n",
    "    rel_path_to_date_subfolder, raw_data_subfolder = os.path.split(os.path.dirname(raw_data_relpath))\n",
    "    dir_out_prefix = os.path.normpath(os.path.join(raw_pose_data_in_path, rel_path_to_date_subfolder))\n",
    "    print('dir_out_prefix: ' + dir_out_prefix)\n",
    "    \n",
    "    # select raw data paths that match right or left vertical task \n",
    "    for task_i, task, in enumerate(tasks):  \n",
    "        \n",
    "        # select files matching current task \n",
    "        current_task_csv_paths = [item for item in current_id_date_csv_file_paths if task in item]\n",
    "        \n",
    "        # if files with raw data for this task is saved in subfolder, run analysis  \n",
    "        if len(current_task_csv_paths) == 0: \n",
    "            print('Skipped: no files matching ' + task)\n",
    "        elif len(current_task_csv_paths) > 0:   \n",
    "            \n",
    "            # after selecting for correct task, save each raw data path as own variable \n",
    "            current_yolo_data_path = [item for item in current_task_csv_paths if 'yolo.csv' in item]\n",
    "            current_mp_pose_data_path = [item for item in current_task_csv_paths if 'mediapipe.csv' in item]\n",
    "            current_mp_world_data_path = [item for item in current_task_csv_paths if 'mediapipe_world.csv' in item]\n",
    "            # save video frames per second (fps) file path\n",
    "            current_video_fps_path = [item for item in current_task_csv_paths if 'fps.csv' in item]\n",
    "            \n",
    "            # read in raw pose data, all three types \n",
    "            mp_pose_df = pd.read_csv(current_mp_pose_data_path[0])\n",
    "            mp_world_df = pd.read_csv(current_mp_world_data_path[0])\n",
    "            yolo_df = pd.read_csv(current_yolo_data_path[0])\n",
    "            \n",
    "            # read in frames per seconds and save as var for future code \n",
    "            fps_df = pd.read_csv(current_video_fps_path[0], index_col = 0)\n",
    "            fps = fps_df.iloc[0,0]\n",
    "\n",
    "            # set video ID - ID_date_task (analogous to vid_in_path in run script, use for plot and file names)\n",
    "            yolo_basename = os.path.splitext(os.path.basename(current_yolo_data_path[0]))[0]\n",
    "            video_id_date_name = (yolo_basename).replace('yolo', id_date).replace('\\\\', '_')\n",
    "            print('video_id_date_name: ' + video_id_date_name)\n",
    "        \n",
    "            # run analysis functions \n",
    "            # step 001 - save updated .csv files in 001 output folder \n",
    "            [mp_all_df, yolo_df] = merge_mp_pose_world(mp_pose_df, mp_world_df, yolo_df)\n",
    "            [mp_all_df, yolo_df] = clean_mp_yolo_missing_data(mp_all_df, yolo_df)\n",
    "            [mp_all_df, yolo_df] = add_orientation_and_turn_direction(video_id_date_name, mp_all_df, yolo_df) # check vid_in_path \n",
    "            save_merge_mp_yolo_df(mp_all_df, yolo_df, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # 002 frames to time: save .csv file with seconds in 003 output folder \n",
    "            [mp_all_df, yolo_df] = add_time_column(mp_all_df, yolo_df, fps)\n",
    "            save_df_w_time(mp_all_df, yolo_df, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # 003 - plot and save landmark visibility scores for yolo and mediapipe \n",
    "            # yolo \n",
    "            yolo_vis_lineplot(yolo_df, video_id_date_name, dir_out_prefix)\n",
    "            # mediapipe \n",
    "            mp_vis_all_labels_boxplot(mp_all_df, video_id_date_name, dir_out_prefix) \n",
    "            mp_vis_lineplot(mp_all_df, video_id_date_name, dir_out_prefix)\n",
    "            # calculate and save mean, standard deviation, and median visibility for each marker\n",
    "            vis_stats_df = mp_save_vis_stats_by_label(mp_all_df, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # 004 - segment walking toward camera, away from camera, or turning based on hip positions\n",
    "            # interpolate and filter mp hip Z position, L and R \n",
    "            # interpolate yolo hip X position, L and R \n",
    "            [mp_hip_z_filt, yolo_hip_x_interp] = segment_video_interp_filter(mp_all_df,\n",
    "                                                                             yolo_df, \n",
    "                                                                             video_id_date_name, \n",
    "                                                                             dir_out_prefix, \n",
    "                                                                             max_gap, \n",
    "                                                                             fps, \n",
    "                                                                             cutoff, \n",
    "                                                                             order)\n",
    "            \n",
    "            # using interpolated and filtered data, ID toward, away, or turn\n",
    "            # save plots and .csv files \n",
    "            [turn_df, walks_df] = segment_video_walks_turn(mp_hip_z_filt, yolo_hip_x_interp, video_id_date_name, dir_out_prefix, fps,\n",
    "                                                           find_peaks_distance = 3 * fps, # min distance between hip z distance peaks (frames) \n",
    "                                                           find_peaks_prominence = 0.2, # hip Z peaks need to be greater than this value to count as a turn\n",
    "                                                           flattening_point_atol = 0.01, # Distance of hip z diff away from zero to be identified as \"flattening point\"\n",
    "                                                           dist_turn_mid_to_flattening = 20, # flattening point has to be at least this many frames from turn midpoint\n",
    "                                                           mean_rolling_window_size = 20)  # smooth curve over this many frames \n",
    "\n",
    "            #005 calculate gait metrics \n",
    "            # stride time \n",
    "            mp_ankle_Y_interp = stride_time_interp(mp_all_df,video_id_date_name, dir_out_prefix, max_gap, fps)\n",
    "            [stride_time_stats_df, stride_times_peaks, stride_times_valleys] = calculate_stride_time(mp_ankle_Y_interp, fps,\n",
    "                                                                                                     video_id_date_name, dir_out_prefix,\n",
    "                                                                                                     rolling_mean_window = round(.5 * fps), \n",
    "                                                                                                     find_peaks_distance = round(.33 * fps), # min distance between ankle y distance peaks (frames) \n",
    "                                                                                                     find_peaks_prominence = 0.01) # ankle y peaks need to be greater than this value to count as step\n",
    "\n",
    "            # cadence \n",
    "            [total_steps, video_length_sec, cadence_df] = calculate_cadence(stride_times_peaks, stride_times_valleys,\n",
    "                                                                         fps, mp_all_df, \n",
    "                                                                         video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # stride width \n",
    "            mp_stride_width_interp_dfs = stride_width_interp(mp_all_df, video_id_date_name, dir_out_prefix, max_gap, fps)\n",
    "            stride_width_stats_df = calculate_stride_width(mp_stride_width_interp_dfs, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # double and single support\n",
    "            # select and interpolate ankle y data \n",
    "            yolo_support_interp_dfs = support_interp(yolo_df, video_id_date_name, dir_out_prefix, max_gap, fps)\n",
    "            right_ankle_y = yolo_support_interp_dfs[0]\n",
    "            left_ankle_y = yolo_support_interp_dfs[1]\n",
    "\n",
    "            # find peaks and min of velocity and acceleration \n",
    "            right_ank_y_data = ankle_y_vel_accel_peak_min(right_ankle_y, \n",
    "                                                          diff_period = round(.167 * fps),  # frames to take diff between for vel + accel\n",
    "                                                          peaks_distance = round(.167 * fps), # min distance between peaks + valleys \n",
    "                                                          peaks_prominence_percent_max = .05, # percent of biggest peak that each peak must be greater than to be identified \n",
    "                                                          valleys_prominence_percent_max = .10) # percent of biggest peak that each valley must be greater than to be identified \n",
    "            left_ank_y_data = ankle_y_vel_accel_peak_min(left_ankle_y, \n",
    "                                                         diff_period = round(.167 * fps),  # frames to take diff between for vel + accel\n",
    "                                                         peaks_distance = round(.167 * fps), # min distance between peaks + valleys \n",
    "                                                         peaks_prominence_percent_max = .05, \n",
    "                                                         valleys_prominence_percent_max = .10)\n",
    "\n",
    "            # get gait events from position, velocity, and acceleration data\n",
    "            toe_off_heel_strike_df = id_toe_off_heel_strike(right_ank_y_data, left_ank_y_data, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # calculate single and double support from toe off and heel strike frames \n",
    "            support_metrics_df = calculate_single_double_support(toe_off_heel_strike_df, fps, video_id_date_name, dir_out_prefix)\n",
    "\n",
    "            # compile all metrics stats for one participant into one .csv and save \n",
    "            pose_metrics_df = save_all_pose_metrics(id_date, video_id_date_name, task, turn_df, cadence_df,\n",
    "                                                     stride_time_stats_df, stride_width_stats_df, \n",
    "                                                     support_metrics_df, dir_out_prefix)\n",
    "\n",
    "            # add this participant to all participants df \n",
    "            all_participants_pose_metrics_df = pd.concat([all_participants_pose_metrics_df, \n",
    "                                                           pose_metrics_df], \n",
    "                                                          axis = 0)\n",
    "\n",
    "\n",
    "all_participants_pose_metrics_df.to_csv(os.path.join(raw_pose_data_in_path, (current_parent_folder + '_pose_metrics_all.csv')))\n",
    "all_participants_pose_metrics_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
