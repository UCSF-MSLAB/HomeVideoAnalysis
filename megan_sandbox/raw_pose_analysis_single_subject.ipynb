{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ad79b49-59de-49f7-bcc9-5fd9ba0a7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07686078-18da-4217-b40d-02206ee3da7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import functions from sandbox src code files \n",
    "from raw_pose_analysis_funs.merge_mp_yolo_dfs import (merge_mp_pose_world, clean_mp_yolo_missing_data, add_orientation_and_turn_direction, save_merge_mp_yolo_df)\n",
    "\n",
    "from raw_pose_analysis_funs.frames_to_time import (get_frames_per_second, add_time_column, save_df_w_time)\n",
    "\n",
    "from raw_pose_analysis_funs.landmark_visibility import (mp_vis_all_labels_boxplot, mp_vis_lineplot, mp_save_vis_stats_by_label, yolo_vis_lineplot)\n",
    "\n",
    "from raw_pose_analysis_funs.segment_video_walk_turn import filter_landmark_single_axis, segment_video_walks_turn\n",
    "\n",
    "from raw_pose_analysis_funs.filter_interpolate_funs import (interpolate_landmark_single_axis, \n",
    "filter_landmark_single_axis) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2851e5-2584-4ebb-b022-3120cc0e2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis functions on one participant at a time \n",
    "\n",
    "# path to video \n",
    "vid_in_path = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\hva_code\\HomeVideoAnalysis\\tests\\fixtures\\all_videos\\RB_HC_practice videos\\RB_HC_gait_vertical_right.MOV' # vid_in_path set during process_dir() of run.py\n",
    "\n",
    "# load mp, mp_world, and yolo .csv files for one video (from main branch, output of home video analysis run.py 8/29/2024)\n",
    "mp_pose_filepath = r'..\\temp\\main_branch_outputs\\000_run\\RB_HC_gait_vertical_right_mediapipe.csv'\n",
    "mp_world_filepath = r'..\\temp\\main_branch_outputs\\000_run\\RB_HC_gait_vertical_right_mediapipe_world.csv'\n",
    "yolo_filepath = r'..\\temp\\main_branch_outputs\\000_run\\RB_HC_gait_vertical_right_yolo.csv'\n",
    "\n",
    "#mp_pose_basename = os.path.splitext(os.path.basename(mp_pose_filepath))[0]\n",
    "mp_all_filepath = mp_pose_basename + '_all.csv'\n",
    "\n",
    "# output folder \n",
    "output_parent_folder = r'..\\temp\\test_sandbox_pipeline_outputs'\n",
    "\n",
    "# read csv \n",
    "mp_pose_df = pd.read_csv(mp_pose_filepath)\n",
    "mp_world_df = pd.read_csv(mp_world_filepath)\n",
    "yolo_df = pd.read_csv(yolo_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e62e399-ab8e-4ca9-aeb2-5765676dcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 001 - merge mp df, add tasks info and negative Y\n",
    "[mp_all_df, yolo_df] = merge_mp_pose_world(mp_pose_df, mp_world_df, yolo_df)\n",
    "[mp_all_df, yolo_df] = clean_mp_yolo_missing_data(mp_all_df, yolo_df)\n",
    "[mp_all_df, yolo_df] = add_orientation_and_turn_direction(vid_in_path, mp_all_df, yolo_df)\n",
    "save_merge_mp_yolo_df(mp_all_df, yolo_df, vid_in_path, output_parent_folder)\n",
    "\n",
    "# outputs \n",
    "# mp_all_df and yolo_df pandas data frames updated and .csv file saved    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd9bd02-f6d1-49fa-bcd5-4b36f4dcf48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 002 - get frames per second and add time column \n",
    "fps = get_frames_per_second(vid_in_path)\n",
    "[mp_all_df, yolo_df] = add_time_column(mp_all_df, yolo_df, fps)\n",
    "save_df_w_time(mp_all_df, yolo_df, vid_in_path, output_parent_folder)\n",
    "# outputs \n",
    "# fps = video frames per second \n",
    "# [mp_all_df, yolo_df]: panda data frames added seconds and .csv file saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24910c35-3bbb-48df-a755-c88581642f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is na: skipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\hva_code\\HomeVideoAnalysis\\megan_sandbox\\sandbox_main_src_funs\\landmark_visibility.py:150: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  vis_stats_df = pd.concat([vis_stats_df, current_vis_stats_row])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip: no_labels_tracked, included in each label\n"
     ]
    }
   ],
   "source": [
    "# step 003 - plot and save landmark visibility scores \n",
    "# yolo \n",
    "yolo_vis_lineplot(yolo_df, vid_in_path, output_parent_folder)\n",
    "\n",
    "# mediapipe \n",
    "# boxplot \n",
    "mp_vis_all_labels_boxplot(mp_all_df, vid_in_path, output_parent_folder)\n",
    "\n",
    "# lineplot \n",
    "mp_vis_lineplot(mp_all_df, vid_in_path, output_parent_folder)\n",
    "\n",
    "# calculate and save vis score per label \n",
    "vis_stats_df = mp_save_vis_stats_by_label(mp_all_df, vid_in_path, output_parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e07652-3daf-40e0-9499-308b94f1c3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Segment turn, toward, or away from camera \n",
    "\n",
    "max_gap = 0.12 # max gap to interpolate over \n",
    "cutoff = 0.4\n",
    "order = 1\n",
    "\n",
    "# MEDIAPIPE HIP DATA \n",
    "# Interpolate \n",
    "r_hip_mp_z_interp_df = interpolate_landmark_single_axis(mp_all_df, # mediapipe data frame \n",
    "                                                       'right_hip', # marker to interpolate \n",
    "                                                       'Z_pose', # axis to interpolate \n",
    "                                                       max_gap, # seconds, maximum gap to interpolate over \n",
    "                                                       fps,\n",
    "                                                       vid_in_path, \n",
    "                                                       output_parent_folder,\n",
    "                                                      mediapipe_or_yolo = 'mediapipe')\n",
    "\n",
    "l_hip_mp_z_interp_df = interpolate_landmark_single_axis(mp_all_df, # mediapipe data frame \n",
    "                                                       'left_hip', # marker to interpolate \n",
    "                                                       'Z_pose', # axis to interpolate \n",
    "                                                       max_gap, # seconds, maximum gap to interpolate over \n",
    "                                                       fps,\n",
    "                                                       vid_in_path, \n",
    "                                                       output_parent_folder, \n",
    "                                                      mediapipe_or_yolo = 'mediapipe')\n",
    "\n",
    "# filter \n",
    "r_hip_mp_z_interp_filt = filter_landmark_single_axis(r_hip_mp_z_interp_df.iloc[:, 2],  # one series, position data from one axis of one landmark\n",
    "                                                  fps, # video HZ\n",
    "                                                  cutoff, # filter cutoff \n",
    "                                                  order, # butterworth filter order\n",
    "                                                  vid_in_path,\n",
    "                                                  output_parent_folder\n",
    "                                                  )\n",
    "\n",
    "l_hip_mp_z_interp_filt = filter_landmark_single_axis(l_hip_mp_z_interp_df.iloc[:, 2],  # one series, position data from one axis of one landmark\n",
    "                                                  fps, # video HZ\n",
    "                                                  cutoff, # filter cutoff \n",
    "                                                  order, # butterworth filter order\n",
    "                                                  vid_in_path,\n",
    "                                                  output_parent_folder\n",
    "                                                  )\n",
    "\n",
    "# YOLO HIP DATA \n",
    "# interpolate  \n",
    "r_hip_yolo_z_interp_df = interpolate_landmark_single_axis(yolo_df, # mediapipe data frame \n",
    "                                                       'right_hip', # marker to interpolate \n",
    "                                                       'X_yolo', # axis to interpolate \n",
    "                                                       max_gap, # seconds, maximum gap to interpolate over \n",
    "                                                       fps,\n",
    "                                                       vid_in_path, \n",
    "                                                       output_parent_folder,\n",
    "                                                      mediapipe_or_yolo = 'yolo')\n",
    "\n",
    "l_hip_yolo_z_interp_df = interpolate_landmark_single_axis(yolo_df, # mediapipe data frame \n",
    "                                                       'left_hip', # marker to interpolate \n",
    "                                                       'X_yolo', # axis to interpolate \n",
    "                                                       max_gap, # seconds, maximum gap to interpolate over \n",
    "                                                       fps,\n",
    "                                                       vid_in_path, \n",
    "                                                       output_parent_folder,\n",
    "                                                       mediapipe_or_yolo = 'yolo')\n",
    "\n",
    "# filter \n",
    "\n",
    "\n",
    "# segment code - filter MP, interpolated df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
