{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee1f5547-2a58-433a-beee-962a08691d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# follows gait_events_vertical script, use same df and structure \n",
    "# segment toward away from camera against ground truth from visual annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15484234-6405-4604-bdd6-51d267b758f5",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.signal as sig \n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e87a1-a314-4bd9-9f54-3e6591e41e20",
   "metadata": {},
   "source": [
    "### To - do \n",
    "update so these functions and relative file paths work in this folder. Original script in sandbox source functions folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1c638-9e8f-409f-a948-ac20519bd035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions from sandbox src \n",
    "# need to fix folder paths \n",
    "from frames_to_time import get_frames_per_second\n",
    "from filtering_funs import filter_landmark_single_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaac6ae-a634-4e6f-89aa-96be2ed28d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually input below if running one video at a time \n",
    "# long term goal - incorporate into pipeline \n",
    "\n",
    "# video file path \n",
    "vid_in_path = r'..\\..\\tests\\fixtures\\all_videos\\NW_HC_practice videos\\NW_HC_gait_vertical_left.MOV' # vid_in_path set during process_dir() of run.py\n",
    "\n",
    "# run.py outputs\n",
    "mp_all_filepath = r'..\\..\\temp\\test_sandbox_pipeline_outputs\\002_frames_to_time\\NW_HC_gait_vertical_left_mediapipe_all_sec.csv'\n",
    "yolo_filepath = r'..\\..\\temp\\test_sandbox_pipeline_outputs\\002_frames_to_time\\NW_HC_gait_vertical_left_yolo_sec.csv' \n",
    "\n",
    "mp_all_df = pd.read_csv(mp_all_filepath, index_col = 0)\n",
    "yolo_df = pd.read_csv(yolo_filepath, index_col = 0)\n",
    "\n",
    "# ground truth anotation of turn start and stop time \n",
    "# watch videos frame by frame: e on keyboard = move forward one frame \n",
    "ground_truth_turn_frames_filepath = r'C:\\Users\\mmccu\\Box\\MM_Personal\\5_Projects\\BoveLab\\3_Data_and_Code\\poseEstimation_practice\\data_example_videos\\visual_annotation_ground_truth\\vertical_turns_start_stop_frame.xlsx'\n",
    "ground_truth_turn_frames_df = pd.read_excel(ground_truth_turn_frames_filepath, sheet_name = 'Sheet1', engine='openpyxl')\n",
    "\n",
    "#filter ground truth for this specific participant \n",
    "ground_truth_turn_frames_df  = ground_truth_turn_frames_df.loc[ground_truth_turn_frames_df['filename'] == 'NW_HC_gait_vertical_left', :]\n",
    "print(ground_truth_turn_frames_df.head())\n",
    "\n",
    "# outputs \n",
    "output_parent_folder = r'..\\..\\temp\\test_sandbox_pipeline_outputs'\n",
    "\n",
    "# filtering vars \n",
    "cutoff = 0.4  # Desired cutoff frequency of the filter in Hz\n",
    "order = 1  # Order of the filter (higher means sharper cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e15852-78b3-47fe-a83d-661f22b70af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## save fps variable \n",
    "fps = get_frames_per_second(vid_in_path)\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed549a20-cebb-4c7d-9ffa-72468ad19b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use hip z position to ID start, stop, and midpoint of turns in vertical videos \n",
    "\n",
    "# filter right and left hip z pose data \n",
    "[hip_r_mp_z, hip_r_mp_z_filt] = filter_landmark_single_axis(df = mp_all_df, \n",
    "                                                              landmark = 'right_hip', \n",
    "                                                              axis_to_filter = 'Z_pose', \n",
    "                                                              video_fps = fps, \n",
    "                                                              cutoff_hz = cutoff, \n",
    "                                                              filter_order = order)\n",
    "\n",
    "[hip_l_mp_z, hip_l_mp_z_filt] = filter_landmark_single_axis(df = mp_all_df, \n",
    "                                                              landmark = 'left_hip', \n",
    "                                                              axis_to_filter = 'Z_pose', \n",
    "                                                              video_fps = fps, \n",
    "                                                              cutoff_hz = cutoff, \n",
    "                                                              filter_order = order)\n",
    "\n",
    "# frames for hip vars \n",
    "hip_l_mp_z_frames = hip_l_mp_z.index\n",
    "hip_r_mp_z_frames = hip_r_mp_z.index\n",
    "\n",
    "# distance between l and r z \n",
    "hip_z_diff_mp_filt = hip_l_mp_z_filt - hip_r_mp_z_filt\n",
    "hip_z_diff_mp_filt = pd.Series(hip_z_diff_mp_filt).rolling(window=15, min_periods=1).mean()\n",
    "hip_z_diff_mp_filt.index = hip_l_mp_z_frames\n",
    "\n",
    "# find max and min of hip distance filtered \n",
    "    # max and min = frame of midpoint of turn \n",
    "hip_z_diff_mp_filt_peak_frames, _ = sig.find_peaks(hip_z_diff_mp_filt, distance = 200, prominence = (0.2, None))\n",
    "hip_z_diff_mp_filt_peak_frames = hip_z_diff_mp_filt.index[hip_z_diff_mp_filt_peak_frames] # set to index, accounts for missing data where frame doesn't equal row index\n",
    "hip_z_diff_mp_filt_valley_frames, _ = sig.find_peaks(-hip_z_diff_mp_filt, distance = 200, prominence = (0.2, None))\n",
    "hip_z_diff_mp_filt_valley_frames = hip_z_diff_mp_filt.index[hip_z_diff_mp_filt_valley_frames]\n",
    "\n",
    "# merge together peaks and valleys of hip z diff df -> frames of each turn, ordered \n",
    "hip_z_diff_mp_filt_turn_midpoints = np.concatenate((hip_z_diff_mp_filt_peak_frames, hip_z_diff_mp_filt_valley_frames), axis = None)\n",
    "hip_z_diff_mp_filt_turn_midpoints = np.sort(hip_z_diff_mp_filt_turn_midpoints)\n",
    "\n",
    "# rate of change of z hip distance \n",
    "hip_z_diff_mp_filt_gradient = np.gradient(hip_z_diff_mp_filt)\n",
    "# make series and set index \n",
    "hip_z_diff_mp_filt_gradient = pd.Series(hip_z_diff_mp_filt_gradient)\n",
    "hip_z_diff_mp_filt_gradient.index = hip_l_mp_z_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1c530-9522-4c51-a8b6-52ee887274f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new approach: find where local min and max of hip_z_diff_mp_filt start and flatten out \n",
    "\n",
    "#def adfs(make atol variable to enter)\n",
    "\n",
    "# Identify where the slope is within absolute tolerance value (atol) away from zero \n",
    "flattening_points = np.where(np.isclose(hip_z_diff_mp_filt_gradient, 0, atol=0.0025))[0]\n",
    "flattening_points = hip_z_diff_mp_filt_gradient.index[flattening_points]\n",
    "\n",
    "\n",
    "# Find first flattening point prior to turn midpoint\n",
    "turn_start_frames = np.array([], dtype='int16')\n",
    "for midpoint_i, current_midpoint in enumerate(hip_z_diff_mp_filt_turn_midpoints):\n",
    "    # flattening points that are before current midpoint and at least 10 frames away from midpoint (exclude midpoint itself)\n",
    "    before_peak_flattening_all = flattening_points[(flattening_points < current_midpoint) & (abs(current_midpoint - flattening_points) >= 20)]\n",
    "    # select last element (closest to turn midpoint)\n",
    "    before_peak_flattening_last = before_peak_flattening_all[-1]\n",
    "    # save \n",
    "    turn_start_frames = np.append(turn_start_frames, before_peak_flattening_last)\n",
    "\n",
    "#Find first flattening point after hip midpoint \n",
    "turn_stop_frames = np.array([], dtype='int16')\n",
    "for midpoint_i, current_midpoint in enumerate(hip_z_diff_mp_filt_turn_midpoints):\n",
    "    # flattening points that are after current midpoint and at least 10 frames away from midpoint (exclude midpoint itself)\n",
    "    after_peak_flattening_all = flattening_points[(flattening_points > current_midpoint) & (abs(current_midpoint - flattening_points) >= 20)]\n",
    "    # select first element (closest to turn midpoint)\n",
    "    after_peak_flattening_first = after_peak_flattening_all[0]\n",
    "    # save \n",
    "    turn_stop_frames = np.append(turn_stop_frames, after_peak_flattening_first)\n",
    "\n",
    "# save all turn info as one df \n",
    "turn_data = {'turn_num' : np.arange(0, len(hip_z_diff_mp_filt_turn_midpoints), step = 1), \n",
    "             'turn_start_frame' : turn_start_frames, \n",
    "             'turn_midpoint' : hip_z_diff_mp_filt_turn_midpoints,\n",
    "             'turn_stop_frame' : turn_stop_frames,\n",
    "             'turn_time_frames' : turn_stop_frames - turn_start_frames, \n",
    "             'turn_time_seconds' : (turn_stop_frames - turn_start_frames) / fps\n",
    "            } \n",
    "\n",
    "turn_df = pd.DataFrame(turn_data)\n",
    "turn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdafbc9-4376-4caf-a967-aa147a372910",
   "metadata": {},
   "outputs": [],
   "source": [
    " # -----------------------------------------------------------------------------\n",
    "# Use distance between shoulders in pixels (yolo) to determine direction subject is moving \n",
    "# shoulder width increasing = walking toward camera  \n",
    "#  shoulder width decreasing = walking away from camera\n",
    "# use start and stop of turns from hip z distance to ID walking times\n",
    "\n",
    " # create one df for r shoulder, one for l \n",
    "shoulder_r_yolo_df = yolo_df.loc[(yolo_df['label'] == 'right_shoulder')]\n",
    "shoulder_r_yolo_df.index = shoulder_r_yolo_df['frame']\n",
    "\n",
    "shoulder_l_yolo_df = yolo_df.loc[(yolo_df['label'] == 'left_shoulder')]\n",
    "shoulder_l_yolo_df.index = shoulder_l_yolo_df['frame']\n",
    "\n",
    "# shoulder width \n",
    "shoulder_width_yolo = abs(shoulder_r_yolo_df['X'] - shoulder_l_yolo_df['X'])\n",
    "shoulder_width_yolo_smooth = pd.Series(shoulder_width_yolo).rolling(window=15, min_periods=1).mean()\n",
    "\n",
    "# frames \n",
    "frames = shoulder_r_yolo_df['frame']\n",
    "# walk start - start one second in to account for time for model to fit to person\n",
    "        # start of entire video \n",
    "first_walk_start_frame = frames[0] \n",
    " # end of last walk \n",
    "last_walk_end_frame = frames.iloc[-1]\n",
    "\n",
    "# create walk_df with start and stop of eaach walk, time per walk, and direction \n",
    "walks_df = pd.DataFrame(index=range(len(turn_df) + 1), \n",
    "                        columns = ['walk_num', \n",
    "                                    'walk_start_frame', \n",
    "                                    'walk_end_frame', \n",
    "                                    'walk_time_frames', \n",
    "                                    'walk_time_turns', \n",
    "                                    'walk_direction'])\n",
    "\n",
    "number_of_walks = np.arange(0, len(walks_df), step = 1)\n",
    "\n",
    "for current_walk_num in number_of_walks: \n",
    "    print(current_walk_num)\n",
    "    # walk_num\n",
    "    walks_df.iloc[current_walk_num, 0] = current_walk_num\n",
    "    \n",
    "    #walk_start_frame \n",
    "    # if walk 1 - start = first_walk_start_frame\n",
    "    # all other walks = walk start = end of previous turn \n",
    "    if current_walk_num == 0:\n",
    "        current_walk_start = first_walk_start_frame\n",
    "    else:   \n",
    "        turn_stop_frame = turn_df['turn_stop_frame'] \n",
    "        current_walk_start = turn_stop_frame[current_walk_num - 1]\n",
    "\n",
    "    walks_df.iloc[current_walk_num, 1] = current_walk_start\n",
    "\n",
    "    # walk end frame \n",
    "    # if current walk is the last walk, stop frame = last walk stop \n",
    "    if current_walk_num == max(number_of_walks): \n",
    "            current_walk_stop = last_walk_end_frame\n",
    "    else:\n",
    "        turn_start_frame = turn_df['turn_start_frame'] \n",
    "        current_walk_stop = turn_start_frame[current_walk_num]\n",
    "        \n",
    "    walks_df.iloc[current_walk_num, 2] = current_walk_stop\n",
    "\n",
    "    # walk_time_frames \n",
    "    walks_df.iloc[current_walk_num, 3] = current_walk_stop - current_walk_start\n",
    "\n",
    "    # walk_time_seconds \n",
    "    walks_df.iloc[current_walk_num, 4] = (current_walk_stop - current_walk_start) / fps\n",
    "\n",
    "    # walk direction \n",
    "    # if shoulder width is bigger at walk stop than walk start, person is moving toward camera \n",
    "    if (shoulder_width_yolo_smooth[current_walk_stop] - shoulder_width_yolo_smooth[current_walk_start]) > 0: \n",
    "        walks_df.iloc[current_walk_num, 5] = 'toward'\n",
    "    elif (shoulder_width_yolo_smooth[current_walk_stop] - shoulder_width_yolo_smooth[current_walk_start]) < 0:\n",
    "        walks_df.iloc[current_walk_num, 5] = 'away'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953e053-1a09-4158-b03b-0fdc89a0700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots of hip and shoulder positions \n",
    "\n",
    "# set plot with two subplots \n",
    "fig1, (ax1, ax2) = plt.subplots(2)\n",
    "fig1.suptitle(os.path.splitext(os.path.basename(vid_in_path))[0])\n",
    "\n",
    "# subplot 1 - mp z for each hip \n",
    "ax1.plot(hip_r_mp_z_frames, hip_r_mp_z_filt, label = 'r_hip_z_filt', color = 'blue')\n",
    "ax1.plot(hip_l_mp_z_frames, hip_l_mp_z_filt, label = 'l_hip_z_filt', color = 'red')\n",
    "ax1.set_ylabel('MP Pose')\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# subplot 2 - yolo x for each shoulder \n",
    "ax2.plot(shoulder_r_yolo_df['frame'], shoulder_r_yolo_df['X'], label = 'r_shoulder_x', color = 'orange')\n",
    "ax2.plot(shoulder_r_yolo_df['frame'], shoulder_l_yolo_df['X'], label = 'l_shoulder_x', color = 'green')\n",
    "ax2.set_ylabel('Yolo Pixels')\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c2b5b-32db-43f7-bf5c-c443145f3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2 \n",
    "# set plot with two subplots \n",
    "fig2, (ax1, ax2) = plt.subplots(2)\n",
    "fig2.suptitle(os.path.splitext(os.path.basename(vid_in_path))[0])\n",
    "\n",
    "# subplot 1 - distance between right and left hip, use peaks and mins as turns \n",
    "ax1.set_title('Turns')\n",
    "ax1.plot(hip_z_diff_mp_filt, label = 'l_hip_z_filt - r_hip_z_filt', color = 'black')\n",
    "ax1.vlines(x = ground_truth_turn_frames_df['start_frame'],  ymin = -1, ymax = 1, linestyle = '--', color = 'black', alpha = 0.5, label = 'turn_stop_frame ground truth')\n",
    "ax1.vlines(x = ground_truth_turn_frames_df['stop_frame'], ymin = -1, ymax = 1, linestyle = 'dotted', color = 'black', alpha = 0.5,label = 'turn_start_frame ground truth')\n",
    "ax1.vlines(x = turn_start_frames, ymin = -1, ymax = 1, color = 'green', alpha = 0.5, label = 'turn_start_calculated')\n",
    "ax1.vlines(x=turn_df['turn_midpoint'], ymin = -1, ymax = 1, color = 'yellow',  alpha = 0.5, label = 'turn_midpoint calculated')\n",
    "ax1.vlines(x = turn_stop_frames, ymin = -1, ymax = 1, color = 'red', alpha = 0.5,  label = 'turn_stop_calculated')\n",
    "ax1.set_ylabel('MP Pose')\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# sublot 2 - yolo shoulder width \n",
    "ax2.set_title('Walks')\n",
    "ax2.plot(shoulder_r_yolo_df['frame'], shoulder_width_yolo_smooth, label = \"shoulder_width, abs, smooth\", color = 'black') \n",
    "ax2.vlines(x = walks_df['walk_start_frame'], ymin = 0, ymax = 1000, color = 'green', alpha = 0.5, label = 'walk_start_calculated')\n",
    "ax2.vlines(x = walks_df['walk_end_frame'], ymin = 0, ymax = 1000, color = 'red', alpha = 0.5,  label = 'walk_stop_calculated')\n",
    "ax2.vlines(x = first_walk_start_frame, ymin = 0, ymax = 1000,  color = 'green', linestyle = '--', label = 'first_walk_start_frame')\n",
    "ax2.vlines(x = last_walk_end_frame, ymin = 0, ymax = 1000, color = 'red', linestyle = '--', label = 'last_walk_end_frame')\n",
    "ax2.set_xlabel('Frames')\n",
    "ax2.set_ylabel('Yolo Pixels')\n",
    "ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7f943-7e9c-4e9b-9e2d-e894e284a4d3",
   "metadata": {},
   "source": [
    "## To-do \n",
    "save dfs as .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c97a33-ad88-46fd-bf55-0909939cc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs \n",
    "    # save plot \n",
    "    # add column - away 1, turn 1, toward 1, away 2 \n",
    "    # save df (and as .csv) with frames at which events occur (ie - columns: away_1_start, away_1_stop, turn_1 start, turn_1_stop, etc) \n",
    "    # save time of each walk, time per turn, etc \n",
    "\n",
    "output_folder = os.path.join(output_parent_folder, '004_segment_towards_away_turn')\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "vid_in_path_no_ext = os.path.splitext(os.path.basename(vid_in_path))[0]\n",
    "\n",
    "# save turn_df as .csv \n",
    "\n",
    "# save walk_df as .csv \n",
    "\n",
    "# save plots\n",
    "# plot 1 \n",
    "output_plot_1 = os.path.normpath(os.path.join(output_folder, (vid_in_path_no_ext + '_hip_z_mp_shoulder_x_yolo.png')))\n",
    "fig1.savefig(output_plot_1, bbox_inches = 'tight')\n",
    "\n",
    "# plot 2 \n",
    "output_plot_2 = os.path.normpath(os.path.join(output_folder, (vid_in_path_no_ext + '_turn_walk_start_stop.png')))\n",
    "fig2.savefig(output_plot_2, bbox_inches = 'tight')\n",
    "\n",
    "# save mp_all_df and yolo_df\n",
    "\n",
    "# save filtering and atol values "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
