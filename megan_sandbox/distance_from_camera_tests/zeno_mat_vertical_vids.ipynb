{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8010034-9ea7-4cdd-a362-920c6f81c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7dbc7a-863a-4efb-86ba-61a46dcd21bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input \n",
    "\n",
    "# ground truth data with frames when person was at each end of mat, contains path to yolo data and measured distances \n",
    "ground_truth_path = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\gait\\gait_hc_videos\\MM_HC_test_distance\\frames_at_end_of_mat_manual.xlsx'\n",
    "ground_truth_df = pd.read_excel(ground_truth_path, sheet_name = 'Sheet1', engine='openpyxl')\n",
    "\n",
    "# output \n",
    "output_folder = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\gait\\gait_hc_outputs\\MM_HC_test_distance\\distance_to_camera'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b528f46f-6bf4-4a78-a1f6-cace2ba5c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stenum paper formula \n",
    "# delta_d: depth change of the torso relative to the initial starting depth \n",
    "# s_ratio = ratio of current pixel torso size relative to the pixel size or torso at reference depth (current pixel height / reference pixel height)\n",
    "# d_ref = initial reference depth of person relative to the frontal camera position\n",
    "\n",
    "# s_ratio = s_i (current pixel height) / s_ref (pixel height at ref distance) \n",
    "# delta_d = (d_ref/s_ratio) - d_ref "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f057a1c6-e49b-4814-8aff-82b4441f735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric options for s_ratio \n",
    "    # options - height (neck to shoulder), width (r vs l shoulder), torso area (square root of product of torso ehgith and shoulder width)\n",
    "\n",
    "# starting with torso height - with turn, width may be inaccurate \n",
    "# frame ref = reference distance frame \n",
    "# frame_i = current frame \n",
    "def calculate_torso_height_ratio(yolo_df, frame_ref, frame_i, fps, video_name):\n",
    "    yolo_r_shoulder = yolo_df.loc[yolo_df['label'] == 'right_shoulder']\n",
    "    yolo_r_shoulder.index = yolo_r_shoulder['frame']\n",
    "    yolo_l_shoulder = yolo_df.loc[yolo_df['label'] == 'left_shoulder']\n",
    "    yolo_l_shoulder.index = yolo_l_shoulder['frame']\n",
    "    yolo_r_hip = yolo_df.loc[yolo_df['label'] == 'right_hip']\n",
    "    yolo_r_hip.index = yolo_r_hip['frame']\n",
    "    yolo_l_hip = yolo_df.loc[yolo_df['label'] == 'left_hip']\n",
    "    yolo_l_hip.index = yolo_l_hip['frame']\n",
    "\n",
    "    # plot both heights \n",
    "    fig1, (ax1, ax2) = plt.subplots(2, figsize=(12, 6))\n",
    "    fig1.suptitle('Hip and Shoulder Y: ' + video_name)\n",
    "    ax1.plot(-yolo_r_shoulder['Y'], label = 'r_shoulder -Y')\n",
    "    ax1.plot(-yolo_r_hip['Y'], label = 'r_hip -Y')\n",
    "    ax1.vlines(x = frame_ref, ymin = min(-yolo_r_hip['Y']), ymax = max(-yolo_r_shoulder['Y']), color = 'black', label = 'frame_ref')\n",
    "    ax1.vlines(x = frame_i, ymin = min(-yolo_r_hip['Y']), ymax = max(-yolo_r_shoulder['Y']), color = 'red', label = 'frame_i')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    ax2.plot(-yolo_l_shoulder['Y'], label = 'l_shoulder -Y')\n",
    "    ax2.plot(-yolo_l_hip['Y'], label = 'l_hip -Y')\n",
    "    ax2.vlines(x = frame_ref, ymin = min(-yolo_r_hip['Y']), ymax = max(-yolo_r_shoulder['Y']), color = 'black', label = 'frame_ref')\n",
    "    ax2.vlines(x = frame_i, ymin = min(-yolo_r_hip['Y']), ymax = max(-yolo_r_shoulder['Y']), color = 'red', label = 'frame_i')\n",
    "    ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig1.savefig(os.path.join(output_folder, video_name + '_hip_shoulder_y.png'))\n",
    "    plt.close(fig1)\n",
    "    plt.close()\n",
    "\n",
    "    # shoulder Y - hip Y at reference frame \n",
    "    right_torso_h_pix = abs(yolo_r_shoulder['Y'] - yolo_r_hip['Y'])\n",
    "    right_torso_h_pix = pd.Series(right_torso_h_pix).rolling(window=10, min_periods=1).mean()\n",
    "    left_torso_h_pix = abs(yolo_l_shoulder['Y'] - yolo_l_hip['Y'])\n",
    "    left_torso_h_pix = pd.Series(left_torso_h_pix).rolling(window=10, min_periods=1).mean()\n",
    "    \n",
    "    # plot torso heights  \n",
    "    fig2, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    fig2.suptitle('Filtered Torso Height: ' + video_name)\n",
    "    ax1.plot(right_torso_h_pix, label = 'right_height')\n",
    "    ax1.plot(left_torso_h_pix, label = 'left_height')\n",
    "    ax1.vlines(x = frame_ref, ymin = min(right_torso_h_pix), ymax = max(right_torso_h_pix), color = 'black', label = 'frame_ref')\n",
    "    ax1.vlines(x = frame_i, ymin = min(right_torso_h_pix), ymax = max(right_torso_h_pix), color = 'red', label = 'frame_i')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig2.savefig(os.path.join(output_folder, video_name +'torso_height.png'))\n",
    "    plt.close(fig2)\n",
    "    plt.close()\n",
    "    \n",
    "    # s_ratio = s_i/s_ref  \n",
    "   # right_s_ratio = right_torso_h_pix_filt/right_torso_h_pix_filt[frame_ref]\n",
    "   # left_s_ratio = left_torso_h_pix_filt/left_torso_h_pix_filt[frame_ref]\n",
    "    right_s_ratio = right_torso_h_pix/right_torso_h_pix[frame_ref]\n",
    "    left_s_ratio = left_torso_h_pix/left_torso_h_pix[frame_ref]\n",
    "    \n",
    "    fig3, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    fig3.suptitle('Height Ratio: ' + video_name)\n",
    "    ax1.plot(right_s_ratio, label = 'right_height_ratio')\n",
    "    ax1.plot(left_s_ratio, label = 'left_height_ratio')\n",
    "    ax1.vlines(x = frame_ref, ymin = min(right_s_ratio), ymax = max(right_s_ratio), color = 'black', label = 'frame_ref')\n",
    "    ax1.vlines(x = frame_i, ymin = min(right_s_ratio), ymax = max(right_s_ratio), color = 'red', label = 'frame_i')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig3.savefig(os.path.join(output_folder, video_name + '_height_ratio.png'))\n",
    "    plt.close(fig3)\n",
    "    plt.close()\n",
    "\n",
    "    # get size ratio at current frame (frame_i)\n",
    "    right_s_ratio_i = right_s_ratio[frame_i]\n",
    "    left_s_ratio_i = left_s_ratio[frame_i]\n",
    "\n",
    "    return([right_s_ratio, left_s_ratio, right_s_ratio_i, left_s_ratio_i, right_torso_h_pix, left_torso_h_pix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae12d009-4af1-4d48-aae7-f8b28ec558cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea 1 - using stenum formula - can't be used retrospectively \n",
    "    # delta_d = (d_ref/s_ratio) - d_ref\n",
    "    # d_ref = distance from camera to front end of mat, measured \n",
    "    # true delta_d = mat length \n",
    "def estimate_delta_d(d_ref, torso_ratio, true_delta_d):\n",
    "    delta_d_calculated = (d_ref/torso_ratio) - d_ref\n",
    "    delta_d_error = true_delta_d - delta_d_calculated\n",
    "    return([delta_d_calculated, delta_d_error])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0b2f3e-882d-4f0e-b5be-b4725fdd4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea 2 - use turn midpoints frames, expect person to have traveled 17 feet before turning\n",
    "# could be used retrospectively for in person BW, not for home videos \n",
    "\n",
    "def estimate_vel_from_turn_times(turns_df, fps, true_delta_d, torso_h, video_name): \n",
    "    \n",
    "    turn_midpoints = turns_df['turn_midpoint']\n",
    "    time_btwn_turn_midpoints = np.diff(turn_midpoints)\n",
    "    velocity_from_turns = true_delta_d / (time_btwn_turn_midpoints/fps)\n",
    "    \n",
    "    fig4, ax1 = plt.subplots()\n",
    "    ax1.plot(torso_h, label = 'torso_height', color = 'black')\n",
    "    ax1.scatter(x = turn_midpoints, y = torso_h[turn_midpoints], color = 'blue', label = 'turn_midpoints')\n",
    "    ax1.legend()\n",
    "    fig4.savefig(os.path.join(output_folder, video_name + '_turn_midpoints_by_height.png'))\n",
    "    plt.close(fig4)\n",
    "    plt.close()\n",
    "\n",
    "    return(velocity_from_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecb87a36-3fbd-4082-9680-ff37b5b112b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk 1\n",
      "estimate dist\n",
      "1 160 0.3599208952604652 [4.878236693705038, 0.30311045655402946]\n",
      "walk 2\n",
      "estimate dist\n",
      "289 452 0.4070181269592236 [3.996353943149515, 1.1849932071095521]\n",
      "walk 1\n",
      "estimate dist\n",
      "1 168 0.36747064845265814 [4.7216556017799265, 0.4596915484791406]\n",
      "walk 2\n",
      "estimate dist\n",
      "333 507 0.4050133912140999 [4.029712732344931, 1.1516344179141358]\n",
      "walk 1\n",
      "estimate dist\n",
      "41 230 0.262694424608143 [6.950464056446975, -1.7691169061879082]\n",
      "walk 2\n",
      "estimate dist\n",
      "389 546 0.2898457365209478 [6.067404110846963, -0.8860569605878963]\n"
     ]
    }
   ],
   "source": [
    "# for each video (row), calculate change in distance from size ratio \n",
    "# save values and errors in .csv file \n",
    "\n",
    "#output .csvs  \n",
    "dist_from_ratio_df = pd.DataFrame(index = range(len(ground_truth_df)), \n",
    "                                columns = ['video', \n",
    "                                           'true_delta_d',\n",
    "                                           'true_d_ref',\n",
    "                                           'frame_ref_1', \n",
    "                                           'frame_i_1', \n",
    "                                           'estimated_delta_d_1', \n",
    "                                           'estimated_delta_d_1_error',\n",
    "                                           'estimated_velocity_1_mps',\n",
    "                                           'frame_ref_2', \n",
    "                                           'frame_i_2', \n",
    "                                           'estimated_delta_d_2',\n",
    "                                           'estimated_delta_d_2_error',\n",
    "                                           'estimated_velocity_2_mps'])\n",
    "\n",
    "vel_from_turn_time = pd.DataFrame(index = range(len(ground_truth_df)),\n",
    "                                  columns = ['video',\n",
    "                                             'estimated_velocity_1_mps',\n",
    "                                             'estimated_velocity_2_mps'])\n",
    "                                                          \n",
    "for video_i, current_video in enumerate(ground_truth_df['video']):\n",
    "    \n",
    "    dist_from_ratio_df.loc[video_i, \"video\"] = current_video\n",
    "    true_delta_d = ground_truth_df['mat_length_ft'].iloc[video_i] / (3.281) # convert feet to meters \n",
    "    dist_from_ratio_df.loc[video_i, \"true_delta_d\"] = true_delta_d\n",
    "    true_d_ref = ground_truth_df['dis_cam_to_front_mat_ft'].iloc[video_i]  / (3.281)\n",
    "    dist_from_ratio_df.loc[video_i, \"true_d_ref\"] = true_d_ref\n",
    "    yolo_path = ground_truth_df['yolo_full_path'].iloc[video_i] \n",
    "    yolo_df = pd.read_csv(yolo_path, index_col =0)\n",
    "    fps = 30 # know my phone and BW camera is 30, need to update if using other cameras \n",
    "    turn_times_path = ground_truth_df['turn_times_path'].iloc[video_i]\n",
    "    turn_times_df = pd.read_csv(turn_times_path, index_col = 0)\n",
    "\n",
    "    # estimate distance change using size ratio change \n",
    "    if ~np.isnan(ground_truth_df['front_end_mat_1'].iloc[video_i]) & ~np.isnan(ground_truth_df['far_end_mat_1'].iloc[video_i]):\n",
    "        print('walk 1')\n",
    "        # calculate values\n",
    "        frame_ref = int(ground_truth_df['front_end_mat_1'].iloc[video_i])\n",
    "        frame_i = int(ground_truth_df['far_end_mat_1'].iloc[video_i])\n",
    "        torso_height_results_1 = calculate_torso_height_ratio(yolo_df, frame_ref, frame_i, fps, current_video)\n",
    "        delta_d_results_1 =  estimate_delta_d(true_d_ref, torso_height_results_1[2], true_delta_d)\n",
    "        #d_ref_results_1 = estimate_d_ref(true_delta_d, torso_height_results_1[2], true_d_ref)\n",
    "        print('estimate dist')\n",
    "        print(frame_ref, frame_i, torso_height_results_1[2], delta_d_results_1)\n",
    "        \n",
    "        # save results in df \n",
    "        dist_from_ratio_df.loc[video_i, \"frame_ref_1\"] = frame_ref\n",
    "        dist_from_ratio_df.loc[video_i, \"frame_i_1\"] = frame_i\n",
    "        dist_from_ratio_df.loc[video_i, \"estimated_delta_d_1\"] = delta_d_results_1[0]\n",
    "        dist_from_ratio_df.loc[video_i, 'estimated_delta_d_1_error'] = delta_d_results_1[1]\n",
    "        dist_from_ratio_df.loc[video_i, 'estimated_velocity_1_mps'] = delta_d_results_1[0] / ((frame_i - frame_ref)/fps) # m/s\n",
    "        #dist_from_ratio_df.loc[video_i, \"estimated_d_ref_1\"] = d_ref_results_1[0]\n",
    "       # dist_from_ratio_df.loc[video_i, 'estimated_d_ref_1_error'] = d_ref_results_1[1]\n",
    "        \n",
    "\n",
    "    # if there is data for second walk from camera \n",
    "    if ~np.isnan(ground_truth_df['front_end_mat_2'].iloc[video_i]) & ~np.isnan(ground_truth_df['far_end_mat_2'].iloc[video_i]):\n",
    "        print('walk 2')\n",
    "        # calculate values \n",
    "        frame_ref = int(ground_truth_df['front_end_mat_2'].iloc[video_i])\n",
    "        frame_i = int(ground_truth_df['far_end_mat_2'].iloc[video_i])\n",
    "        torso_height_results_2 = calculate_torso_height_ratio(yolo_df, frame_ref, frame_i, fps, current_video)\n",
    "        delta_d_results_2 = estimate_delta_d(true_d_ref, torso_height_results_2[2], true_delta_d)\n",
    "       # d_ref_results_2 = estimate_d_ref(true_delta_d, torso_height_results_2[2], true_d_ref)\n",
    "        print('estimate dist')\n",
    "        print(frame_ref, frame_i, torso_height_results_2[2], delta_d_results_2)\n",
    "\n",
    "        # save results in df \n",
    "        dist_from_ratio_df.loc[video_i, \"frame_ref_2\"] = frame_ref\n",
    "        dist_from_ratio_df.loc[video_i, \"frame_i_2\"] = frame_i\n",
    "        dist_from_ratio_df.loc[video_i, \"estimated_delta_d_2\"] = delta_d_results_2[0]\n",
    "        dist_from_ratio_df.loc[video_i, 'estimated_delta_d_2_error'] = delta_d_results_2[1]\n",
    "        dist_from_ratio_df.loc[video_i, 'estimated_velocity_2_mps'] = delta_d_results_2[0] / ((frame_i - frame_ref)/fps) # m/s\n",
    "        #dist_from_ratio_df.loc[video_i, \"estimated_d_ref_2\"] = d_ref_results_2[0]\n",
    "        #dist_from_ratio_df.loc[video_i, 'estimated_d_ref_2_error'] = d_ref_results_2[1]\n",
    "\n",
    "    # estimate velocity with known distance travled and turn midpoints \n",
    "    velocity_from_turns = estimate_vel_from_turn_times(turn_times_df, fps, true_delta_d, torso_height_results_1[4], current_video)\n",
    "    \n",
    "    vel_from_turn_time.loc[video_i, 'video'] = current_video\n",
    "    vel_from_turn_time.loc[video_i,'estimated_velocity_1_mps'] = velocity_from_turns[0]\n",
    "    vel_from_turn_time.loc[video_i,'estimated_velocity_2_mps'] = velocity_from_turns[1]\n",
    "\n",
    "\n",
    "\n",
    "# save .csv \n",
    "dist_from_ratio_df.to_csv(os.path.join(output_folder, 'delta_d_and_vel_from_ratio.csv'))\n",
    "vel_from_turn_time.to_csv(os.path.join(output_folder, 'vel_from_turn_time.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5541410d-69b1-47ad-8d29-568fe874d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>estimated_velocity_1_mps</th>\n",
       "      <th>estimated_velocity_2_mps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MM_HC_17ft_gait_vertical_right</td>\n",
       "      <td>0.914355</td>\n",
       "      <td>0.868382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MM_HC_17ft_gait_vertical_right</td>\n",
       "      <td>0.914355</td>\n",
       "      <td>0.868382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MM_HC_17ft_gait_vertical_right</td>\n",
       "      <td>0.914355</td>\n",
       "      <td>0.868382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            video  estimated_velocity_1_mps  \\\n",
       "0  MM_HC_17ft_gait_vertical_right                  0.914355   \n",
       "1  MM_HC_17ft_gait_vertical_right                  0.914355   \n",
       "2  MM_HC_17ft_gait_vertical_right                  0.914355   \n",
       "\n",
       "   estimated_velocity_2_mps  \n",
       "0                  0.868382  \n",
       "1                  0.868382  \n",
       "2                  0.868382  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel_from_turn_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11078b0d-0f3f-4164-80d9-9a416f43e358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other ideas \n",
    "# double check formula \n",
    "# torso area? not sure how much width affects \n",
    "# filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6e1a6f-2107-49b4-a8f3-6058e1ab5638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea 2 - know distance traveled -> use ratio at front and back of mat (17 ft) to make ratio \n",
    "#-> get distance from camera at front end of mat \n",
    "\n",
    "# delta_d = (d_ref/s_ratio) - d_ref -> solve for d_ref -> d_ref = (-s_ratio * delta_d) / (s_ratio - 1)\n",
    "# delta_d = distance traveled between frame_ref and frame_i, math length \n",
    "# true_d_ref = true distance from camera to front of mat, measured \n",
    "def estimate_d_ref(delta_d, torso_ratio, true_d_ref):\n",
    "    d_ref_calculated = (-torso_ratio * delta_d) / (torso_ratio - 1)\n",
    "    d_ref_error = true_d_ref - d_ref_calculated\n",
    "    return([d_ref_calculated, d_ref_error])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
