{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6f9e8-dd7b-46a6-9c16-f69d16acf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ba9df-f0b2-4e8d-8968-6b65ae395979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy and paste .csv file paths into excel \n",
    "# read in excel and use to load \n",
    "yolo_and_turn_paths = r'C:\\Users\\mmccu\\Box\\Brainwalk\\Home Video Walking\\Megan Project\\bw_data_and_code\\gait\\gait_test_velocity_videos\\test_vel_turn_yolo_csv_paths.xlsx'\n",
    "\n",
    "# output \n",
    "output_folder = # gait_test_velocity outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864026da-1b16-4a9e-b96d-8fa807827233",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_delta_d = 17 # mat 17 feet long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109c414-9fa5-4010-a267-3b2f44430631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea 2 - use turn midpoints frames, expect person to have traveled 17 feet before turning\n",
    "# could be used retrospectively for in person BW, not for home videos \n",
    "\n",
    "def estimate_vel_from_turn_times(turns_df, fps, true_delta_d, video_name): \n",
    "    \n",
    "    turn_midpoints = turns_df['turn_midpoint']\n",
    "    time_btwn_turn_midpoints = np.diff(turn_midpoints)\n",
    "    velocity_from_turns = true_delta_d / (time_btwn_turn_midpoints/fps)\n",
    "    \n",
    "    #fig4, ax1 = plt.subplots()\n",
    "     #ax1.plot(torso_h, label = 'torso_height', color = 'black')\n",
    "     #ax1.scatter(x = turn_midpoints, y = torso_h[turn_midpoints], color = 'blue', label = 'turn_midpoints')\n",
    "    # ax1.legend()\n",
    "    # fig4.savefig(os.path.join(output_folder, video_name + '_turn_midpoints_by_height.png'))\n",
    "   #  plt.close(fig4)\n",
    "     #plt.close()\n",
    "\n",
    "    return(velocity_from_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0b85e-a6a7-4d7c-b058-df845a979740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIM distance in centimeters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83dd5f0-525b-4416-b976-9903f5a54785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull files from .csv file \n",
    "\n",
    "vel_from_turn_time = pd.DataFrame(index = range(len(ground_truth_df)),\n",
    "                                  columns = ['video',\n",
    "                                             'estimated_velocity_1_mps',\n",
    "                                             'estimated_velocity_2_mps'])\n",
    "\n",
    "for video_i, current_video in enumerate(ground_truth_df['video']):\n",
    " # estimate velocity with known distance travled and turn midpoints \n",
    "    velocity_from_turns = estimate_vel_from_turn_times(turn_times_df, fps, true_delta_d, current_video)\n",
    "    \n",
    "    vel_from_turn_time.loc[video_i, 'video'] = current_video\n",
    "    vel_from_turn_time.loc[video_i,'estimated_velocity_1_mps'] = velocity_from_turns[0]\n",
    "    vel_from_turn_time.loc[video_i,'estimated_velocity_2_mps'] = velocity_from_turns[1]\n",
    "\n",
    "vel_from_turn_time.to_csv(os.path.join(output_folder, 'vel_from_turn_time.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_home_video_analysis_2",
   "language": "python",
   "name": "venv_home_video_analysis_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
